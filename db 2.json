{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.png","path":"images/avatar.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16.png","path":"images/favicon-16x16.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32.png","path":"images/favicon-32x32.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.png","path":"images/logo.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"2527bbe60f973fb3850ad164301d3dd0ffa1af76","modified":1534336663458},{"_id":"source/CNAME","hash":"60a8e20c70bd998439e15176191819babc30c3f4","modified":1514995391045},{"_id":"themes/next/.DS_Store","hash":"c47531dc2d400d132a56d40f6b1e67cbb4055eb5","modified":1516784141403},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1514995391178},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1514995391179},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1514995391179},{"_id":"themes/next/.gitignore","hash":"32ea93f21d8693d5d8fa4eef1c51a21ad0670047","modified":1514995391180},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1514995391180},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1514995391180},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1514995391180},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1514995391180},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1514995391181},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1514995391181},{"_id":"themes/next/README.cn.md","hash":"6d9177e7dad87e6129760e4b559bd3f7a15429d7","modified":1514995391181},{"_id":"themes/next/README.md","hash":"1a79f01601517b777cfb238916635d4df7368473","modified":1514995391181},{"_id":"themes/next/_config.yml","hash":"ddc5ec6fbbb46e240351388643efb417059a0384","modified":1516110524767},{"_id":"themes/next/bower.json","hash":"6d6ae7531cf3fedc97c58cdad664f5793eb3cc88","modified":1514995391182},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1514995391182},{"_id":"themes/next/package.json","hash":"93a74dbc0fe3a1208a02e9cec3c15c2375339cc1","modified":1514995391200},{"_id":"themes/next/package-lock.json","hash":"12a3557021ecf4570f4ae6f6ce603177a2d1044e","modified":1514995391200},{"_id":"source/categories/index.md","hash":"579fce50c1184d0c104f9662f269ecc62cf02e4b","modified":1514995391046},{"_id":"source/_posts/.DS_Store","hash":"000a289fd4ca62e9dee3c957dc914528e4c076ce","modified":1534336337317},{"_id":"source/_posts/2017年度总结.md","hash":"240da64df2144d510eea747b6c8d8640ce396e8a","modified":1519205347942},{"_id":"source/_posts/Boosting-Moving-Average-Reversion-Strategy-for-Online-Portfolio-Selection-A-Meta-Learning-Approach.md","hash":"d944ddc41d70b334e40c0fffded93c42aeacadc3","modified":1534336502828},{"_id":"source/_posts/Boosting-Moving-Average-Reversion-Strategy-for-Online-Portfolio-Selection.md","hash":"576c8bcb72ecb68c4e69adb396e06a391abb94e1","modified":1534336069143},{"_id":"source/_posts/CNN反向传播算法.md","hash":"90d0982fdb345f6cde4b8a9d5794232ed4f6a497","modified":1524908091088},{"_id":"source/_posts/Convexity-Lipschitzness-and-Smoothness.md","hash":"6e117ffa10732dc3d29ce437fa2d5d2a3c7b57d4","modified":1534336650789},{"_id":"source/_posts/Cost-Sensitive-Online-Classification.md","hash":"ee39ee70e65b42cf6b82b59a848781c580b3466d","modified":1530010498425},{"_id":"source/_posts/Fast-Matrix-Factorization-for-Online-Recommendation-with-Implicit-Feedback.md","hash":"f7658bc80a0f70a508655e9763caef079b6bd6df","modified":1534336080779},{"_id":"source/_posts/Softmax-and-Cross-Entropy-Loss.md","hash":"1d0241698e49ed7d25012189bab5c400ec6dd1e2","modified":1524908293306},{"_id":"source/_posts/SpringMVC-Controllers-说明文档.md","hash":"355d7b4f0d11a9bfa9e49c130f812438a16d4725","modified":1515247022781},{"_id":"source/_posts/ZELDA-男人的浪漫.md","hash":"a5a39e29d525df42c45381c0fd82b2323161878c","modified":1521445287318},{"_id":"source/_posts/google-map-比例尺算法分析.md","hash":"babc2c7c3bbe8a831e58537391225ed0acfbb890","modified":1514995391045},{"_id":"source/_posts/hexo-双线部署及seo优化.md","hash":"e43908a6507f6b110b59d50da7017ae3c7099536","modified":1514995391045},{"_id":"source/_posts/java类与成员访问控制.md","hash":"e60c9dcfb182a145cda94a5b2540bfee9d209226","modified":1514995391046},{"_id":"source/_posts/robust-optimization-in-ML.md","hash":"e138297725bee114f20497078144741e472530bd","modified":1534331766521},{"_id":"source/_posts/机器学习-决策树.md","hash":"75d78a3c380a98debad6b2141ccd65f2a845101e","modified":1524908136644},{"_id":"source/_posts/链表考点剖析.md","hash":"2e05df2d76a805adae41feabf12842770ea66022","modified":1514995391046},{"_id":"source/tags/index.md","hash":"acbcabe556c3b342d4a4ef2e4553a3bbe7a83fbf","modified":1514995391046},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1514995391179},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"352093a1b210c72136687fd2eee649244cee402c","modified":1514995391179},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1514995391179},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1514995391180},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1514995391182},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1514995391182},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1514995391182},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1514995391183},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1514995391183},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1514995391183},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1514995391183},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1514995391183},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1514995391184},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1514995391184},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1514995391184},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1514995391184},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1514995391184},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1514995391184},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1514995391185},{"_id":"themes/next/layout/_layout.swig","hash":"26bd9be87576eaab53aaf178b5ddd84d8bb4cabf","modified":1514995391185},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1514995391198},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1514995391198},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1514995391199},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1514995391199},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1514995391199},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1514995391199},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1514995391199},{"_id":"themes/next/scripts/merge-configs.js","hash":"cb617ddf692f56e6b6129564d52e302f50b28243","modified":1514995391200},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1514995391201},{"_id":"themes/next/source/.DS_Store","hash":"e8ee507309407bffe7b3c0f68601516bacee23be","modified":1516784147205},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1514995391285},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1514995391286},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1514995391286},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514995391222},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1514995391185},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1514995391185},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1514995391186},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1514995391186},{"_id":"themes/next/layout/_macro/post.swig","hash":"7a64914a0a3c893c1aaa8b5349b85898f95af314","modified":1514995391186},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1514995391186},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"9efc455894921a66bbc074055d3b39c8a34a48a4","modified":1514995391186},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1514995391187},{"_id":"themes/next/layout/_partials/comments.swig","hash":"044bc872d7b59655e46f6fb1cf14f767e31a4dfa","modified":1514995391187},{"_id":"themes/next/layout/_partials/footer.swig","hash":"3554c7ff515d7090ee45cdeea9e768bd91ed3caf","modified":1514995391187},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1514995391187},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1514995391188},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1514995391188},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1514995391188},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1514995391188},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1514995391190},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1514995391190},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1514995391191},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1514995391196},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1514995391196},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1514995391196},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1514995391196},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1514995391196},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1514995391196},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1514995391197},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1514995391201},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1514995391201},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1514995391201},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1514995391202},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1514995391202},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1514995391202},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1514995391202},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1514995391202},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1514995391202},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1514995391222},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1514995391223},{"_id":"themes/next/source/images/avatar.png","hash":"f5c6e0d08a043f591725c07d7f8c4e29e3710b5d","modified":1514995391223},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1514995391223},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1514995391223},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1514995391224},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1514995391224},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1514995391224},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1514995391224},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1514995391224},{"_id":"themes/next/source/images/favicon-16x16.png","hash":"04e442c746e943f68e6d34ec933b8c695be8ce7d","modified":1514995391225},{"_id":"themes/next/source/images/favicon-32x32.png","hash":"1b87370098f096074eb59f6ea9c1c7ad972806e8","modified":1514995391225},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1514995391225},{"_id":"themes/next/source/images/logo.png","hash":"38f2b377e11c1bc836ae15b5b94b302c2298db1d","modified":1514995391225},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1514995391225},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1514995391225},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1514995391226},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1514995391226},{"_id":"themes/next/source/js/.DS_Store","hash":"88c7c4afa46bf1771149126b6d4212cc30610171","modified":1516784147204},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514995391191},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514995391191},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514995391217},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514995391217},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514995391217},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514995391221},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514995391222},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1514995391187},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1514995391188},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1514995391189},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1514995391189},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1514995391189},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1514995391189},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1514995391189},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1514995391190},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1514995391190},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1514995391191},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1514995391191},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1514995391191},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1514995391192},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1514995391192},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1514995391192},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1514995391192},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1514995391192},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1514995391192},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1514995391193},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1514995391193},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1514995391193},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1514995391193},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1514995391193},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1514995391194},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1514995391194},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1514995391194},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1514995391194},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1514995391194},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1514995391195},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1514995391195},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1514995391195},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"f780973e0f8c2e52a70ac5e927af845d7b547b71","modified":1514995391195},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1514995391195},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1514995391198},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1514995391197},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1514995391198},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1514995391198},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1514995391216},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1514995391216},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1514995391217},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1514995391217},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1514995391221},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1514995391221},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1514995391222},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1514995391222},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1514995391226},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1514995391226},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1514995391226},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1514995391227},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1514995391227},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1514995391227},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1514995391227},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1514995391227},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1514995391228},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1514995391228},{"_id":"themes/next/source/js/src/utils.js","hash":"dbdc3d1300eec7da9632608ebc0e5b697779dad7","modified":1514995391228},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1514995391232},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1514995391235},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1514995391235},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1514995391260},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1514995391260},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1514995391260},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1514995391260},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1514995391266},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1514995391266},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1514995391266},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1514995391267},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1514995391267},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1514995391272},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1514995391273},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1514995391273},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1514995391273},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1514995391273},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1514995391274},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1514995391274},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1514995391274},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1514995391275},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1514995391275},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1514995391275},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1514995391275},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1514995391275},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1514995391276},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1514995391276},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1514995391276},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1514995391276},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1514995391276},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1514995391277},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1514995391277},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1514995391277},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1514995391277},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1514995391277},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1514995391277},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1514995391278},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1514995391278},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1514995391279},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1514995391283},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1514995391283},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1514995391284},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1514995391285},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1514995391285},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1514995391273},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1514995391197},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1514995391197},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1514995391203},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1514995391203},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1514995391203},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1514995391203},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1514995391203},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1514995391206},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1514995391211},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1514995391215},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1514995391215},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1514995391215},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1514995391215},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1514995391216},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1514995391216},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1514995391216},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1514995391217},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1514995391217},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1514995391218},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1514995391218},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1514995391218},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1514995391218},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1514995391218},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1514995391219},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1514995391219},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1514995391219},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"02fb8fa6b6c252b6bed469539cd057716606a787","modified":1514995391219},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1514995391220},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1514995391220},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1514995391220},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1514995391220},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1514995391221},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1514995391221},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"bcf52192942c0afc410c74a0fb458e7936ddc3d5","modified":1514995391221},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1514995391221},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1514995391228},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1514995391230},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1514995391231},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1514995391231},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1514995391235},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1514995391235},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1514995391236},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1514995391236},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1514995391237},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1514995391237},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1514995391254},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1514995391255},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1514995391259},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1514995391261},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1514995391263},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1514995391267},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1514995391267},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1514995391268},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1514995391282},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1514995391282},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1514995391231},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1514995391272},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1514995391272},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1514995391284},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1514995391204},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1514995391204},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1514995391204},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1514995391204},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1514995391205},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1514995391205},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1514995391205},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1514995391205},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1514995391205},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1514995391206},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1514995391206},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1514995391206},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1514995391206},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1514995391206},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1514995391207},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1514995391207},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1514995391207},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1514995391207},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1514995391207},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1514995391207},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1514995391208},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1514995391208},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1514995391208},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1514995391208},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1514995391208},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1514995391208},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1514995391209},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1514995391209},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1514995391209},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1514995391209},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1514995391209},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1514995391209},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1514995391210},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1514995391210},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1514995391210},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1514995391210},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1514995391210},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1514995391211},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1514995391211},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1514995391211},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1514995391211},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1514995391212},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1514995391212},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1514995391212},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1514995391212},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1514995391212},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1514995391212},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1514995391213},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1514995391213},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1514995391213},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1514995391213},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1514995391213},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1514995391214},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1514995391214},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1514995391214},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1514995391214},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1514995391214},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1514995391215},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1514995391219},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1514995391219},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1514995391220},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1514995391229},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1514995391229},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1514995391229},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1514995391229},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1514995391230},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1514995391239},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1514995391240},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1514995391240},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1514995391240},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1514995391240},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1514995391242},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1514995391268},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1514995391269},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1514995391271},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1514995391234},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1514995391281},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1514995391270},{"_id":"public/baidusitemap.xml","hash":"88d3c968eae797d393df54d7707aa81798845627","modified":1534337098987},{"_id":"public/search.xml","hash":"9904875a2445dde3fe1ea386a32b23992e2b483d","modified":1534337098996},{"_id":"public/sitemap.xml","hash":"81622d91f349ac5b7afd549065112d64c0574c0f","modified":1534337098997},{"_id":"public/categories/index.html","hash":"e082e4c76283d5f21c1eda06201cf503987cdd91","modified":1534337099017},{"_id":"public/tags/index.html","hash":"50dc6cd3ec89751ffe3196569f1b1f9cae7ddb14","modified":1534337099017},{"_id":"public/2018/08/15/Fast-Matrix-Factorization-for-Online-Recommendation-with-Implicit-Feedback/index.html","hash":"08cde6d335c27700f35c41a1e0fbeffe7a1cd163","modified":1534337099017},{"_id":"public/2018/07/15/Boosting-Moving-Average-Reversion-Strategy-for-Online-Portfolio-Selection-A-Meta-Learning-Approach/index.html","hash":"05cb2d75294950000190486fe63ceb344f6ea70a","modified":1534337099017},{"_id":"public/2018/06/28/Convexity-Lipschitzness-and-Smoothness/index.html","hash":"31963f46ebdaa480f8b1d80ad724ad5f7be0dad7","modified":1534337099017},{"_id":"public/2018/06/14/Cost-Sensitive-Online-Classification/index.html","hash":"7c8bc58d617eb61b4808757b6a59958fb9baf4de","modified":1534337099017},{"_id":"public/2018/04/25/robust-optimization-in-ML/index.html","hash":"76ebbce66e05d2e39ef20dc1c242823b3fc8624c","modified":1534337099017},{"_id":"public/2018/04/11/Softmax-and-Cross-Entropy-Loss/index.html","hash":"5d093410ab5ecf32df9cb4e103ea84f560badbad","modified":1534337099017},{"_id":"public/2018/03/21/CNN反向传播算法/index.html","hash":"02b3098b9232f97268aeb407407ade8bcbb207c6","modified":1534337099017},{"_id":"public/2018/03/19/ZELDA-男人的浪漫/index.html","hash":"961c6db8cb4d35cb3f3fb46cd071ff3f503ebf73","modified":1534337099018},{"_id":"public/2018/02/21/2017年度总结/index.html","hash":"645bdf5cec36599a245f57385d9779a917917df8","modified":1534337099018},{"_id":"public/2018/01/15/机器学习-决策树/index.html","hash":"174fed0532890fd387ae4c155b47e487ab39c4c2","modified":1534337099018},{"_id":"public/2018/01/05/SpringMVC-Controllers-说明文档/index.html","hash":"f7d1b43b790ca551caec2e7cff8138018c0acb87","modified":1534337099018},{"_id":"public/2017/12/24/google-map-比例尺算法分析/index.html","hash":"b221a783114ea5d3fa5558092b3c6e988f6dee24","modified":1534337099018},{"_id":"public/2017/10/30/链表考点剖析/index.html","hash":"7b242a44e9db1dee18fe290eaf53a388427f24f6","modified":1534337099018},{"_id":"public/2017/10/27/java类与成员访问控制/index.html","hash":"e62b333072c887653fadcc709f5b039ab311808f","modified":1534337099018},{"_id":"public/2017/10/27/hexo-双线部署及seo优化/index.html","hash":"0e042784c06bc6376f4d6b823107f6dd61e573f1","modified":1534337099018},{"_id":"public/archives/index.html","hash":"93c0675315d6e97917c4a39332bfe6944b3bb69b","modified":1534337099018},{"_id":"public/archives/page/2/index.html","hash":"a18f800655d10a1a30ff186ce04879f9acf16b10","modified":1534337099018},{"_id":"public/archives/2017/index.html","hash":"cb47ef87a89c04bbdd602d41309487440db6e1bb","modified":1534337099018},{"_id":"public/archives/2017/10/index.html","hash":"b69cebe181445fa8f7e9836544cb2939bcd9d1ca","modified":1534337099018},{"_id":"public/archives/2017/12/index.html","hash":"51d6a0011ad51abd4cd9b36df3067f328ea58bdb","modified":1534337099019},{"_id":"public/archives/2018/index.html","hash":"33eb9d0ab628c25d02ac1989a3169247a0a56a99","modified":1534337099019},{"_id":"public/archives/2018/page/2/index.html","hash":"edfff874c063872c0dcb53335f0c475428f3ac2e","modified":1534337099019},{"_id":"public/archives/2018/01/index.html","hash":"2f12dc0518973f7a626e1a4d81f62cd956f9bffb","modified":1534337099019},{"_id":"public/archives/2018/02/index.html","hash":"7812cd0316f2f4fdb28d117c1ad0b3a510e6b1ed","modified":1534337099019},{"_id":"public/archives/2018/03/index.html","hash":"e9b858fb96340642828409a988d653f9a10592ac","modified":1534337099019},{"_id":"public/archives/2018/04/index.html","hash":"75fc6ba26d54ab2f9c3cc7feb859a079d5aa0228","modified":1534337099019},{"_id":"public/archives/2018/06/index.html","hash":"1574f5776a160980055d39ac0b29baf0eaaf906a","modified":1534337099019},{"_id":"public/archives/2018/07/index.html","hash":"0d3cd729f7a40a1495e3dc86527163013070da81","modified":1534337099019},{"_id":"public/archives/2018/08/index.html","hash":"eb7360b251a714215c73375757d17994d4c05a5c","modified":1534337099019},{"_id":"public/categories/paper-notes/index.html","hash":"5e30c0e3620ddf360c5f82c9e2a540341cb21f7b","modified":1534337099019},{"_id":"public/categories/生活点滴/index.html","hash":"3e8a32b410212b4a8a031ac6ff84bdd831ed2856","modified":1534337099019},{"_id":"public/categories/artificial-intelligence/index.html","hash":"731d9d622d4b3602ffc4cfdfe69912c1b494c660","modified":1534337099019},{"_id":"public/categories/杂谈/index.html","hash":"ef009d574ced46f090222a4ab03f9d3334922872","modified":1534337099019},{"_id":"public/categories/前端/index.html","hash":"2e0d0de2d5484da51fd1bc8e4d1d831ce4c87235","modified":1534337099020},{"_id":"public/categories/SpringMVC/index.html","hash":"f0d7a0090273bbfc39f87cab04b2bfa42fed8bb9","modified":1534337099020},{"_id":"public/categories/技术分享/index.html","hash":"2f8b011356facab00abe2529fc2e44cfffaf1bf1","modified":1534337099020},{"_id":"public/categories/java/index.html","hash":"16b7508eeb6b73812c5e160af7d2f8d011117277","modified":1534337099020},{"_id":"public/categories/笔试面试/index.html","hash":"7aca3d2b876e6dd204a3c0f2b6442000351b73b8","modified":1534337099020},{"_id":"public/index.html","hash":"fd583ba4bb897ac45ce1eb8da23e7be1be104f90","modified":1534337099020},{"_id":"public/page/2/index.html","hash":"c4ea7d085e3b790d6131919dd85aa3fe7d142202","modified":1534337099020},{"_id":"public/tags/machine-learning/index.html","hash":"773533170e7adbefff2cf1db082bbd4aabbcb2ec","modified":1534337099020},{"_id":"public/tags/年度总结/index.html","hash":"e204e8d54a6f265c186c7286c10052db6fd84a86","modified":1534337099020},{"_id":"public/tags/deep-learning/index.html","hash":"231db2f7ba06f68770c1267fc85d67a1285f3221","modified":1534337099020},{"_id":"public/tags/softmax/index.html","hash":"4d39305b5ed16619c294cfcc43701921b219c69e","modified":1534337099021},{"_id":"public/tags/游戏/index.html","hash":"5e87132fce95286f460ea401ee81be425ca1776e","modified":1534337099021},{"_id":"public/tags/google-map/index.html","hash":"0805e496283c5e28e6a595f735bb110db4c8d32a","modified":1534337099021},{"_id":"public/tags/Controllers/index.html","hash":"b72a4f8985b98db96de2543d0ad013fe8d42cb68","modified":1534337099021},{"_id":"public/tags/hexo/index.html","hash":"c68c7b7556c97c8a556134f7cc6500ba9449786e","modified":1534337099021},{"_id":"public/tags/java基础/index.html","hash":"684fdfb0a627782a5089234da27652123b1df7ac","modified":1534337099021},{"_id":"public/tags/machine-learing/index.html","hash":"31e7250d06cd8affc4a05274d4d036d78f8ccc8e","modified":1534337099021},{"_id":"public/tags/面试/index.html","hash":"fad7b7b7aecdcabbf5756b3236708f8aaed034e2","modified":1534337099021},{"_id":"public/CNAME","hash":"60a8e20c70bd998439e15176191819babc30c3f4","modified":1534337099026},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1534337099026},{"_id":"public/images/avatar.png","hash":"f5c6e0d08a043f591725c07d7f8c4e29e3710b5d","modified":1534337099026},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1534337099026},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1534337099026},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1534337099026},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1534337099026},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1534337099026},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1534337099026},{"_id":"public/images/favicon-16x16.png","hash":"04e442c746e943f68e6d34ec933b8c695be8ce7d","modified":1534337099026},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1534337099026},{"_id":"public/images/favicon-32x32.png","hash":"1b87370098f096074eb59f6ea9c1c7ad972806e8","modified":1534337099026},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1534337099026},{"_id":"public/images/logo.png","hash":"38f2b377e11c1bc836ae15b5b94b302c2298db1d","modified":1534337099026},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1534337099026},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1534337099027},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1534337099027},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1534337099027},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1534337099027},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1534337099027},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1534337099027},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1534337099027},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1534337099027},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1534337099027},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1534337099027},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1534337099027},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1534337099027},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1534337099027},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1534337099027},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1534337099027},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1534337099027},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1534337099027},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1534337099027},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1534337099428},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1534337099433},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1534337099481},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1534337099481},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1534337099481},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1534337099481},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1534337099481},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1534337099481},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1534337099481},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1534337099481},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1534337099481},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1534337099482},{"_id":"public/js/src/utils.js","hash":"dbdc3d1300eec7da9632608ebc0e5b697779dad7","modified":1534337099482},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1534337099482},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1534337099482},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1534337099482},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1534337099482},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1534337099482},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1534337099482},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1534337099482},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1534337099482},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1534337099482},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1534337099483},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1534337099483},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1534337099484},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1534337099484},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1534337099484},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1534337099484},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1534337099484},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1534337099484},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1534337099484},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1534337099484},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1534337099484},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1534337099484},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1534337099484},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1534337099484},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1534337099484},{"_id":"public/lib/fastclick/README.html","hash":"d6e90449a2c09f3033f7e43d68b0cc8208e22e09","modified":1534337099484},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"06811ca2f722dead021493457f27cdc264ef928d","modified":1534337099484},{"_id":"public/lib/jquery_lazyload/README.html","hash":"a08fccd381c8fdb70ba8974b208254c5ba23a95f","modified":1534337099484},{"_id":"public/css/main.css","hash":"c55c18ce044758b37aa210b0ccaed617a423b5e8","modified":1534337099484},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1534337099485},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1534337099485},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1534337099485},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1534337099485},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1534337099485},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1534337099485},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1534337099485},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1534337099485},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1534337099485},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1534337099485},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1534337099485},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1534337099485},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1534337099485},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1534337099485},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1534337099485},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1534337099485},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1534337099486},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1534337099486},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1534337099486},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1534337099486},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1534337099486},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1534337099486},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1534337099486},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1534337099506}],"Category":[{"name":"paper notes","_id":"cjkv4owbn0003fb9lpesiajag"},{"name":"生活点滴","_id":"cjkv4owbs0008fb9lzljyf5t5"},{"name":"artificial intelligence","_id":"cjkv4owbv000ffb9lvxrr1o5y"},{"name":"杂谈","_id":"cjkv4owc70015fb9l0lahr6rg"},{"name":"前端","_id":"cjkv4owc8001cfb9lfgvfb86o"},{"name":"SpringMVC","_id":"cjkv4owc9001hfb9ljlo5wira"},{"name":"技术分享","_id":"cjkv4owca001lfb9ldoap9yso"},{"name":"java","_id":"cjkv4owcb001pfb9lylod0t3m"},{"name":"笔试面试","_id":"cjkv4owcc001tfb9lq8sjf5tl"}],"Data":[],"Page":[{"title":"categories","date":"2017-10-25T01:41:31.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2017-10-25 09:41:31\ntype: \"categories\"\ncomments: false\n---\n","updated":"2018-01-03T16:03:11.046Z","path":"categories/index.html","layout":"page","_id":"cjkv4owbh0000fb9lw8h4u0ns","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2017-10-25T01:39:11.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-10-25 09:39:11\ntype: \"tags\"\ncomments: false\n---\n","updated":"2018-01-03T16:03:11.046Z","path":"tags/index.html","layout":"page","_id":"cjkv4owgj001xfb9le2f6u8wl","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Boosting Moving Average Reversion Strategy for Online Portfolio Selection: A Meta-Learning Approach","date":"2018-07-15T12:30:17.000Z","_content":"\n> [Boosting Moving Average Reversion Strategy for Online Portfolio Selection: A Meta-Learning Approach](https://link.springer.com/chapter/10.1007/978-3-319-55699-4_30)\n\n<!--- more --->\n\n#### Background\n\n- All existing mean reversion strategies do not fully consider the noisy data and outliers \n- the assumption of single-period prediction leads to estimation error\n- RMR (Robust Mean Reversion) and OLMAR uses multi-period prediction, but the algorithm sees each period equally, which ignores the temporal heterogeneity of historical price relatives and causes inaccuracy of predictions. \n\n#### Contribution\n\nWe utilize meta learning to exploit the benefit of multi-period prediction and the periods are assigned with weights according to their performances. Moreover, this alleviates the impact of noisy data and outliers. \n\n**first phase**: predict the price relative at next period based on historical data.\n\n**second phase: **compute the optimal portfolio given the prediction of price relative. \n\nuse Passive-Aggressive algorithm.\n\n### Algorithm\n\n1. generate a set of experts and each expert is a predictor of the price relative following a mean reversion policy.  \n2. In each period, each expert first makes its predictions on the price relatives in next period.\n3. compute the cumulated losses induced by each expert from their historical predictions and the true past price relatives.  \n4. With the cumulated losses, we compute the weights assigned to each expert.\n5. make prediction.\n6. use **Online Passive-Aggressive learning method **to compute an optimized portfolio with the final prediction of price relatives in next period. \n\n","source":"_posts/Boosting-Moving-Average-Reversion-Strategy-for-Online-Portfolio-Selection-A-Meta-Learning-Approach.md","raw":"---\ntitle: >-\n  Boosting Moving Average Reversion Strategy for Online Portfolio Selection: A\n  Meta-Learning Approach\ndate: 2018-07-15 20:30:17\ntags: machine learning\ncategories: paper notes\n---\n\n> [Boosting Moving Average Reversion Strategy for Online Portfolio Selection: A Meta-Learning Approach](https://link.springer.com/chapter/10.1007/978-3-319-55699-4_30)\n\n<!--- more --->\n\n#### Background\n\n- All existing mean reversion strategies do not fully consider the noisy data and outliers \n- the assumption of single-period prediction leads to estimation error\n- RMR (Robust Mean Reversion) and OLMAR uses multi-period prediction, but the algorithm sees each period equally, which ignores the temporal heterogeneity of historical price relatives and causes inaccuracy of predictions. \n\n#### Contribution\n\nWe utilize meta learning to exploit the benefit of multi-period prediction and the periods are assigned with weights according to their performances. Moreover, this alleviates the impact of noisy data and outliers. \n\n**first phase**: predict the price relative at next period based on historical data.\n\n**second phase: **compute the optimal portfolio given the prediction of price relative. \n\nuse Passive-Aggressive algorithm.\n\n### Algorithm\n\n1. generate a set of experts and each expert is a predictor of the price relative following a mean reversion policy.  \n2. In each period, each expert first makes its predictions on the price relatives in next period.\n3. compute the cumulated losses induced by each expert from their historical predictions and the true past price relatives.  \n4. With the cumulated losses, we compute the weights assigned to each expert.\n5. make prediction.\n6. use **Online Passive-Aggressive learning method **to compute an optimized portfolio with the final prediction of price relatives in next period. \n\n","slug":"Boosting-Moving-Average-Reversion-Strategy-for-Online-Portfolio-Selection-A-Meta-Learning-Approach","published":1,"updated":"2018-08-15T12:35:02.828Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owbi0001fb9lvul48xzk","content":"<blockquote>\n<p><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-55699-4_30\" target=\"_blank\" rel=\"noopener\">Boosting Moving Average Reversion Strategy for Online Portfolio Selection: A Meta-Learning Approach</a></p>\n</blockquote>\n<a id=\"more\"></a>\n<h4 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h4><ul>\n<li>All existing mean reversion strategies do not fully consider the noisy data and outliers </li>\n<li>the assumption of single-period prediction leads to estimation error</li>\n<li>RMR (Robust Mean Reversion) and OLMAR uses multi-period prediction, but the algorithm sees each period equally, which ignores the temporal heterogeneity of historical price relatives and causes inaccuracy of predictions. </li>\n</ul>\n<h4 id=\"Contribution\"><a href=\"#Contribution\" class=\"headerlink\" title=\"Contribution\"></a>Contribution</h4><p>We utilize meta learning to exploit the benefit of multi-period prediction and the periods are assigned with weights according to their performances. Moreover, this alleviates the impact of noisy data and outliers. </p>\n<p><strong>first phase</strong>: predict the price relative at next period based on historical data.</p>\n<p><strong>second phase: </strong>compute the optimal portfolio given the prediction of price relative. </p>\n<p>use Passive-Aggressive algorithm.</p>\n<h3 id=\"Algorithm\"><a href=\"#Algorithm\" class=\"headerlink\" title=\"Algorithm\"></a>Algorithm</h3><ol>\n<li>generate a set of experts and each expert is a predictor of the price relative following a mean reversion policy.  </li>\n<li>In each period, each expert first makes its predictions on the price relatives in next period.</li>\n<li>compute the cumulated losses induced by each expert from their historical predictions and the true past price relatives.  </li>\n<li>With the cumulated losses, we compute the weights assigned to each expert.</li>\n<li>make prediction.</li>\n<li>use <strong>Online Passive-Aggressive learning method </strong>to compute an optimized portfolio with the final prediction of price relatives in next period. </li>\n</ol>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p><a href=\"https://link.springer.com/chapter/10.1007/978-3-319-55699-4_30\" target=\"_blank\" rel=\"noopener\">Boosting Moving Average Reversion Strategy for Online Portfolio Selection: A Meta-Learning Approach</a></p>\n</blockquote>","more":"<h4 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h4><ul>\n<li>All existing mean reversion strategies do not fully consider the noisy data and outliers </li>\n<li>the assumption of single-period prediction leads to estimation error</li>\n<li>RMR (Robust Mean Reversion) and OLMAR uses multi-period prediction, but the algorithm sees each period equally, which ignores the temporal heterogeneity of historical price relatives and causes inaccuracy of predictions. </li>\n</ul>\n<h4 id=\"Contribution\"><a href=\"#Contribution\" class=\"headerlink\" title=\"Contribution\"></a>Contribution</h4><p>We utilize meta learning to exploit the benefit of multi-period prediction and the periods are assigned with weights according to their performances. Moreover, this alleviates the impact of noisy data and outliers. </p>\n<p><strong>first phase</strong>: predict the price relative at next period based on historical data.</p>\n<p><strong>second phase: </strong>compute the optimal portfolio given the prediction of price relative. </p>\n<p>use Passive-Aggressive algorithm.</p>\n<h3 id=\"Algorithm\"><a href=\"#Algorithm\" class=\"headerlink\" title=\"Algorithm\"></a>Algorithm</h3><ol>\n<li>generate a set of experts and each expert is a predictor of the price relative following a mean reversion policy.  </li>\n<li>In each period, each expert first makes its predictions on the price relatives in next period.</li>\n<li>compute the cumulated losses induced by each expert from their historical predictions and the true past price relatives.  </li>\n<li>With the cumulated losses, we compute the weights assigned to each expert.</li>\n<li>make prediction.</li>\n<li>use <strong>Online Passive-Aggressive learning method </strong>to compute an optimized portfolio with the final prediction of price relatives in next period. </li>\n</ol>"},{"title":"2017年度总结","date":"2018-02-21T07:44:05.000Z","_content":"\n> 山重水复疑无路，柳暗花明又一村——陆游\n\n如果让我选出我的2017年度汉字，那么“选择”当之无愧。2017年充满了选择，大三的尾巴与大四的开始，或读研或工作或出国，每个人都必须作出选择。人生是由无数个选择组成的，就像一棵决策树，所有的决策最终决定了你的人生。\n\n2014年，面临大学与专业的选择，我义无反顾。\n\n2017年，面临保研和工作的选择，我万分纠结。\n\n<!--more-->\n\n17年的开始，刚到学校的我和大家一样开始努力的找实习。大约是3-5月那段时间，每天都在痛苦的笔试面试，同时在牛客网上刷题并查阅相关面试经验。当时心理压力很大，经常失眠，每天都在忐忑中等待结果。在刷题的过程中会突然陷入恐慌之中，负面情绪仿佛要溢出一般。\n\n很快，残酷的现实让我认识到自己水平之差和准备不足，总是在终面的时候被刷。算法题越刷越多，会的越多却越恐慌，越认识到自己的不足。项目也基本上是课程项目，很难让人眼前一亮。当时身边只有两种人，大神和普通人。大神们拿offer拿到手软，普通人则心惊胆战，认真备战。而弱渣显然是不存在的，因为弱渣连毕业都成问题，是不会去找实习的，而这种人在计算机专业少到可以忽略不计。\n\n在计算机学院，残酷的竞争让我认识到自己的水平之低，一个普通人，可怜的普通人。在这里很能体会到以前高中中等生的心情，普普通通，拼命挣扎。现在想想，当时那段日子非常感谢BB的陪伴，一起努力找实习，互相吹牛安慰，也算是很好的压力排泄方式。\n\n最后阿里四面后被拒，华为二面被拒，腾讯二面被拒，网易笔试被刷，招商银行拿到offer，仔细想想自己好像也只投了这几个公司，毕竟自己信息不足，等到投简历的时候很多公司校招都已经结束了。实习季后期学业紧张，于是放弃了继续面试投入到紧张的学习当中。\n\n时间过得很快，在考试前与家里有些争执，关于读研和工作的问题。我一心想要工作，或许是想一雪前耻，又或许是考虑到程序员本身的问题，是经验更重要还是学历更重要。思绪的复杂是很难用文字表述的，虽然自己很想成为一名科研人士，在计算机前沿探索，然而现实是很残酷的。不是所有人都适合科研，甚至只有少数人才能在领域内取得成果。逃避是弱者的选择，然而我却选择成为了一名弱者。\n\n在大三考试周结束，我并没有去实习，而是去了实验室开始毕业设计的准备，指导我的博士生学长是一个很优秀的人，在他的指导下我很快的完成了毕业设计工作。在关于未来道理的选择上，学长强烈建议我们继续深造，或许是学长的原因，我决定尽可能的保研。最终在一边准备笔试面试，一边做毕设的过程中，我成功保研。\n\n在整个寝室的命运被决定的那一天，空气都变得清新了。四个人中三个保研，一个工作。于是我们进行了简单的聚餐和game，向那段煎熬的日子say goodbye。\n\n之后的日子如同流水账，每天白天实习，晚上玩耍。时间飞逝，我追不上它的脚步，于是站在原地休息，遮住双眼。典型的“鸵鸟算法”，我运用的很熟练。\n\n2017，不那么愉快，连空气都是苦涩的。一个普通人的挣扎，写成年度总结都是那么普通。除了挣扎，2017还充满着孤独，在大三上学期和萌萌同学说再见后，我继续着孤独。直到今天我都无法衡量孤独给我带来的快乐和悲伤的重量，他们是均等的吗？\n\n2018，希望自己在又一村中努力，山穷水复可以拿来回忆，但是再来一次可就不好了。\n\n\n\n","source":"_posts/2017年度总结.md","raw":"---\ntitle: 2017年度总结\ndate: 2018-02-21 15:44:05\ntags: 年度总结\ncategories: 生活点滴\n---\n\n> 山重水复疑无路，柳暗花明又一村——陆游\n\n如果让我选出我的2017年度汉字，那么“选择”当之无愧。2017年充满了选择，大三的尾巴与大四的开始，或读研或工作或出国，每个人都必须作出选择。人生是由无数个选择组成的，就像一棵决策树，所有的决策最终决定了你的人生。\n\n2014年，面临大学与专业的选择，我义无反顾。\n\n2017年，面临保研和工作的选择，我万分纠结。\n\n<!--more-->\n\n17年的开始，刚到学校的我和大家一样开始努力的找实习。大约是3-5月那段时间，每天都在痛苦的笔试面试，同时在牛客网上刷题并查阅相关面试经验。当时心理压力很大，经常失眠，每天都在忐忑中等待结果。在刷题的过程中会突然陷入恐慌之中，负面情绪仿佛要溢出一般。\n\n很快，残酷的现实让我认识到自己水平之差和准备不足，总是在终面的时候被刷。算法题越刷越多，会的越多却越恐慌，越认识到自己的不足。项目也基本上是课程项目，很难让人眼前一亮。当时身边只有两种人，大神和普通人。大神们拿offer拿到手软，普通人则心惊胆战，认真备战。而弱渣显然是不存在的，因为弱渣连毕业都成问题，是不会去找实习的，而这种人在计算机专业少到可以忽略不计。\n\n在计算机学院，残酷的竞争让我认识到自己的水平之低，一个普通人，可怜的普通人。在这里很能体会到以前高中中等生的心情，普普通通，拼命挣扎。现在想想，当时那段日子非常感谢BB的陪伴，一起努力找实习，互相吹牛安慰，也算是很好的压力排泄方式。\n\n最后阿里四面后被拒，华为二面被拒，腾讯二面被拒，网易笔试被刷，招商银行拿到offer，仔细想想自己好像也只投了这几个公司，毕竟自己信息不足，等到投简历的时候很多公司校招都已经结束了。实习季后期学业紧张，于是放弃了继续面试投入到紧张的学习当中。\n\n时间过得很快，在考试前与家里有些争执，关于读研和工作的问题。我一心想要工作，或许是想一雪前耻，又或许是考虑到程序员本身的问题，是经验更重要还是学历更重要。思绪的复杂是很难用文字表述的，虽然自己很想成为一名科研人士，在计算机前沿探索，然而现实是很残酷的。不是所有人都适合科研，甚至只有少数人才能在领域内取得成果。逃避是弱者的选择，然而我却选择成为了一名弱者。\n\n在大三考试周结束，我并没有去实习，而是去了实验室开始毕业设计的准备，指导我的博士生学长是一个很优秀的人，在他的指导下我很快的完成了毕业设计工作。在关于未来道理的选择上，学长强烈建议我们继续深造，或许是学长的原因，我决定尽可能的保研。最终在一边准备笔试面试，一边做毕设的过程中，我成功保研。\n\n在整个寝室的命运被决定的那一天，空气都变得清新了。四个人中三个保研，一个工作。于是我们进行了简单的聚餐和game，向那段煎熬的日子say goodbye。\n\n之后的日子如同流水账，每天白天实习，晚上玩耍。时间飞逝，我追不上它的脚步，于是站在原地休息，遮住双眼。典型的“鸵鸟算法”，我运用的很熟练。\n\n2017，不那么愉快，连空气都是苦涩的。一个普通人的挣扎，写成年度总结都是那么普通。除了挣扎，2017还充满着孤独，在大三上学期和萌萌同学说再见后，我继续着孤独。直到今天我都无法衡量孤独给我带来的快乐和悲伤的重量，他们是均等的吗？\n\n2018，希望自己在又一村中努力，山穷水复可以拿来回忆，但是再来一次可就不好了。\n\n\n\n","slug":"2017年度总结","published":1,"updated":"2018-02-21T09:29:07.942Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owbl0002fb9lx2y40lmh","content":"<blockquote>\n<p>山重水复疑无路，柳暗花明又一村——陆游</p>\n</blockquote>\n<p>如果让我选出我的2017年度汉字，那么“选择”当之无愧。2017年充满了选择，大三的尾巴与大四的开始，或读研或工作或出国，每个人都必须作出选择。人生是由无数个选择组成的，就像一棵决策树，所有的决策最终决定了你的人生。</p>\n<p>2014年，面临大学与专业的选择，我义无反顾。</p>\n<p>2017年，面临保研和工作的选择，我万分纠结。</p>\n<a id=\"more\"></a>\n<p>17年的开始，刚到学校的我和大家一样开始努力的找实习。大约是3-5月那段时间，每天都在痛苦的笔试面试，同时在牛客网上刷题并查阅相关面试经验。当时心理压力很大，经常失眠，每天都在忐忑中等待结果。在刷题的过程中会突然陷入恐慌之中，负面情绪仿佛要溢出一般。</p>\n<p>很快，残酷的现实让我认识到自己水平之差和准备不足，总是在终面的时候被刷。算法题越刷越多，会的越多却越恐慌，越认识到自己的不足。项目也基本上是课程项目，很难让人眼前一亮。当时身边只有两种人，大神和普通人。大神们拿offer拿到手软，普通人则心惊胆战，认真备战。而弱渣显然是不存在的，因为弱渣连毕业都成问题，是不会去找实习的，而这种人在计算机专业少到可以忽略不计。</p>\n<p>在计算机学院，残酷的竞争让我认识到自己的水平之低，一个普通人，可怜的普通人。在这里很能体会到以前高中中等生的心情，普普通通，拼命挣扎。现在想想，当时那段日子非常感谢BB的陪伴，一起努力找实习，互相吹牛安慰，也算是很好的压力排泄方式。</p>\n<p>最后阿里四面后被拒，华为二面被拒，腾讯二面被拒，网易笔试被刷，招商银行拿到offer，仔细想想自己好像也只投了这几个公司，毕竟自己信息不足，等到投简历的时候很多公司校招都已经结束了。实习季后期学业紧张，于是放弃了继续面试投入到紧张的学习当中。</p>\n<p>时间过得很快，在考试前与家里有些争执，关于读研和工作的问题。我一心想要工作，或许是想一雪前耻，又或许是考虑到程序员本身的问题，是经验更重要还是学历更重要。思绪的复杂是很难用文字表述的，虽然自己很想成为一名科研人士，在计算机前沿探索，然而现实是很残酷的。不是所有人都适合科研，甚至只有少数人才能在领域内取得成果。逃避是弱者的选择，然而我却选择成为了一名弱者。</p>\n<p>在大三考试周结束，我并没有去实习，而是去了实验室开始毕业设计的准备，指导我的博士生学长是一个很优秀的人，在他的指导下我很快的完成了毕业设计工作。在关于未来道理的选择上，学长强烈建议我们继续深造，或许是学长的原因，我决定尽可能的保研。最终在一边准备笔试面试，一边做毕设的过程中，我成功保研。</p>\n<p>在整个寝室的命运被决定的那一天，空气都变得清新了。四个人中三个保研，一个工作。于是我们进行了简单的聚餐和game，向那段煎熬的日子say goodbye。</p>\n<p>之后的日子如同流水账，每天白天实习，晚上玩耍。时间飞逝，我追不上它的脚步，于是站在原地休息，遮住双眼。典型的“鸵鸟算法”，我运用的很熟练。</p>\n<p>2017，不那么愉快，连空气都是苦涩的。一个普通人的挣扎，写成年度总结都是那么普通。除了挣扎，2017还充满着孤独，在大三上学期和萌萌同学说再见后，我继续着孤独。直到今天我都无法衡量孤独给我带来的快乐和悲伤的重量，他们是均等的吗？</p>\n<p>2018，希望自己在又一村中努力，山穷水复可以拿来回忆，但是再来一次可就不好了。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>山重水复疑无路，柳暗花明又一村——陆游</p>\n</blockquote>\n<p>如果让我选出我的2017年度汉字，那么“选择”当之无愧。2017年充满了选择，大三的尾巴与大四的开始，或读研或工作或出国，每个人都必须作出选择。人生是由无数个选择组成的，就像一棵决策树，所有的决策最终决定了你的人生。</p>\n<p>2014年，面临大学与专业的选择，我义无反顾。</p>\n<p>2017年，面临保研和工作的选择，我万分纠结。</p>","more":"<p>17年的开始，刚到学校的我和大家一样开始努力的找实习。大约是3-5月那段时间，每天都在痛苦的笔试面试，同时在牛客网上刷题并查阅相关面试经验。当时心理压力很大，经常失眠，每天都在忐忑中等待结果。在刷题的过程中会突然陷入恐慌之中，负面情绪仿佛要溢出一般。</p>\n<p>很快，残酷的现实让我认识到自己水平之差和准备不足，总是在终面的时候被刷。算法题越刷越多，会的越多却越恐慌，越认识到自己的不足。项目也基本上是课程项目，很难让人眼前一亮。当时身边只有两种人，大神和普通人。大神们拿offer拿到手软，普通人则心惊胆战，认真备战。而弱渣显然是不存在的，因为弱渣连毕业都成问题，是不会去找实习的，而这种人在计算机专业少到可以忽略不计。</p>\n<p>在计算机学院，残酷的竞争让我认识到自己的水平之低，一个普通人，可怜的普通人。在这里很能体会到以前高中中等生的心情，普普通通，拼命挣扎。现在想想，当时那段日子非常感谢BB的陪伴，一起努力找实习，互相吹牛安慰，也算是很好的压力排泄方式。</p>\n<p>最后阿里四面后被拒，华为二面被拒，腾讯二面被拒，网易笔试被刷，招商银行拿到offer，仔细想想自己好像也只投了这几个公司，毕竟自己信息不足，等到投简历的时候很多公司校招都已经结束了。实习季后期学业紧张，于是放弃了继续面试投入到紧张的学习当中。</p>\n<p>时间过得很快，在考试前与家里有些争执，关于读研和工作的问题。我一心想要工作，或许是想一雪前耻，又或许是考虑到程序员本身的问题，是经验更重要还是学历更重要。思绪的复杂是很难用文字表述的，虽然自己很想成为一名科研人士，在计算机前沿探索，然而现实是很残酷的。不是所有人都适合科研，甚至只有少数人才能在领域内取得成果。逃避是弱者的选择，然而我却选择成为了一名弱者。</p>\n<p>在大三考试周结束，我并没有去实习，而是去了实验室开始毕业设计的准备，指导我的博士生学长是一个很优秀的人，在他的指导下我很快的完成了毕业设计工作。在关于未来道理的选择上，学长强烈建议我们继续深造，或许是学长的原因，我决定尽可能的保研。最终在一边准备笔试面试，一边做毕设的过程中，我成功保研。</p>\n<p>在整个寝室的命运被决定的那一天，空气都变得清新了。四个人中三个保研，一个工作。于是我们进行了简单的聚餐和game，向那段煎熬的日子say goodbye。</p>\n<p>之后的日子如同流水账，每天白天实习，晚上玩耍。时间飞逝，我追不上它的脚步，于是站在原地休息，遮住双眼。典型的“鸵鸟算法”，我运用的很熟练。</p>\n<p>2017，不那么愉快，连空气都是苦涩的。一个普通人的挣扎，写成年度总结都是那么普通。除了挣扎，2017还充满着孤独，在大三上学期和萌萌同学说再见后，我继续着孤独。直到今天我都无法衡量孤独给我带来的快乐和悲伤的重量，他们是均等的吗？</p>\n<p>2018，希望自己在又一村中努力，山穷水复可以拿来回忆，但是再来一次可就不好了。</p>"},{"title":"CNN反向传播算法","date":"2018-03-21T03:19:00.000Z","_content":"\n> 全文翻译自 Notes on Convolutional Neural Networks \n>\n> [论文链接](http://web.mit.edu/jvb/www/papers/cnn_tutorial.pdf)\n>\n> 释部分为自己的补充说明，可能存在错误\n\n<!--- more --->\n\n###1 介绍\n\n本文档讨论CNN的推导和实现，并加上一些简单的扩展。相比权值，卷积神经网络涉及到更多的连接。其架构本身实现了正则化。此外，CNN在某种程度上实现了平移不变性。这种特殊的神经网络假设我们希望通过数据驱动的方式学习过滤器，用来提取输入特征。推导是在二维的数据和卷积的基础上展开的，但可以很容易的推广到任意维度。\n\n我们先对经典的BP算法做一个描述，然后推导2D卷积神经网络中卷积层和子采样层（池化层）的BP权值更新方法。在整个过程中，我们强调了视线的效率，给出MATLAB代码片段配合方程讲解。然后讨论如何自动组合前一层的feature map，最后是feature map的稀疏组合。\n\n免责声明：这个笔记可能有错误。\n\n> feature map 就是特征矩阵，一张图片的每个像素点的RGB值可分别组成矩阵（R矩阵，G矩阵，B矩阵），这些就是feature map\n\n###2 全连接的反向传播算法\n\n一个典型的卷积神经网络，开始是卷积层和子采样层交替，最后几层（最接近输出）是全连接的一维网络（全连接层）。当你准备将2D feature map作为一维全连接网络的输入时，直接将所有特征连接为一个一维向量，然后就可以利用BP算法。因此在讨论CNN之前，这里先对BP算法进行解释。\n\n####2.1 前向传播 Feedforward Pass\n\n在接下来的推导中，我们考虑平方和误差函数，对于一个有c个类别和N个训练样本的多分类问题，计算公式如下：\n$$\nE^N=\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{k=1}^{c}(t_k^n-y_k^n)^2\n$$\n$t_k^n$是第n个样本对应标签的第k个维度的值，$y_k^n$表示第n个样本对应的网络输出的第k个值。对于多分类问题，输出一般为“one-of-c”形式。如果样本$x^n$属于第k类，那么$t_k^n$为正，$t^n$的其他维度即$t_{k\\neq1}^n$为0或负数。这取决于输出激活函数的选择，此处不做讨论。\n\n因为整个训练集的误差为每个训练样本的误差和，所以我们先讨论一个样本。第n个样本的误差如下：\n$$\nE^N=\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{k=1}^c(t_k^n-y_k^n)^2=\\frac{1}{2}||t^n-y^n||_2^2\\tag{1}\n$$\n在全连接层，我们可以根据反向传播规则计算E对网络权值的偏导数。用$l$代表当前层，输出层被指定为$L$层，输入层为第1层，那么当前层的输出为\n$$\nx^l=f(u^l), with \\space u^l=W^lx^{l-1}+b^l\\tag{2}\n$$\n\n\n输出激活函数$f(\\cdot)$一般选择logistic(sigmoid)函数$f(x)=(1+e^{-\\beta x})^{-1}$或者hyperbolic tangent函数$f(x)=a\\space tanh(bx)$。logistic函数将$[-\\infty,\\infty]$映射到$[0,1]$，hyperbolic tangent函数将$[-\\infty,\\infty]$映射到$[-a,a]$，因此hyperbolic tangent函数的输出平均值一般趋于0，sigmoid函数的输出平均为非零。但是如果将训练数据归一化到均值为0方差为1，可以在梯度下降时增加收敛。对于归一化的数据集来说，hyperbolic tangent函数是较好的选择。LeCun推荐$a=1.7159,b=2/3$，所以最大非线性点在$f(\\pm1)=\\pm1$，因此对预期训练目标进行正则化将会避免训练饱和。\n\n####2.2 反向传播 Backpropagation Pass\n\n通过网络反向传播的误差可以看作每个神经元关于偏差扰动的敏感度（sensitivities），通过链式法则可得：\n\n> 敏感度就是误差对目标的偏导数\n\n$$\n\\begin{equation}\n\\frac{\\partial{E}}{\\partial{b}}=\\frac{\\partial{E}}{\\partial{u}}\\frac{\\partial{u}}{\\partial{b}}=\\delta\n\\end{equation}\\tag{3}\n$$\n\n因为$\\frac{\\partial{u}}{\\partial{b}}=1$，所以bias的敏感度和误差对一个神经元的输入的偏导数是相等的。利用这个关系将高层误差反向传播到底层，使用下面的递推关系式：\n$$\n\\delta^t=(W^{l+1})^T\\delta^{l+1}\\circ f'(u^t)\\tag{4}\n$$\n其中$\\circ$表示对应位置元素相乘，从公式（1）可以看到，输出层神经元的敏感度会有一些不同：\n$$\n\\delta^L=f'(u^L)\\circ(y^n-t^n)\n$$\n最后，对每个神经元运用delta规则进行更行，即对神经元的输入使用delta进行缩放。用向量的形式表述就是：输入向量（前一层的输出）和灵敏度向量之间的一个外积：\n$$\n\\frac{\\partial{E}}{\\partial{W^l}}=x^{l-1}(\\delta^l)^T\\tag{5}\n$$\n\n$$\n\\bigtriangleup W^l=-\\eta\\frac{\\partial{E}}{\\partial{W^l}}\\tag{6}\n$$\n\n更新偏置值（bias）也是相同的原理，在实际中通常为每个权值赋予一个特定的学习率$\\eta_{ij}$。\n\n### 3 卷积神经网络 Convolutional Neural Networks\n\n>公式符号释意\n>\n>在本文中卷积核有多个，每个卷积核和feature map有多个维度，例如一张图片有RGB值，那么就有三个维度\n>\n>$i$----卷积核或者feature的第几维度\n>$j$----第几个卷积核\n>$up()$----上采样函数\n>$down()$----下采样函数\n>$l$----当前层\n\n\n\n通常卷积层和子采样层交替以减少计算时间并逐步建立空间和结构不变性。为了同时保持特异性，需要小的子采样因子。这并不是什么新鲜的概念，但简洁有效。这种模型在哺乳动物的视觉皮层非常常见，在过去十年，听觉神经科学发现，这些相同的设计范例可以在多种不同动物皮层的主要和带状听觉区域中找到。 分级分析和学习架构可能仍然是听觉领域的关键。\n\n####3.1 卷积层 Convolution Layers\n\n我们现在推导卷积层的BP更行。在一个卷积层，上一层的feature map与一个卷积核进行卷积运算，然后通过一个激活函数获得输出feature map。每个输出map可能是多个卷积结果的结合，公式表述：\n$$\nx_j^l=f\\left(\\sum_{i\\in M_j}x_i^{l-1}*k_{ij}^{l}+b_j^l\\right)\n$$\n\n\n$M_j$表示输入maps的集合，在MATLAB中卷积的运算需采用\"valid\"模式。通常情况下，输入maps选择一对或者三个。后面我们会讨论如何自动选择需要组合的特征map。每一个输出map都会加上一个偏执项$b$，但是对于一个特定的输出map，输入maps会和相同的卷积核进行卷积运算，也就是说，如果输出map $j$ 和 $k$ 都是由map $i$通过卷积运算的结果，那么对应的卷积核是不同的。\n\n>一张图片有RGB三个颜色通道，则对应的卷积核也是三维的，输出的feature map就是三个卷积结果的结合\n>\n>![CNN_02](http://oygov02sc.bkt.clouddn.com/CNN_02.gif)\n\n3.1.1 Computing the Gradients\n\n我们假设每个卷积层$l$后面都接一个子采样层 $l+1$。在使用BP算法计算 $l$ 层每个节点的敏感度时，我们需要先对下一层（$l+1$层）连接当前层（$l$层）的节点的敏感度求和，再乘以这些连接对应的权值（连接$l$层和$l+1$层的权值），最后乘以当前层$l$的该神经元节点的输入$u$的激活函数$f$的导数值。因为下采样的存在，采样层的一个像素（神经元）对应的灵敏度$\\delta$对应于卷积层（上一层）的输出map的一块像素（采样窗口大小）。因此，$l$层中的map的每个节点只与$l+1$层中相应map的一个节点连接。为了有效计算$l$层的敏感度，我们可以对下采样层的敏感，度map进行“上采样(upsample)”操作，这样可以使下采样层的敏感度map的大小和卷积层的map大小相同，然后将$l$层的激活值偏导map和$l+1$层的上采样敏感度map对应元素相乘。因为下采样层map的权值均是一个常数$\\beta$（见3.2节），所以我们只需要将上一步得到的结果乘以 $ \\beta$ 就可以得到$l$层的敏感度map $\\delta^l$。我们可以在卷积层的每个feature map进行相同的计算过程：\n$$\n\\delta_j^l=\\beta_j^{l+1}\\left(f'(u_j^l)\\circ up(\\delta_j^{l+1})\\right)\n$$\n其中的 $up(\\cdot)$表示上采样操作，如果下采样过程的采样因子为$n$，只需将每个像素点在水平方向和垂直方向复制$n$次就可以实现，一种有效的实现方式是利用 Kronecker product:\n$$\nup(x)=x\\otimes1_{n\\times n}\n$$\n\n\n>Ref:[克罗内克积](https://zh.wikipedia.org/zh/克罗内克积)\n\n现在对于一个给定的map，我们已经可以计算其敏感度map，然后我们可以简单的对敏感度map的所有节点求和计算出其bias（偏置项）梯度:\n$$\n\\frac{\\partial{E}}{\\partial{b_j}}=\\sum_{u,v}(\\delta_j^l)_{uv}\n$$\n最后，使用BP算法计算权重（卷积核）的梯度，很多权重在连接中是共享的，因此我们需要对所有与该权值有联系（权值共享的连接）的连接对该点求梯度，然后对这些梯度进行求和，就像计算bias梯度一样：\n$$\n\\frac{\\partial{E}}{\\partial{k_{ij}^l}}=\\sum_{u,v}(\\delta_j^l)_{uv}(p_i^{l-1})_{uv}\\tag{7}\n$$\n其中$(p_i^{l-1})_{uv}$是$x_i^{l-1}$在卷积运算时和$k_{ij}^l$按元素相乘得到输出map的$(u,v)$位置值的patch。看上去好像我们我刻意追踪输入map中哪些patch与输出map中的哪些像素（及其对应的敏感map）相对应，但是公式(7)可以通过卷积运算获得:\n$$\n\\frac{\\partial{E}}{\\partial{k_{ij}^l}}=rot180(conv2(x_i^{l-1},rot180(\\delta_j^l),'valid'))\n$$\n这里我们对$\\delta$敏感度map做旋转操作是为了这样就可以进行互相关计算而不是卷积，之后将输出旋转回来，以便当我们在前馈阶段执行卷积时，卷积核将具有正确的方向。\n\n####3.2 子采样层 Sub-sampling Layers\n\n子采样层对输入maps进行downsample操作（池化），输入有N个maps，输出也会有N个maps，只是每个maps变小了，公式表述如下：\n$$\nx_j^l=f\\left(\\beta_j^ldown(x_j^{l-1})+b_j^l\\right)\n$$\n\n\n其中的$down(\\cdot)$是下采样函数。典型的操作一般是对输入图像的不同$n\\times n$的块的像素进行求和。这样输出图像在两个维度上都缩小了n倍。每个输出map都有一个属于自己的乘性偏置β和一个加性偏置b。\n\n3.2.1 Computing the Gradients\n\n这里的困难在于如何计算敏感度maps。只要我们能得到敏感度maps，需要更新的只有bias参数 $\\beta$ 和 $b$ 。如果子采样层的下一层是全连接层，那么子采样层的敏感度maps只需要利用BP算法就可以容易获得。所以我们假设子采样层的上一层和下一层都是卷积层。\n\n当我们在3.1.1节计算卷积核梯度时，我们需要找到输入map中patch和输出map的像素的对应关系。这里就是必须找到当前层的敏感度map中那个patch与下一层的敏感度矩阵的的给定像素对应，这样就可以像公式 (4)那样应用$\\delta$递推。 当然，将输入patch和输出像素之间连接相乘的权重恰好是（旋转的）卷积核的权重。利用卷积可以实现该计算：\n$$\n\\delta_j^l=f'(u_j^l)\\circ conv2(\\delta_j^{l+1},rot180(k_j^{l+1}),full)\n$$\n如前所述，我们旋转内核是为了是卷积函数实施互相关计算。同时，我们需要对卷积边界进行“full”处理，Matlab的卷积函数会自动执行这个过程，对缺少的输入像素进行补零操作。\n\n现在我们可以很容易的计算 $b$ 和 $\\beta$ 的梯度，加性基 $b$ 的处理和之前一样，将敏感度map中所有元素相加即可 ：\n$$\n\\frac{\\partial E}{\\partial b_j}=\\sum_{u,v}(\\delta_j^l)_{uv}\n$$\n对于乘性偏置$\\beta$ ，参与了前向传播时下采样map的运算，所以在前向计算时将这些maps保存，这样避免了在反向传播时重复计算。定义：\n$$\nd_j^l=down(x_j^{l-1})\n$$\n\n\n$\\beta$ 梯度计算公式如下：\n$$\n\\frac{\\partial E}{\\partial \\beta_j}=\\sum_{u,v}(\\delta_j^l)\n$$\n\n> 补充说明：对rot180的解释\n>\n> 假设第$l-1$层输出$x^l$是一个3x3矩阵，第$l$层卷积核$k^l$是一个2x2的矩阵，步幅为1，输出一个2x2的矩阵$z^l$，则有（简化$b^l=0$，单卷积核)\n> $$\n> x^{l-1}*k^{l}=z^{l}\n> $$\n> 矩阵形式表达：\n> $$\n> \\left( \\begin{array}{}\n> x_{11}&x_{12}&x_{13}\\\\\n> x_{21}&x_{22}&x_{23}\\\\\n> x_{31}&x_{32}&x_{33}\n> \\end{array}\n> \\right)\n> *\n> \\left( \\begin{array}{}\n> k_{11}&k_{12}\\\\\n> k_{21}&k_{22}\n> \\end{array}\n> \\right)\n> =\n> \\left( \\begin{array}{}\n> z_{11}&z_{12}\\\\\n> z_{21}&z_{22}\n> \\end{array}\n> \\right)\n> $$\n> 根据卷积的定义可得：\n> $$\n> z_{11}=x_{11}k_{11}+x_{12}k_{12}+x_{21}k_{21}+x_{22}k_{22}\\\\\n> z_{12}=x_{12}k_{11}+x_{13}k_{12}+x_{22}k_{21}+x_{23}k_{22}\\\\\n> z_{21}=x_{21}k_{11}+x_{22}k_{12}+x_{31}k_{21}+x_{32}k_{22}\\\\\n> z_{22}=x_{22}k_{11}+x_{23}k_{12}+x_{32}k_{21}+x_{33}k_{22}\n> $$\n> 第$l$层的梯度误差为$\\delta^l$，反向传导：\n> $$\n> \\frac{\\partial{E}}{\\partial{k^l}}=\\frac{\\partial{E}}{\\partial{z^l}}\\frac{\\partial{z^l}}{\\partial{k^l}}=\\delta^l\\frac{z^l}{k^l}\n> $$\n> 因此对于卷积核$k^l$的梯度为第$l$层的敏感度（梯度）乘上$\\frac{\\partial{z^l}}{\\partial{k^l}}$，分别计算可得\n> $$\n> \\bigtriangledown{k_{11}}=\\delta_{11}x_{11}+\\delta_{12}x_{22}+\\delta_{21}x_{21}+\\delta_{22}x_{22}\\\\\n> \\bigtriangledown{k_{12}}=\\delta_{11}x_{12}+\\delta_{12}x_{13}+\\delta_{21}x_{22}+\\delta_{22}x_{23}\\\\\n> \\bigtriangledown{k_{21}}=\\delta_{11}x_{21}+\\delta_{12}x_{22}+\\delta_{21}x_{31}+\\delta_{22}x_{32}\\\\\n> \\bigtriangledown{k_{22}}=\\delta_{11}x_{22}+\\delta_{12}x_{23}+\\delta_{21}x_{32}+\\delta_{22}x_{33}\n> $$\n> 上面4个式子用矩阵卷积形式表示：\n> $$\n> \\left( \\begin{array}{}\n> x_{11}&x_{12}&x_{13}\\\\\n> x_{21}&x_{22}&x_{23}\\\\\n> x_{31}&x_{32}&x_{33}\n> \\end{array}\n> \\right)\n> *\n> \\left( \\begin{array}{}\n> \\delta_{11}&\\delta_{12}\\\\\n> \\delta_{21}&\\delta_{22}\n> \\end{array}\n> \\right)\n> =\n> \\left( \\begin{array}{}\n> \\bigtriangledown k_{11}&\\bigtriangledown k_{12}\\\\\n> \\bigtriangledown k_{21}&\\bigtriangledown k_{22}\n> \\end{array}\n> \\right)\n> $$\n> 公式化表达为：\n> $$\n> \\frac{\\partial{E}}{\\partial{k^l}}=x^{l-1}*\\delta^l\n> $$\n>\n>\n> 这里需要注意，在论文中进行了两次旋转，这是因为在MATLAB中conv2函数在计算卷积时除了会对矩阵进行“0”扩展，还会将卷积核进行旋转，然后再计算。例如：\n>\n> ```matlab\n> a =\n>      1     1     1\n>      1     1     1\n>      1     1     1\n> k =\n>      1     2     3\n>      4     5     6\n>      7     8     9\n>\n> >> convn(a,k,'full')\n> ans =\n>\n>      1     3     6     5     3\n>      5    12    21    16     9\n>     12    27    45    33    18\n>     11    24    39    28    15\n>      7    15    24    17     9\n> ```\n>\n> 因此在编写代码时需要注意保持一致（要么旋转，要么不旋转）。\n>\n> 在3.2节计算 $\\delta^l_j$ 也是同理\n>\n> 利用反向传播：\n> $$\n> \\frac{\\partial{E}}{\\partial{x^{l-1}}}=\\frac{\\partial{E}}{\\partial{z^l}}\\frac{\\partial{z^l}}{\\partial{x^{l-1}}}=\\delta^l\\frac{z^l}{x^{l-1}}\n> $$\n> 利用上式，可得：\n> $$\n> \\bigtriangledown{x_{11}}=\\delta_{11}k_{11}\\\\\n> \\bigtriangledown{x_{12}}=\\delta_{11}k_{12}+\\delta_{12}k_{11}\\\\\n> \\bigtriangledown{x_{13}}=\\delta_{12}k_{12}\\\\\n> \\bigtriangledown{x_{21}}=\\delta_{11}k_{21}+\\delta_{21}k_{11}\\\\\n> \\bigtriangledown{x_{22}}=\\delta_{11}k_{22}+\\delta_{12}k_{21}+\\delta_{21}k_{12}+\\delta_{22}k_{11}\\\\\n> \\bigtriangledown{x_{23}}=\\delta_{12}k_{22}+\\delta_{22}k_{12}\\\\\n> \\bigtriangledown{x_{31}}=\\delta_{21}k_{21}\\\\\n> \\bigtriangledown{x_{32}}=\\delta_{21}k_{22}+\\delta_{22}k_{21}\\\\\n> \\bigtriangledown{x_{33}}=\\delta_{22}k_{22}\n> $$\n> 上面九个式子用矩阵卷积形式表示：\n> $$\n> \\left( \\begin{array}{}\n> 0&0&0&0\\\\\n> 0&\\delta_{11}&\\delta_{12}&0\\\\\n> 0&\\delta_{21}&\\delta_{22}&0\\\\\n> 0&0&0&0\n> \\end{array}\n> \\right)\n> *\n> \\left( \\begin{array}{}\n> k_{22}&k_{21}\\\\\n> k_{12}&k_{11}\n> \\end{array}\n> \\right)\n> =\n> \\left( \\begin{array}{}\n> \\bigtriangledown x_{11}&\\bigtriangledown x_{12}&\\bigtriangledown x_{13}\\\\\n> \\bigtriangledown x_{21}&\\bigtriangledown x_{22}&\\bigtriangledown x_{23}\\\\\n> \\bigtriangledown x_{31}&\\bigtriangledown x_{32}&\\bigtriangledown x_{33}\n> \\end{array}\n> \\right)\n> $$\n> 公式化表达为：\n> $$\n> \\frac{\\partial{E}}{\\partial{x^{l-1}}}=\\delta^l * rot180(k^l)\n> $$\n>\n\n####3.3 学习特征maps组合 Learning Combinations of Feature Maps\n\n通常，对不同的maps进行卷积并对结果求和获得一个输出map，往往能取得不错的效果。在一些文献中，通过人工选择输入maps进行组合。但是我们可以尝试通过训练获得这个组合。让 $a_{ij}$ 表示得到第 $j$ 个输出map中第 $i$ 个输入map的权重，那么第 $j$ 个输出map的定义如下：\n$$\nx_j^l=f\\left( \\sum_{i=1}^{N_{in}}a_{ij}(x_i^{l-1}*k_i^l)+b_j^l\\right)\n$$\n同时需满足以下约束：\n$$\n\\sum_ia_ij=1,and \\space 0\\leq a_{ij}\\leq1\n$$\n这些约束可以通过将变量$a_{ij}$表示为softmax形式来加强：\n$$\na_{ij}=\\frac{exp(c_{ij})}{\\sum_kexp(c_{kj})}\n$$\n\n\n因为对于固定的 $j$ 来说，每组权值 $c_{ij}$ 都和其他组权值相独立，所以为了方便描述，我们把下标 $j$ 去掉，只考虑单个map的更新，其他map的更新方式是相同的过程，只是索引 $j$ 不同。\n\nsoftmax函数的导数：\n$$\n\\frac{\\partial a_k}{\\partial c_i}=\\delta_{ki}a_i-a_ia_k\\tag{8}\n$$\n这里的 $\\delta$ 是 kronecker delta，参照公式 (1) 我们可以得到在 $l$ 层误差对 $a_i$ 的偏导：\n$$\n\\frac{\\partial E}{\\partial a_i}=\\frac{\\partial E}{\\partial u^l}\\frac{\\partial u^l}{\\partial a_i}=\\sum_{u,v}(\\delta^l \\circ (x_i^{l-1}*k_i^l))_{uv}\n$$\n这里的$\\delta^l$对应具有输入 $u$ 的输出map的敏感度map。和前面一样，这里的卷积运算也是“valid”类型，目的是使结果和sensitivity map大小匹配。最后使用链式法则计算损失函数对权值 $c_i$ 的偏导数：\n$$\n\\begin{align}\n\\frac{\\partial E}{\\partial c_i}&=\\sum_k\\frac{\\partial E}{\\partial a_k}\\frac{\\partial a_k}{\\partial c_i}\\tag{9}\\\\\n&=a_i\\left( \\frac{\\partial E}{\\partial a_i}-\\sum_k\\frac{\\partial E}{\\partial a_k}a_k\\right)\\tag{10}\n\\end{align}\n$$\n 3.3.1 Enforcing Sparse Combinations\n\n为了给 $a_i$ 增加稀疏约束（限制一个输出map只与某些而不是全部输入map相连接），我们在代价函数中添加正则项惩罚 $\\Omega(a)$ 。这样就可以使某些权值趋于0，最后只有部分输入maps参与输出map相连接，代价函数为：\n$$\n\\widetilde{E}^n=E^n + \\lambda\\sum{i,j}|(a){ij}|\\tag{11}\n$$\n然后求这个正则项对 $c_i$梯度的影响：\n$$\n\\frac{\\partial\\Omega}{\\partial a_i}=\\lambda sign(a_i)\\tag{12}\n$$\n\n\n\n\n结合公式 (8) 的结果：\n$$\n\\begin{align}\n\\frac{\\partial\\Omega}{\\partial c_i}& = \\sum_k\\frac{\\partial\\Omega}{\\partial a_k}\\frac{\\partial a_k}{\\partial c_i} \\\\\n&=\n\\lambda\\left(|a_i|-a_i\\sum_k|a_k|\\right)\n\\end{align}\n$$\n最后结合公式 (13) 和公式 (9) ，可以求的权重 $c_i$ 的梯度：\n$$\n\\frac{\\partial\\widetilde{E}^n}{\\partial c_i} = \\frac{\\partial E^n}{\\partial c_i} +\\frac{\\partial \\Omega}{\\partial c_i}\n$$\n\n\n#### 3.4 加快MATLAB训练速度 Making it Fast with MATLAB\n\n> 与CNN关系不大，不做翻译，可看原文\n\n### 4 实际训练问题 Practical Training Issues (Incomplete)\n\n> 与CNN关系不大，不做翻译，可看原文\n\n\n$$\n\n$$\n","source":"_posts/CNN反向传播算法.md","raw":"---\ntitle: CNN反向传播算法\ndate: 2018-03-21 11:19:00\ntags: [deep learning]\ncategories: [artificial intelligence]\n---\n\n> 全文翻译自 Notes on Convolutional Neural Networks \n>\n> [论文链接](http://web.mit.edu/jvb/www/papers/cnn_tutorial.pdf)\n>\n> 释部分为自己的补充说明，可能存在错误\n\n<!--- more --->\n\n###1 介绍\n\n本文档讨论CNN的推导和实现，并加上一些简单的扩展。相比权值，卷积神经网络涉及到更多的连接。其架构本身实现了正则化。此外，CNN在某种程度上实现了平移不变性。这种特殊的神经网络假设我们希望通过数据驱动的方式学习过滤器，用来提取输入特征。推导是在二维的数据和卷积的基础上展开的，但可以很容易的推广到任意维度。\n\n我们先对经典的BP算法做一个描述，然后推导2D卷积神经网络中卷积层和子采样层（池化层）的BP权值更新方法。在整个过程中，我们强调了视线的效率，给出MATLAB代码片段配合方程讲解。然后讨论如何自动组合前一层的feature map，最后是feature map的稀疏组合。\n\n免责声明：这个笔记可能有错误。\n\n> feature map 就是特征矩阵，一张图片的每个像素点的RGB值可分别组成矩阵（R矩阵，G矩阵，B矩阵），这些就是feature map\n\n###2 全连接的反向传播算法\n\n一个典型的卷积神经网络，开始是卷积层和子采样层交替，最后几层（最接近输出）是全连接的一维网络（全连接层）。当你准备将2D feature map作为一维全连接网络的输入时，直接将所有特征连接为一个一维向量，然后就可以利用BP算法。因此在讨论CNN之前，这里先对BP算法进行解释。\n\n####2.1 前向传播 Feedforward Pass\n\n在接下来的推导中，我们考虑平方和误差函数，对于一个有c个类别和N个训练样本的多分类问题，计算公式如下：\n$$\nE^N=\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{k=1}^{c}(t_k^n-y_k^n)^2\n$$\n$t_k^n$是第n个样本对应标签的第k个维度的值，$y_k^n$表示第n个样本对应的网络输出的第k个值。对于多分类问题，输出一般为“one-of-c”形式。如果样本$x^n$属于第k类，那么$t_k^n$为正，$t^n$的其他维度即$t_{k\\neq1}^n$为0或负数。这取决于输出激活函数的选择，此处不做讨论。\n\n因为整个训练集的误差为每个训练样本的误差和，所以我们先讨论一个样本。第n个样本的误差如下：\n$$\nE^N=\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{k=1}^c(t_k^n-y_k^n)^2=\\frac{1}{2}||t^n-y^n||_2^2\\tag{1}\n$$\n在全连接层，我们可以根据反向传播规则计算E对网络权值的偏导数。用$l$代表当前层，输出层被指定为$L$层，输入层为第1层，那么当前层的输出为\n$$\nx^l=f(u^l), with \\space u^l=W^lx^{l-1}+b^l\\tag{2}\n$$\n\n\n输出激活函数$f(\\cdot)$一般选择logistic(sigmoid)函数$f(x)=(1+e^{-\\beta x})^{-1}$或者hyperbolic tangent函数$f(x)=a\\space tanh(bx)$。logistic函数将$[-\\infty,\\infty]$映射到$[0,1]$，hyperbolic tangent函数将$[-\\infty,\\infty]$映射到$[-a,a]$，因此hyperbolic tangent函数的输出平均值一般趋于0，sigmoid函数的输出平均为非零。但是如果将训练数据归一化到均值为0方差为1，可以在梯度下降时增加收敛。对于归一化的数据集来说，hyperbolic tangent函数是较好的选择。LeCun推荐$a=1.7159,b=2/3$，所以最大非线性点在$f(\\pm1)=\\pm1$，因此对预期训练目标进行正则化将会避免训练饱和。\n\n####2.2 反向传播 Backpropagation Pass\n\n通过网络反向传播的误差可以看作每个神经元关于偏差扰动的敏感度（sensitivities），通过链式法则可得：\n\n> 敏感度就是误差对目标的偏导数\n\n$$\n\\begin{equation}\n\\frac{\\partial{E}}{\\partial{b}}=\\frac{\\partial{E}}{\\partial{u}}\\frac{\\partial{u}}{\\partial{b}}=\\delta\n\\end{equation}\\tag{3}\n$$\n\n因为$\\frac{\\partial{u}}{\\partial{b}}=1$，所以bias的敏感度和误差对一个神经元的输入的偏导数是相等的。利用这个关系将高层误差反向传播到底层，使用下面的递推关系式：\n$$\n\\delta^t=(W^{l+1})^T\\delta^{l+1}\\circ f'(u^t)\\tag{4}\n$$\n其中$\\circ$表示对应位置元素相乘，从公式（1）可以看到，输出层神经元的敏感度会有一些不同：\n$$\n\\delta^L=f'(u^L)\\circ(y^n-t^n)\n$$\n最后，对每个神经元运用delta规则进行更行，即对神经元的输入使用delta进行缩放。用向量的形式表述就是：输入向量（前一层的输出）和灵敏度向量之间的一个外积：\n$$\n\\frac{\\partial{E}}{\\partial{W^l}}=x^{l-1}(\\delta^l)^T\\tag{5}\n$$\n\n$$\n\\bigtriangleup W^l=-\\eta\\frac{\\partial{E}}{\\partial{W^l}}\\tag{6}\n$$\n\n更新偏置值（bias）也是相同的原理，在实际中通常为每个权值赋予一个特定的学习率$\\eta_{ij}$。\n\n### 3 卷积神经网络 Convolutional Neural Networks\n\n>公式符号释意\n>\n>在本文中卷积核有多个，每个卷积核和feature map有多个维度，例如一张图片有RGB值，那么就有三个维度\n>\n>$i$----卷积核或者feature的第几维度\n>$j$----第几个卷积核\n>$up()$----上采样函数\n>$down()$----下采样函数\n>$l$----当前层\n\n\n\n通常卷积层和子采样层交替以减少计算时间并逐步建立空间和结构不变性。为了同时保持特异性，需要小的子采样因子。这并不是什么新鲜的概念，但简洁有效。这种模型在哺乳动物的视觉皮层非常常见，在过去十年，听觉神经科学发现，这些相同的设计范例可以在多种不同动物皮层的主要和带状听觉区域中找到。 分级分析和学习架构可能仍然是听觉领域的关键。\n\n####3.1 卷积层 Convolution Layers\n\n我们现在推导卷积层的BP更行。在一个卷积层，上一层的feature map与一个卷积核进行卷积运算，然后通过一个激活函数获得输出feature map。每个输出map可能是多个卷积结果的结合，公式表述：\n$$\nx_j^l=f\\left(\\sum_{i\\in M_j}x_i^{l-1}*k_{ij}^{l}+b_j^l\\right)\n$$\n\n\n$M_j$表示输入maps的集合，在MATLAB中卷积的运算需采用\"valid\"模式。通常情况下，输入maps选择一对或者三个。后面我们会讨论如何自动选择需要组合的特征map。每一个输出map都会加上一个偏执项$b$，但是对于一个特定的输出map，输入maps会和相同的卷积核进行卷积运算，也就是说，如果输出map $j$ 和 $k$ 都是由map $i$通过卷积运算的结果，那么对应的卷积核是不同的。\n\n>一张图片有RGB三个颜色通道，则对应的卷积核也是三维的，输出的feature map就是三个卷积结果的结合\n>\n>![CNN_02](http://oygov02sc.bkt.clouddn.com/CNN_02.gif)\n\n3.1.1 Computing the Gradients\n\n我们假设每个卷积层$l$后面都接一个子采样层 $l+1$。在使用BP算法计算 $l$ 层每个节点的敏感度时，我们需要先对下一层（$l+1$层）连接当前层（$l$层）的节点的敏感度求和，再乘以这些连接对应的权值（连接$l$层和$l+1$层的权值），最后乘以当前层$l$的该神经元节点的输入$u$的激活函数$f$的导数值。因为下采样的存在，采样层的一个像素（神经元）对应的灵敏度$\\delta$对应于卷积层（上一层）的输出map的一块像素（采样窗口大小）。因此，$l$层中的map的每个节点只与$l+1$层中相应map的一个节点连接。为了有效计算$l$层的敏感度，我们可以对下采样层的敏感，度map进行“上采样(upsample)”操作，这样可以使下采样层的敏感度map的大小和卷积层的map大小相同，然后将$l$层的激活值偏导map和$l+1$层的上采样敏感度map对应元素相乘。因为下采样层map的权值均是一个常数$\\beta$（见3.2节），所以我们只需要将上一步得到的结果乘以 $ \\beta$ 就可以得到$l$层的敏感度map $\\delta^l$。我们可以在卷积层的每个feature map进行相同的计算过程：\n$$\n\\delta_j^l=\\beta_j^{l+1}\\left(f'(u_j^l)\\circ up(\\delta_j^{l+1})\\right)\n$$\n其中的 $up(\\cdot)$表示上采样操作，如果下采样过程的采样因子为$n$，只需将每个像素点在水平方向和垂直方向复制$n$次就可以实现，一种有效的实现方式是利用 Kronecker product:\n$$\nup(x)=x\\otimes1_{n\\times n}\n$$\n\n\n>Ref:[克罗内克积](https://zh.wikipedia.org/zh/克罗内克积)\n\n现在对于一个给定的map，我们已经可以计算其敏感度map，然后我们可以简单的对敏感度map的所有节点求和计算出其bias（偏置项）梯度:\n$$\n\\frac{\\partial{E}}{\\partial{b_j}}=\\sum_{u,v}(\\delta_j^l)_{uv}\n$$\n最后，使用BP算法计算权重（卷积核）的梯度，很多权重在连接中是共享的，因此我们需要对所有与该权值有联系（权值共享的连接）的连接对该点求梯度，然后对这些梯度进行求和，就像计算bias梯度一样：\n$$\n\\frac{\\partial{E}}{\\partial{k_{ij}^l}}=\\sum_{u,v}(\\delta_j^l)_{uv}(p_i^{l-1})_{uv}\\tag{7}\n$$\n其中$(p_i^{l-1})_{uv}$是$x_i^{l-1}$在卷积运算时和$k_{ij}^l$按元素相乘得到输出map的$(u,v)$位置值的patch。看上去好像我们我刻意追踪输入map中哪些patch与输出map中的哪些像素（及其对应的敏感map）相对应，但是公式(7)可以通过卷积运算获得:\n$$\n\\frac{\\partial{E}}{\\partial{k_{ij}^l}}=rot180(conv2(x_i^{l-1},rot180(\\delta_j^l),'valid'))\n$$\n这里我们对$\\delta$敏感度map做旋转操作是为了这样就可以进行互相关计算而不是卷积，之后将输出旋转回来，以便当我们在前馈阶段执行卷积时，卷积核将具有正确的方向。\n\n####3.2 子采样层 Sub-sampling Layers\n\n子采样层对输入maps进行downsample操作（池化），输入有N个maps，输出也会有N个maps，只是每个maps变小了，公式表述如下：\n$$\nx_j^l=f\\left(\\beta_j^ldown(x_j^{l-1})+b_j^l\\right)\n$$\n\n\n其中的$down(\\cdot)$是下采样函数。典型的操作一般是对输入图像的不同$n\\times n$的块的像素进行求和。这样输出图像在两个维度上都缩小了n倍。每个输出map都有一个属于自己的乘性偏置β和一个加性偏置b。\n\n3.2.1 Computing the Gradients\n\n这里的困难在于如何计算敏感度maps。只要我们能得到敏感度maps，需要更新的只有bias参数 $\\beta$ 和 $b$ 。如果子采样层的下一层是全连接层，那么子采样层的敏感度maps只需要利用BP算法就可以容易获得。所以我们假设子采样层的上一层和下一层都是卷积层。\n\n当我们在3.1.1节计算卷积核梯度时，我们需要找到输入map中patch和输出map的像素的对应关系。这里就是必须找到当前层的敏感度map中那个patch与下一层的敏感度矩阵的的给定像素对应，这样就可以像公式 (4)那样应用$\\delta$递推。 当然，将输入patch和输出像素之间连接相乘的权重恰好是（旋转的）卷积核的权重。利用卷积可以实现该计算：\n$$\n\\delta_j^l=f'(u_j^l)\\circ conv2(\\delta_j^{l+1},rot180(k_j^{l+1}),full)\n$$\n如前所述，我们旋转内核是为了是卷积函数实施互相关计算。同时，我们需要对卷积边界进行“full”处理，Matlab的卷积函数会自动执行这个过程，对缺少的输入像素进行补零操作。\n\n现在我们可以很容易的计算 $b$ 和 $\\beta$ 的梯度，加性基 $b$ 的处理和之前一样，将敏感度map中所有元素相加即可 ：\n$$\n\\frac{\\partial E}{\\partial b_j}=\\sum_{u,v}(\\delta_j^l)_{uv}\n$$\n对于乘性偏置$\\beta$ ，参与了前向传播时下采样map的运算，所以在前向计算时将这些maps保存，这样避免了在反向传播时重复计算。定义：\n$$\nd_j^l=down(x_j^{l-1})\n$$\n\n\n$\\beta$ 梯度计算公式如下：\n$$\n\\frac{\\partial E}{\\partial \\beta_j}=\\sum_{u,v}(\\delta_j^l)\n$$\n\n> 补充说明：对rot180的解释\n>\n> 假设第$l-1$层输出$x^l$是一个3x3矩阵，第$l$层卷积核$k^l$是一个2x2的矩阵，步幅为1，输出一个2x2的矩阵$z^l$，则有（简化$b^l=0$，单卷积核)\n> $$\n> x^{l-1}*k^{l}=z^{l}\n> $$\n> 矩阵形式表达：\n> $$\n> \\left( \\begin{array}{}\n> x_{11}&x_{12}&x_{13}\\\\\n> x_{21}&x_{22}&x_{23}\\\\\n> x_{31}&x_{32}&x_{33}\n> \\end{array}\n> \\right)\n> *\n> \\left( \\begin{array}{}\n> k_{11}&k_{12}\\\\\n> k_{21}&k_{22}\n> \\end{array}\n> \\right)\n> =\n> \\left( \\begin{array}{}\n> z_{11}&z_{12}\\\\\n> z_{21}&z_{22}\n> \\end{array}\n> \\right)\n> $$\n> 根据卷积的定义可得：\n> $$\n> z_{11}=x_{11}k_{11}+x_{12}k_{12}+x_{21}k_{21}+x_{22}k_{22}\\\\\n> z_{12}=x_{12}k_{11}+x_{13}k_{12}+x_{22}k_{21}+x_{23}k_{22}\\\\\n> z_{21}=x_{21}k_{11}+x_{22}k_{12}+x_{31}k_{21}+x_{32}k_{22}\\\\\n> z_{22}=x_{22}k_{11}+x_{23}k_{12}+x_{32}k_{21}+x_{33}k_{22}\n> $$\n> 第$l$层的梯度误差为$\\delta^l$，反向传导：\n> $$\n> \\frac{\\partial{E}}{\\partial{k^l}}=\\frac{\\partial{E}}{\\partial{z^l}}\\frac{\\partial{z^l}}{\\partial{k^l}}=\\delta^l\\frac{z^l}{k^l}\n> $$\n> 因此对于卷积核$k^l$的梯度为第$l$层的敏感度（梯度）乘上$\\frac{\\partial{z^l}}{\\partial{k^l}}$，分别计算可得\n> $$\n> \\bigtriangledown{k_{11}}=\\delta_{11}x_{11}+\\delta_{12}x_{22}+\\delta_{21}x_{21}+\\delta_{22}x_{22}\\\\\n> \\bigtriangledown{k_{12}}=\\delta_{11}x_{12}+\\delta_{12}x_{13}+\\delta_{21}x_{22}+\\delta_{22}x_{23}\\\\\n> \\bigtriangledown{k_{21}}=\\delta_{11}x_{21}+\\delta_{12}x_{22}+\\delta_{21}x_{31}+\\delta_{22}x_{32}\\\\\n> \\bigtriangledown{k_{22}}=\\delta_{11}x_{22}+\\delta_{12}x_{23}+\\delta_{21}x_{32}+\\delta_{22}x_{33}\n> $$\n> 上面4个式子用矩阵卷积形式表示：\n> $$\n> \\left( \\begin{array}{}\n> x_{11}&x_{12}&x_{13}\\\\\n> x_{21}&x_{22}&x_{23}\\\\\n> x_{31}&x_{32}&x_{33}\n> \\end{array}\n> \\right)\n> *\n> \\left( \\begin{array}{}\n> \\delta_{11}&\\delta_{12}\\\\\n> \\delta_{21}&\\delta_{22}\n> \\end{array}\n> \\right)\n> =\n> \\left( \\begin{array}{}\n> \\bigtriangledown k_{11}&\\bigtriangledown k_{12}\\\\\n> \\bigtriangledown k_{21}&\\bigtriangledown k_{22}\n> \\end{array}\n> \\right)\n> $$\n> 公式化表达为：\n> $$\n> \\frac{\\partial{E}}{\\partial{k^l}}=x^{l-1}*\\delta^l\n> $$\n>\n>\n> 这里需要注意，在论文中进行了两次旋转，这是因为在MATLAB中conv2函数在计算卷积时除了会对矩阵进行“0”扩展，还会将卷积核进行旋转，然后再计算。例如：\n>\n> ```matlab\n> a =\n>      1     1     1\n>      1     1     1\n>      1     1     1\n> k =\n>      1     2     3\n>      4     5     6\n>      7     8     9\n>\n> >> convn(a,k,'full')\n> ans =\n>\n>      1     3     6     5     3\n>      5    12    21    16     9\n>     12    27    45    33    18\n>     11    24    39    28    15\n>      7    15    24    17     9\n> ```\n>\n> 因此在编写代码时需要注意保持一致（要么旋转，要么不旋转）。\n>\n> 在3.2节计算 $\\delta^l_j$ 也是同理\n>\n> 利用反向传播：\n> $$\n> \\frac{\\partial{E}}{\\partial{x^{l-1}}}=\\frac{\\partial{E}}{\\partial{z^l}}\\frac{\\partial{z^l}}{\\partial{x^{l-1}}}=\\delta^l\\frac{z^l}{x^{l-1}}\n> $$\n> 利用上式，可得：\n> $$\n> \\bigtriangledown{x_{11}}=\\delta_{11}k_{11}\\\\\n> \\bigtriangledown{x_{12}}=\\delta_{11}k_{12}+\\delta_{12}k_{11}\\\\\n> \\bigtriangledown{x_{13}}=\\delta_{12}k_{12}\\\\\n> \\bigtriangledown{x_{21}}=\\delta_{11}k_{21}+\\delta_{21}k_{11}\\\\\n> \\bigtriangledown{x_{22}}=\\delta_{11}k_{22}+\\delta_{12}k_{21}+\\delta_{21}k_{12}+\\delta_{22}k_{11}\\\\\n> \\bigtriangledown{x_{23}}=\\delta_{12}k_{22}+\\delta_{22}k_{12}\\\\\n> \\bigtriangledown{x_{31}}=\\delta_{21}k_{21}\\\\\n> \\bigtriangledown{x_{32}}=\\delta_{21}k_{22}+\\delta_{22}k_{21}\\\\\n> \\bigtriangledown{x_{33}}=\\delta_{22}k_{22}\n> $$\n> 上面九个式子用矩阵卷积形式表示：\n> $$\n> \\left( \\begin{array}{}\n> 0&0&0&0\\\\\n> 0&\\delta_{11}&\\delta_{12}&0\\\\\n> 0&\\delta_{21}&\\delta_{22}&0\\\\\n> 0&0&0&0\n> \\end{array}\n> \\right)\n> *\n> \\left( \\begin{array}{}\n> k_{22}&k_{21}\\\\\n> k_{12}&k_{11}\n> \\end{array}\n> \\right)\n> =\n> \\left( \\begin{array}{}\n> \\bigtriangledown x_{11}&\\bigtriangledown x_{12}&\\bigtriangledown x_{13}\\\\\n> \\bigtriangledown x_{21}&\\bigtriangledown x_{22}&\\bigtriangledown x_{23}\\\\\n> \\bigtriangledown x_{31}&\\bigtriangledown x_{32}&\\bigtriangledown x_{33}\n> \\end{array}\n> \\right)\n> $$\n> 公式化表达为：\n> $$\n> \\frac{\\partial{E}}{\\partial{x^{l-1}}}=\\delta^l * rot180(k^l)\n> $$\n>\n\n####3.3 学习特征maps组合 Learning Combinations of Feature Maps\n\n通常，对不同的maps进行卷积并对结果求和获得一个输出map，往往能取得不错的效果。在一些文献中，通过人工选择输入maps进行组合。但是我们可以尝试通过训练获得这个组合。让 $a_{ij}$ 表示得到第 $j$ 个输出map中第 $i$ 个输入map的权重，那么第 $j$ 个输出map的定义如下：\n$$\nx_j^l=f\\left( \\sum_{i=1}^{N_{in}}a_{ij}(x_i^{l-1}*k_i^l)+b_j^l\\right)\n$$\n同时需满足以下约束：\n$$\n\\sum_ia_ij=1,and \\space 0\\leq a_{ij}\\leq1\n$$\n这些约束可以通过将变量$a_{ij}$表示为softmax形式来加强：\n$$\na_{ij}=\\frac{exp(c_{ij})}{\\sum_kexp(c_{kj})}\n$$\n\n\n因为对于固定的 $j$ 来说，每组权值 $c_{ij}$ 都和其他组权值相独立，所以为了方便描述，我们把下标 $j$ 去掉，只考虑单个map的更新，其他map的更新方式是相同的过程，只是索引 $j$ 不同。\n\nsoftmax函数的导数：\n$$\n\\frac{\\partial a_k}{\\partial c_i}=\\delta_{ki}a_i-a_ia_k\\tag{8}\n$$\n这里的 $\\delta$ 是 kronecker delta，参照公式 (1) 我们可以得到在 $l$ 层误差对 $a_i$ 的偏导：\n$$\n\\frac{\\partial E}{\\partial a_i}=\\frac{\\partial E}{\\partial u^l}\\frac{\\partial u^l}{\\partial a_i}=\\sum_{u,v}(\\delta^l \\circ (x_i^{l-1}*k_i^l))_{uv}\n$$\n这里的$\\delta^l$对应具有输入 $u$ 的输出map的敏感度map。和前面一样，这里的卷积运算也是“valid”类型，目的是使结果和sensitivity map大小匹配。最后使用链式法则计算损失函数对权值 $c_i$ 的偏导数：\n$$\n\\begin{align}\n\\frac{\\partial E}{\\partial c_i}&=\\sum_k\\frac{\\partial E}{\\partial a_k}\\frac{\\partial a_k}{\\partial c_i}\\tag{9}\\\\\n&=a_i\\left( \\frac{\\partial E}{\\partial a_i}-\\sum_k\\frac{\\partial E}{\\partial a_k}a_k\\right)\\tag{10}\n\\end{align}\n$$\n 3.3.1 Enforcing Sparse Combinations\n\n为了给 $a_i$ 增加稀疏约束（限制一个输出map只与某些而不是全部输入map相连接），我们在代价函数中添加正则项惩罚 $\\Omega(a)$ 。这样就可以使某些权值趋于0，最后只有部分输入maps参与输出map相连接，代价函数为：\n$$\n\\widetilde{E}^n=E^n + \\lambda\\sum{i,j}|(a){ij}|\\tag{11}\n$$\n然后求这个正则项对 $c_i$梯度的影响：\n$$\n\\frac{\\partial\\Omega}{\\partial a_i}=\\lambda sign(a_i)\\tag{12}\n$$\n\n\n\n\n结合公式 (8) 的结果：\n$$\n\\begin{align}\n\\frac{\\partial\\Omega}{\\partial c_i}& = \\sum_k\\frac{\\partial\\Omega}{\\partial a_k}\\frac{\\partial a_k}{\\partial c_i} \\\\\n&=\n\\lambda\\left(|a_i|-a_i\\sum_k|a_k|\\right)\n\\end{align}\n$$\n最后结合公式 (13) 和公式 (9) ，可以求的权重 $c_i$ 的梯度：\n$$\n\\frac{\\partial\\widetilde{E}^n}{\\partial c_i} = \\frac{\\partial E^n}{\\partial c_i} +\\frac{\\partial \\Omega}{\\partial c_i}\n$$\n\n\n#### 3.4 加快MATLAB训练速度 Making it Fast with MATLAB\n\n> 与CNN关系不大，不做翻译，可看原文\n\n### 4 实际训练问题 Practical Training Issues (Incomplete)\n\n> 与CNN关系不大，不做翻译，可看原文\n\n\n$$\n\n$$\n","slug":"CNN反向传播算法","published":1,"updated":"2018-04-28T09:34:51.088Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owbp0005fb9lg5l30bv2","content":"<blockquote>\n<p>全文翻译自 Notes on Convolutional Neural Networks </p>\n<p><a href=\"http://web.mit.edu/jvb/www/papers/cnn_tutorial.pdf\" target=\"_blank\" rel=\"noopener\">论文链接</a></p>\n<p>释部分为自己的补充说明，可能存在错误</p>\n</blockquote>\n<a id=\"more\"></a>\n<h3 id=\"1-介绍\"><a href=\"#1-介绍\" class=\"headerlink\" title=\"1 介绍\"></a>1 介绍</h3><p>本文档讨论CNN的推导和实现，并加上一些简单的扩展。相比权值，卷积神经网络涉及到更多的连接。其架构本身实现了正则化。此外，CNN在某种程度上实现了平移不变性。这种特殊的神经网络假设我们希望通过数据驱动的方式学习过滤器，用来提取输入特征。推导是在二维的数据和卷积的基础上展开的，但可以很容易的推广到任意维度。</p>\n<p>我们先对经典的BP算法做一个描述，然后推导2D卷积神经网络中卷积层和子采样层（池化层）的BP权值更新方法。在整个过程中，我们强调了视线的效率，给出MATLAB代码片段配合方程讲解。然后讨论如何自动组合前一层的feature map，最后是feature map的稀疏组合。</p>\n<p>免责声明：这个笔记可能有错误。</p>\n<blockquote>\n<p>feature map 就是特征矩阵，一张图片的每个像素点的RGB值可分别组成矩阵（R矩阵，G矩阵，B矩阵），这些就是feature map</p>\n</blockquote>\n<h3 id=\"2-全连接的反向传播算法\"><a href=\"#2-全连接的反向传播算法\" class=\"headerlink\" title=\"2 全连接的反向传播算法\"></a>2 全连接的反向传播算法</h3><p>一个典型的卷积神经网络，开始是卷积层和子采样层交替，最后几层（最接近输出）是全连接的一维网络（全连接层）。当你准备将2D feature map作为一维全连接网络的输入时，直接将所有特征连接为一个一维向量，然后就可以利用BP算法。因此在讨论CNN之前，这里先对BP算法进行解释。</p>\n<h4 id=\"2-1-前向传播-Feedforward-Pass\"><a href=\"#2-1-前向传播-Feedforward-Pass\" class=\"headerlink\" title=\"2.1 前向传播 Feedforward Pass\"></a>2.1 前向传播 Feedforward Pass</h4><p>在接下来的推导中，我们考虑平方和误差函数，对于一个有c个类别和N个训练样本的多分类问题，计算公式如下：</p>\n<script type=\"math/tex; mode=display\">\nE^N=\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{k=1}^{c}(t_k^n-y_k^n)^2</script><p>$t_k^n$是第n个样本对应标签的第k个维度的值，$y_k^n$表示第n个样本对应的网络输出的第k个值。对于多分类问题，输出一般为“one-of-c”形式。如果样本$x^n$属于第k类，那么$t_k^n$为正，$t^n$的其他维度即$t_{k\\neq1}^n$为0或负数。这取决于输出激活函数的选择，此处不做讨论。</p>\n<p>因为整个训练集的误差为每个训练样本的误差和，所以我们先讨论一个样本。第n个样本的误差如下：</p>\n<script type=\"math/tex; mode=display\">\nE^N=\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{k=1}^c(t_k^n-y_k^n)^2=\\frac{1}{2}||t^n-y^n||_2^2\\tag{1}</script><p>在全连接层，我们可以根据反向传播规则计算E对网络权值的偏导数。用$l$代表当前层，输出层被指定为$L$层，输入层为第1层，那么当前层的输出为</p>\n<script type=\"math/tex; mode=display\">\nx^l=f(u^l), with \\space u^l=W^lx^{l-1}+b^l\\tag{2}</script><p>输出激活函数$f(\\cdot)$一般选择logistic(sigmoid)函数$f(x)=(1+e^{-\\beta x})^{-1}$或者hyperbolic tangent函数$f(x)=a\\space tanh(bx)$。logistic函数将$[-\\infty,\\infty]$映射到$[0,1]$，hyperbolic tangent函数将$[-\\infty,\\infty]$映射到$[-a,a]$，因此hyperbolic tangent函数的输出平均值一般趋于0，sigmoid函数的输出平均为非零。但是如果将训练数据归一化到均值为0方差为1，可以在梯度下降时增加收敛。对于归一化的数据集来说，hyperbolic tangent函数是较好的选择。LeCun推荐$a=1.7159,b=2/3$，所以最大非线性点在$f(\\pm1)=\\pm1$，因此对预期训练目标进行正则化将会避免训练饱和。</p>\n<h4 id=\"2-2-反向传播-Backpropagation-Pass\"><a href=\"#2-2-反向传播-Backpropagation-Pass\" class=\"headerlink\" title=\"2.2 反向传播 Backpropagation Pass\"></a>2.2 反向传播 Backpropagation Pass</h4><p>通过网络反向传播的误差可以看作每个神经元关于偏差扰动的敏感度（sensitivities），通过链式法则可得：</p>\n<blockquote>\n<p>敏感度就是误差对目标的偏导数</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\frac{\\partial{E}}{\\partial{b}}=\\frac{\\partial{E}}{\\partial{u}}\\frac{\\partial{u}}{\\partial{b}}=\\delta\n\\end{equation}\\tag{3}</script><p>因为$\\frac{\\partial{u}}{\\partial{b}}=1$，所以bias的敏感度和误差对一个神经元的输入的偏导数是相等的。利用这个关系将高层误差反向传播到底层，使用下面的递推关系式：</p>\n<script type=\"math/tex; mode=display\">\n\\delta^t=(W^{l+1})^T\\delta^{l+1}\\circ f'(u^t)\\tag{4}</script><p>其中$\\circ$表示对应位置元素相乘，从公式（1）可以看到，输出层神经元的敏感度会有一些不同：</p>\n<script type=\"math/tex; mode=display\">\n\\delta^L=f'(u^L)\\circ(y^n-t^n)</script><p>最后，对每个神经元运用delta规则进行更行，即对神经元的输入使用delta进行缩放。用向量的形式表述就是：输入向量（前一层的输出）和灵敏度向量之间的一个外积：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{W^l}}=x^{l-1}(\\delta^l)^T\\tag{5}</script><script type=\"math/tex; mode=display\">\n\\bigtriangleup W^l=-\\eta\\frac{\\partial{E}}{\\partial{W^l}}\\tag{6}</script><p>更新偏置值（bias）也是相同的原理，在实际中通常为每个权值赋予一个特定的学习率$\\eta_{ij}$。</p>\n<h3 id=\"3-卷积神经网络-Convolutional-Neural-Networks\"><a href=\"#3-卷积神经网络-Convolutional-Neural-Networks\" class=\"headerlink\" title=\"3 卷积神经网络 Convolutional Neural Networks\"></a>3 卷积神经网络 Convolutional Neural Networks</h3><blockquote>\n<p>公式符号释意</p>\n<p>在本文中卷积核有多个，每个卷积核和feature map有多个维度，例如一张图片有RGB值，那么就有三个维度</p>\n<p>$i$——卷积核或者feature的第几维度<br>$j$——第几个卷积核<br>$up()$——上采样函数<br>$down()$——下采样函数<br>$l$——当前层</p>\n</blockquote>\n<p>通常卷积层和子采样层交替以减少计算时间并逐步建立空间和结构不变性。为了同时保持特异性，需要小的子采样因子。这并不是什么新鲜的概念，但简洁有效。这种模型在哺乳动物的视觉皮层非常常见，在过去十年，听觉神经科学发现，这些相同的设计范例可以在多种不同动物皮层的主要和带状听觉区域中找到。 分级分析和学习架构可能仍然是听觉领域的关键。</p>\n<h4 id=\"3-1-卷积层-Convolution-Layers\"><a href=\"#3-1-卷积层-Convolution-Layers\" class=\"headerlink\" title=\"3.1 卷积层 Convolution Layers\"></a>3.1 卷积层 Convolution Layers</h4><p>我们现在推导卷积层的BP更行。在一个卷积层，上一层的feature map与一个卷积核进行卷积运算，然后通过一个激活函数获得输出feature map。每个输出map可能是多个卷积结果的结合，公式表述：</p>\n<script type=\"math/tex; mode=display\">\nx_j^l=f\\left(\\sum_{i\\in M_j}x_i^{l-1}*k_{ij}^{l}+b_j^l\\right)</script><p>$M_j$表示输入maps的集合，在MATLAB中卷积的运算需采用”valid”模式。通常情况下，输入maps选择一对或者三个。后面我们会讨论如何自动选择需要组合的特征map。每一个输出map都会加上一个偏执项$b$，但是对于一个特定的输出map，输入maps会和相同的卷积核进行卷积运算，也就是说，如果输出map $j$ 和 $k$ 都是由map $i$通过卷积运算的结果，那么对应的卷积核是不同的。</p>\n<blockquote>\n<p>一张图片有RGB三个颜色通道，则对应的卷积核也是三维的，输出的feature map就是三个卷积结果的结合</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/CNN_02.gif\" alt=\"CNN_02\"></p>\n</blockquote>\n<p>3.1.1 Computing the Gradients</p>\n<p>我们假设每个卷积层$l$后面都接一个子采样层 $l+1$。在使用BP算法计算 $l$ 层每个节点的敏感度时，我们需要先对下一层（$l+1$层）连接当前层（$l$层）的节点的敏感度求和，再乘以这些连接对应的权值（连接$l$层和$l+1$层的权值），最后乘以当前层$l$的该神经元节点的输入$u$的激活函数$f$的导数值。因为下采样的存在，采样层的一个像素（神经元）对应的灵敏度$\\delta$对应于卷积层（上一层）的输出map的一块像素（采样窗口大小）。因此，$l$层中的map的每个节点只与$l+1$层中相应map的一个节点连接。为了有效计算$l$层的敏感度，我们可以对下采样层的敏感，度map进行“上采样(upsample)”操作，这样可以使下采样层的敏感度map的大小和卷积层的map大小相同，然后将$l$层的激活值偏导map和$l+1$层的上采样敏感度map对应元素相乘。因为下采样层map的权值均是一个常数$\\beta$（见3.2节），所以我们只需要将上一步得到的结果乘以 $ \\beta$ 就可以得到$l$层的敏感度map $\\delta^l$。我们可以在卷积层的每个feature map进行相同的计算过程：</p>\n<script type=\"math/tex; mode=display\">\n\\delta_j^l=\\beta_j^{l+1}\\left(f'(u_j^l)\\circ up(\\delta_j^{l+1})\\right)</script><p>其中的 $up(\\cdot)$表示上采样操作，如果下采样过程的采样因子为$n$，只需将每个像素点在水平方向和垂直方向复制$n$次就可以实现，一种有效的实现方式是利用 Kronecker product:</p>\n<script type=\"math/tex; mode=display\">\nup(x)=x\\otimes1_{n\\times n}</script><blockquote>\n<p>Ref:<a href=\"https://zh.wikipedia.org/zh/克罗内克积\" target=\"_blank\" rel=\"noopener\">克罗内克积</a></p>\n</blockquote>\n<p>现在对于一个给定的map，我们已经可以计算其敏感度map，然后我们可以简单的对敏感度map的所有节点求和计算出其bias（偏置项）梯度:</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{b_j}}=\\sum_{u,v}(\\delta_j^l)_{uv}</script><p>最后，使用BP算法计算权重（卷积核）的梯度，很多权重在连接中是共享的，因此我们需要对所有与该权值有联系（权值共享的连接）的连接对该点求梯度，然后对这些梯度进行求和，就像计算bias梯度一样：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{k_{ij}^l}}=\\sum_{u,v}(\\delta_j^l)_{uv}(p_i^{l-1})_{uv}\\tag{7}</script><p>其中$(p_i^{l-1})_{uv}$是$x_i^{l-1}$在卷积运算时和$k_{ij}^l$按元素相乘得到输出map的$(u,v)$位置值的patch。看上去好像我们我刻意追踪输入map中哪些patch与输出map中的哪些像素（及其对应的敏感map）相对应，但是公式(7)可以通过卷积运算获得:</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{k_{ij}^l}}=rot180(conv2(x_i^{l-1},rot180(\\delta_j^l),'valid'))</script><p>这里我们对$\\delta$敏感度map做旋转操作是为了这样就可以进行互相关计算而不是卷积，之后将输出旋转回来，以便当我们在前馈阶段执行卷积时，卷积核将具有正确的方向。</p>\n<h4 id=\"3-2-子采样层-Sub-sampling-Layers\"><a href=\"#3-2-子采样层-Sub-sampling-Layers\" class=\"headerlink\" title=\"3.2 子采样层 Sub-sampling Layers\"></a>3.2 子采样层 Sub-sampling Layers</h4><p>子采样层对输入maps进行downsample操作（池化），输入有N个maps，输出也会有N个maps，只是每个maps变小了，公式表述如下：</p>\n<script type=\"math/tex; mode=display\">\nx_j^l=f\\left(\\beta_j^ldown(x_j^{l-1})+b_j^l\\right)</script><p>其中的$down(\\cdot)$是下采样函数。典型的操作一般是对输入图像的不同$n\\times n$的块的像素进行求和。这样输出图像在两个维度上都缩小了n倍。每个输出map都有一个属于自己的乘性偏置β和一个加性偏置b。</p>\n<p>3.2.1 Computing the Gradients</p>\n<p>这里的困难在于如何计算敏感度maps。只要我们能得到敏感度maps，需要更新的只有bias参数 $\\beta$ 和 $b$ 。如果子采样层的下一层是全连接层，那么子采样层的敏感度maps只需要利用BP算法就可以容易获得。所以我们假设子采样层的上一层和下一层都是卷积层。</p>\n<p>当我们在3.1.1节计算卷积核梯度时，我们需要找到输入map中patch和输出map的像素的对应关系。这里就是必须找到当前层的敏感度map中那个patch与下一层的敏感度矩阵的的给定像素对应，这样就可以像公式 (4)那样应用$\\delta$递推。 当然，将输入patch和输出像素之间连接相乘的权重恰好是（旋转的）卷积核的权重。利用卷积可以实现该计算：</p>\n<script type=\"math/tex; mode=display\">\n\\delta_j^l=f'(u_j^l)\\circ conv2(\\delta_j^{l+1},rot180(k_j^{l+1}),full)</script><p>如前所述，我们旋转内核是为了是卷积函数实施互相关计算。同时，我们需要对卷积边界进行“full”处理，Matlab的卷积函数会自动执行这个过程，对缺少的输入像素进行补零操作。</p>\n<p>现在我们可以很容易的计算 $b$ 和 $\\beta$ 的梯度，加性基 $b$ 的处理和之前一样，将敏感度map中所有元素相加即可 ：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial E}{\\partial b_j}=\\sum_{u,v}(\\delta_j^l)_{uv}</script><p>对于乘性偏置$\\beta$ ，参与了前向传播时下采样map的运算，所以在前向计算时将这些maps保存，这样避免了在反向传播时重复计算。定义：</p>\n<script type=\"math/tex; mode=display\">\nd_j^l=down(x_j^{l-1})</script><p>$\\beta$ 梯度计算公式如下：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial E}{\\partial \\beta_j}=\\sum_{u,v}(\\delta_j^l)</script><blockquote>\n<p>补充说明：对rot180的解释</p>\n<p>假设第$l-1$层输出$x^l$是一个3x3矩阵，第$l$层卷积核$k^l$是一个2x2的矩阵，步幅为1，输出一个2x2的矩阵$z^l$，则有（简化$b^l=0$，单卷积核)</p>\n<script type=\"math/tex; mode=display\">\nx^{l-1}*k^{l}=z^{l}</script><p>矩阵形式表达：</p>\n<script type=\"math/tex; mode=display\">\n\\left( \\begin{array}{}\nx_{11}&x_{12}&x_{13}\\\\\nx_{21}&x_{22}&x_{23}\\\\\nx_{31}&x_{32}&x_{33}\n\\end{array}\n\\right)\n*\n\\left( \\begin{array}{}\nk_{11}&k_{12}\\\\\nk_{21}&k_{22}\n\\end{array}\n\\right)\n=\n\\left( \\begin{array}{}\nz_{11}&z_{12}\\\\\nz_{21}&z_{22}\n\\end{array}\n\\right)</script><p>根据卷积的定义可得：</p>\n<script type=\"math/tex; mode=display\">\nz_{11}=x_{11}k_{11}+x_{12}k_{12}+x_{21}k_{21}+x_{22}k_{22}\\\\\nz_{12}=x_{12}k_{11}+x_{13}k_{12}+x_{22}k_{21}+x_{23}k_{22}\\\\\nz_{21}=x_{21}k_{11}+x_{22}k_{12}+x_{31}k_{21}+x_{32}k_{22}\\\\\nz_{22}=x_{22}k_{11}+x_{23}k_{12}+x_{32}k_{21}+x_{33}k_{22}</script><p>第$l$层的梯度误差为$\\delta^l$，反向传导：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{k^l}}=\\frac{\\partial{E}}{\\partial{z^l}}\\frac{\\partial{z^l}}{\\partial{k^l}}=\\delta^l\\frac{z^l}{k^l}</script><p>因此对于卷积核$k^l$的梯度为第$l$层的敏感度（梯度）乘上$\\frac{\\partial{z^l}}{\\partial{k^l}}$，分别计算可得</p>\n<script type=\"math/tex; mode=display\">\n\\bigtriangledown{k_{11}}=\\delta_{11}x_{11}+\\delta_{12}x_{22}+\\delta_{21}x_{21}+\\delta_{22}x_{22}\\\\\n\\bigtriangledown{k_{12}}=\\delta_{11}x_{12}+\\delta_{12}x_{13}+\\delta_{21}x_{22}+\\delta_{22}x_{23}\\\\\n\\bigtriangledown{k_{21}}=\\delta_{11}x_{21}+\\delta_{12}x_{22}+\\delta_{21}x_{31}+\\delta_{22}x_{32}\\\\\n\\bigtriangledown{k_{22}}=\\delta_{11}x_{22}+\\delta_{12}x_{23}+\\delta_{21}x_{32}+\\delta_{22}x_{33}</script><p>上面4个式子用矩阵卷积形式表示：</p>\n<script type=\"math/tex; mode=display\">\n\\left( \\begin{array}{}\nx_{11}&x_{12}&x_{13}\\\\\nx_{21}&x_{22}&x_{23}\\\\\nx_{31}&x_{32}&x_{33}\n\\end{array}\n\\right)\n*\n\\left( \\begin{array}{}\n\\delta_{11}&\\delta_{12}\\\\\n\\delta_{21}&\\delta_{22}\n\\end{array}\n\\right)\n=\n\\left( \\begin{array}{}\n\\bigtriangledown k_{11}&\\bigtriangledown k_{12}\\\\\n\\bigtriangledown k_{21}&\\bigtriangledown k_{22}\n\\end{array}\n\\right)</script><p>公式化表达为：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{k^l}}=x^{l-1}*\\delta^l</script><p>这里需要注意，在论文中进行了两次旋转，这是因为在MATLAB中conv2函数在计算卷积时除了会对矩阵进行“0”扩展，还会将卷积核进行旋转，然后再计算。例如：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; a =</span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">1</span>     <span class=\"number\">1</span></span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">1</span>     <span class=\"number\">1</span></span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">1</span>     <span class=\"number\">1</span></span><br><span class=\"line\">&gt; k =</span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">2</span>     <span class=\"number\">3</span></span><br><span class=\"line\">&gt;      <span class=\"number\">4</span>     <span class=\"number\">5</span>     <span class=\"number\">6</span></span><br><span class=\"line\">&gt;      <span class=\"number\">7</span>     <span class=\"number\">8</span>     <span class=\"number\">9</span></span><br><span class=\"line\">&gt;</span><br><span class=\"line\">&gt; &gt;&gt; convn(a,k,<span class=\"string\">'full'</span>)</span><br><span class=\"line\">&gt; <span class=\"built_in\">ans</span> =</span><br><span class=\"line\">&gt;</span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">3</span>     <span class=\"number\">6</span>     <span class=\"number\">5</span>     <span class=\"number\">3</span></span><br><span class=\"line\">&gt;      <span class=\"number\">5</span>    <span class=\"number\">12</span>    <span class=\"number\">21</span>    <span class=\"number\">16</span>     <span class=\"number\">9</span></span><br><span class=\"line\">&gt;     <span class=\"number\">12</span>    <span class=\"number\">27</span>    <span class=\"number\">45</span>    <span class=\"number\">33</span>    <span class=\"number\">18</span></span><br><span class=\"line\">&gt;     <span class=\"number\">11</span>    <span class=\"number\">24</span>    <span class=\"number\">39</span>    <span class=\"number\">28</span>    <span class=\"number\">15</span></span><br><span class=\"line\">&gt;      <span class=\"number\">7</span>    <span class=\"number\">15</span>    <span class=\"number\">24</span>    <span class=\"number\">17</span>     <span class=\"number\">9</span></span><br><span class=\"line\">&gt;</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>&gt;</p>\n<blockquote>\n<p>因此在编写代码时需要注意保持一致（要么旋转，要么不旋转）。</p>\n<p>在3.2节计算 $\\delta^l_j$ 也是同理</p>\n<p>利用反向传播：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{x^{l-1}}}=\\frac{\\partial{E}}{\\partial{z^l}}\\frac{\\partial{z^l}}{\\partial{x^{l-1}}}=\\delta^l\\frac{z^l}{x^{l-1}}</script><p>利用上式，可得：</p>\n<script type=\"math/tex; mode=display\">\n\\bigtriangledown{x_{11}}=\\delta_{11}k_{11}\\\\\n\\bigtriangledown{x_{12}}=\\delta_{11}k_{12}+\\delta_{12}k_{11}\\\\\n\\bigtriangledown{x_{13}}=\\delta_{12}k_{12}\\\\\n\\bigtriangledown{x_{21}}=\\delta_{11}k_{21}+\\delta_{21}k_{11}\\\\\n\\bigtriangledown{x_{22}}=\\delta_{11}k_{22}+\\delta_{12}k_{21}+\\delta_{21}k_{12}+\\delta_{22}k_{11}\\\\\n\\bigtriangledown{x_{23}}=\\delta_{12}k_{22}+\\delta_{22}k_{12}\\\\\n\\bigtriangledown{x_{31}}=\\delta_{21}k_{21}\\\\\n\\bigtriangledown{x_{32}}=\\delta_{21}k_{22}+\\delta_{22}k_{21}\\\\\n\\bigtriangledown{x_{33}}=\\delta_{22}k_{22}</script><p>上面九个式子用矩阵卷积形式表示：</p>\n<script type=\"math/tex; mode=display\">\n\\left( \\begin{array}{}\n0&0&0&0\\\\\n0&\\delta_{11}&\\delta_{12}&0\\\\\n0&\\delta_{21}&\\delta_{22}&0\\\\\n0&0&0&0\n\\end{array}\n\\right)\n*\n\\left( \\begin{array}{}\nk_{22}&k_{21}\\\\\nk_{12}&k_{11}\n\\end{array}\n\\right)\n=\n\\left( \\begin{array}{}\n\\bigtriangledown x_{11}&\\bigtriangledown x_{12}&\\bigtriangledown x_{13}\\\\\n\\bigtriangledown x_{21}&\\bigtriangledown x_{22}&\\bigtriangledown x_{23}\\\\\n\\bigtriangledown x_{31}&\\bigtriangledown x_{32}&\\bigtriangledown x_{33}\n\\end{array}\n\\right)</script><p>公式化表达为：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{x^{l-1}}}=\\delta^l * rot180(k^l)</script></blockquote>\n<h4 id=\"3-3-学习特征maps组合-Learning-Combinations-of-Feature-Maps\"><a href=\"#3-3-学习特征maps组合-Learning-Combinations-of-Feature-Maps\" class=\"headerlink\" title=\"3.3 学习特征maps组合 Learning Combinations of Feature Maps\"></a>3.3 学习特征maps组合 Learning Combinations of Feature Maps</h4><p>通常，对不同的maps进行卷积并对结果求和获得一个输出map，往往能取得不错的效果。在一些文献中，通过人工选择输入maps进行组合。但是我们可以尝试通过训练获得这个组合。让 $a_{ij}$ 表示得到第 $j$ 个输出map中第 $i$ 个输入map的权重，那么第 $j$ 个输出map的定义如下：</p>\n<script type=\"math/tex; mode=display\">\nx_j^l=f\\left( \\sum_{i=1}^{N_{in}}a_{ij}(x_i^{l-1}*k_i^l)+b_j^l\\right)</script><p>同时需满足以下约束：</p>\n<script type=\"math/tex; mode=display\">\n\\sum_ia_ij=1,and \\space 0\\leq a_{ij}\\leq1</script><p>这些约束可以通过将变量$a_{ij}$表示为softmax形式来加强：</p>\n<script type=\"math/tex; mode=display\">\na_{ij}=\\frac{exp(c_{ij})}{\\sum_kexp(c_{kj})}</script><p>因为对于固定的 $j$ 来说，每组权值 $c_{ij}$ 都和其他组权值相独立，所以为了方便描述，我们把下标 $j$ 去掉，只考虑单个map的更新，其他map的更新方式是相同的过程，只是索引 $j$ 不同。</p>\n<p>softmax函数的导数：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial a_k}{\\partial c_i}=\\delta_{ki}a_i-a_ia_k\\tag{8}</script><p>这里的 $\\delta$ 是 kronecker delta，参照公式 (1) 我们可以得到在 $l$ 层误差对 $a_i$ 的偏导：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial E}{\\partial a_i}=\\frac{\\partial E}{\\partial u^l}\\frac{\\partial u^l}{\\partial a_i}=\\sum_{u,v}(\\delta^l \\circ (x_i^{l-1}*k_i^l))_{uv}</script><p>这里的$\\delta^l$对应具有输入 $u$ 的输出map的敏感度map。和前面一样，这里的卷积运算也是“valid”类型，目的是使结果和sensitivity map大小匹配。最后使用链式法则计算损失函数对权值 $c_i$ 的偏导数：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\frac{\\partial E}{\\partial c_i}&=\\sum_k\\frac{\\partial E}{\\partial a_k}\\frac{\\partial a_k}{\\partial c_i}\\tag{9}\\\\\n&=a_i\\left( \\frac{\\partial E}{\\partial a_i}-\\sum_k\\frac{\\partial E}{\\partial a_k}a_k\\right)\\tag{10}\n\\end{align}</script><p> 3.3.1 Enforcing Sparse Combinations</p>\n<p>为了给 $a_i$ 增加稀疏约束（限制一个输出map只与某些而不是全部输入map相连接），我们在代价函数中添加正则项惩罚 $\\Omega(a)$ 。这样就可以使某些权值趋于0，最后只有部分输入maps参与输出map相连接，代价函数为：</p>\n<script type=\"math/tex; mode=display\">\n\\widetilde{E}^n=E^n + \\lambda\\sum{i,j}|(a){ij}|\\tag{11}</script><p>然后求这个正则项对 $c_i$梯度的影响：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial\\Omega}{\\partial a_i}=\\lambda sign(a_i)\\tag{12}</script><p>结合公式 (8) 的结果：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\frac{\\partial\\Omega}{\\partial c_i}& = \\sum_k\\frac{\\partial\\Omega}{\\partial a_k}\\frac{\\partial a_k}{\\partial c_i} \\\\\n&=\n\\lambda\\left(|a_i|-a_i\\sum_k|a_k|\\right)\n\\end{align}</script><p>最后结合公式 (13) 和公式 (9) ，可以求的权重 $c_i$ 的梯度：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial\\widetilde{E}^n}{\\partial c_i} = \\frac{\\partial E^n}{\\partial c_i} +\\frac{\\partial \\Omega}{\\partial c_i}</script><h4 id=\"3-4-加快MATLAB训练速度-Making-it-Fast-with-MATLAB\"><a href=\"#3-4-加快MATLAB训练速度-Making-it-Fast-with-MATLAB\" class=\"headerlink\" title=\"3.4 加快MATLAB训练速度 Making it Fast with MATLAB\"></a>3.4 加快MATLAB训练速度 Making it Fast with MATLAB</h4><blockquote>\n<p>与CNN关系不大，不做翻译，可看原文</p>\n</blockquote>\n<h3 id=\"4-实际训练问题-Practical-Training-Issues-Incomplete\"><a href=\"#4-实际训练问题-Practical-Training-Issues-Incomplete\" class=\"headerlink\" title=\"4 实际训练问题 Practical Training Issues (Incomplete)\"></a>4 实际训练问题 Practical Training Issues (Incomplete)</h3><blockquote>\n<p>与CNN关系不大，不做翻译，可看原文</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\n</script>","site":{"data":{}},"excerpt":"<blockquote>\n<p>全文翻译自 Notes on Convolutional Neural Networks </p>\n<p><a href=\"http://web.mit.edu/jvb/www/papers/cnn_tutorial.pdf\" target=\"_blank\" rel=\"noopener\">论文链接</a></p>\n<p>释部分为自己的补充说明，可能存在错误</p>\n</blockquote>","more":"<h3 id=\"1-介绍\"><a href=\"#1-介绍\" class=\"headerlink\" title=\"1 介绍\"></a>1 介绍</h3><p>本文档讨论CNN的推导和实现，并加上一些简单的扩展。相比权值，卷积神经网络涉及到更多的连接。其架构本身实现了正则化。此外，CNN在某种程度上实现了平移不变性。这种特殊的神经网络假设我们希望通过数据驱动的方式学习过滤器，用来提取输入特征。推导是在二维的数据和卷积的基础上展开的，但可以很容易的推广到任意维度。</p>\n<p>我们先对经典的BP算法做一个描述，然后推导2D卷积神经网络中卷积层和子采样层（池化层）的BP权值更新方法。在整个过程中，我们强调了视线的效率，给出MATLAB代码片段配合方程讲解。然后讨论如何自动组合前一层的feature map，最后是feature map的稀疏组合。</p>\n<p>免责声明：这个笔记可能有错误。</p>\n<blockquote>\n<p>feature map 就是特征矩阵，一张图片的每个像素点的RGB值可分别组成矩阵（R矩阵，G矩阵，B矩阵），这些就是feature map</p>\n</blockquote>\n<h3 id=\"2-全连接的反向传播算法\"><a href=\"#2-全连接的反向传播算法\" class=\"headerlink\" title=\"2 全连接的反向传播算法\"></a>2 全连接的反向传播算法</h3><p>一个典型的卷积神经网络，开始是卷积层和子采样层交替，最后几层（最接近输出）是全连接的一维网络（全连接层）。当你准备将2D feature map作为一维全连接网络的输入时，直接将所有特征连接为一个一维向量，然后就可以利用BP算法。因此在讨论CNN之前，这里先对BP算法进行解释。</p>\n<h4 id=\"2-1-前向传播-Feedforward-Pass\"><a href=\"#2-1-前向传播-Feedforward-Pass\" class=\"headerlink\" title=\"2.1 前向传播 Feedforward Pass\"></a>2.1 前向传播 Feedforward Pass</h4><p>在接下来的推导中，我们考虑平方和误差函数，对于一个有c个类别和N个训练样本的多分类问题，计算公式如下：</p>\n<script type=\"math/tex; mode=display\">\nE^N=\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{k=1}^{c}(t_k^n-y_k^n)^2</script><p>$t_k^n$是第n个样本对应标签的第k个维度的值，$y_k^n$表示第n个样本对应的网络输出的第k个值。对于多分类问题，输出一般为“one-of-c”形式。如果样本$x^n$属于第k类，那么$t_k^n$为正，$t^n$的其他维度即$t_{k\\neq1}^n$为0或负数。这取决于输出激活函数的选择，此处不做讨论。</p>\n<p>因为整个训练集的误差为每个训练样本的误差和，所以我们先讨论一个样本。第n个样本的误差如下：</p>\n<script type=\"math/tex; mode=display\">\nE^N=\\frac{1}{2}\\sum_{n=1}^{N}\\sum_{k=1}^c(t_k^n-y_k^n)^2=\\frac{1}{2}||t^n-y^n||_2^2\\tag{1}</script><p>在全连接层，我们可以根据反向传播规则计算E对网络权值的偏导数。用$l$代表当前层，输出层被指定为$L$层，输入层为第1层，那么当前层的输出为</p>\n<script type=\"math/tex; mode=display\">\nx^l=f(u^l), with \\space u^l=W^lx^{l-1}+b^l\\tag{2}</script><p>输出激活函数$f(\\cdot)$一般选择logistic(sigmoid)函数$f(x)=(1+e^{-\\beta x})^{-1}$或者hyperbolic tangent函数$f(x)=a\\space tanh(bx)$。logistic函数将$[-\\infty,\\infty]$映射到$[0,1]$，hyperbolic tangent函数将$[-\\infty,\\infty]$映射到$[-a,a]$，因此hyperbolic tangent函数的输出平均值一般趋于0，sigmoid函数的输出平均为非零。但是如果将训练数据归一化到均值为0方差为1，可以在梯度下降时增加收敛。对于归一化的数据集来说，hyperbolic tangent函数是较好的选择。LeCun推荐$a=1.7159,b=2/3$，所以最大非线性点在$f(\\pm1)=\\pm1$，因此对预期训练目标进行正则化将会避免训练饱和。</p>\n<h4 id=\"2-2-反向传播-Backpropagation-Pass\"><a href=\"#2-2-反向传播-Backpropagation-Pass\" class=\"headerlink\" title=\"2.2 反向传播 Backpropagation Pass\"></a>2.2 反向传播 Backpropagation Pass</h4><p>通过网络反向传播的误差可以看作每个神经元关于偏差扰动的敏感度（sensitivities），通过链式法则可得：</p>\n<blockquote>\n<p>敏感度就是误差对目标的偏导数</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\frac{\\partial{E}}{\\partial{b}}=\\frac{\\partial{E}}{\\partial{u}}\\frac{\\partial{u}}{\\partial{b}}=\\delta\n\\end{equation}\\tag{3}</script><p>因为$\\frac{\\partial{u}}{\\partial{b}}=1$，所以bias的敏感度和误差对一个神经元的输入的偏导数是相等的。利用这个关系将高层误差反向传播到底层，使用下面的递推关系式：</p>\n<script type=\"math/tex; mode=display\">\n\\delta^t=(W^{l+1})^T\\delta^{l+1}\\circ f'(u^t)\\tag{4}</script><p>其中$\\circ$表示对应位置元素相乘，从公式（1）可以看到，输出层神经元的敏感度会有一些不同：</p>\n<script type=\"math/tex; mode=display\">\n\\delta^L=f'(u^L)\\circ(y^n-t^n)</script><p>最后，对每个神经元运用delta规则进行更行，即对神经元的输入使用delta进行缩放。用向量的形式表述就是：输入向量（前一层的输出）和灵敏度向量之间的一个外积：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{W^l}}=x^{l-1}(\\delta^l)^T\\tag{5}</script><script type=\"math/tex; mode=display\">\n\\bigtriangleup W^l=-\\eta\\frac{\\partial{E}}{\\partial{W^l}}\\tag{6}</script><p>更新偏置值（bias）也是相同的原理，在实际中通常为每个权值赋予一个特定的学习率$\\eta_{ij}$。</p>\n<h3 id=\"3-卷积神经网络-Convolutional-Neural-Networks\"><a href=\"#3-卷积神经网络-Convolutional-Neural-Networks\" class=\"headerlink\" title=\"3 卷积神经网络 Convolutional Neural Networks\"></a>3 卷积神经网络 Convolutional Neural Networks</h3><blockquote>\n<p>公式符号释意</p>\n<p>在本文中卷积核有多个，每个卷积核和feature map有多个维度，例如一张图片有RGB值，那么就有三个维度</p>\n<p>$i$——卷积核或者feature的第几维度<br>$j$——第几个卷积核<br>$up()$——上采样函数<br>$down()$——下采样函数<br>$l$——当前层</p>\n</blockquote>\n<p>通常卷积层和子采样层交替以减少计算时间并逐步建立空间和结构不变性。为了同时保持特异性，需要小的子采样因子。这并不是什么新鲜的概念，但简洁有效。这种模型在哺乳动物的视觉皮层非常常见，在过去十年，听觉神经科学发现，这些相同的设计范例可以在多种不同动物皮层的主要和带状听觉区域中找到。 分级分析和学习架构可能仍然是听觉领域的关键。</p>\n<h4 id=\"3-1-卷积层-Convolution-Layers\"><a href=\"#3-1-卷积层-Convolution-Layers\" class=\"headerlink\" title=\"3.1 卷积层 Convolution Layers\"></a>3.1 卷积层 Convolution Layers</h4><p>我们现在推导卷积层的BP更行。在一个卷积层，上一层的feature map与一个卷积核进行卷积运算，然后通过一个激活函数获得输出feature map。每个输出map可能是多个卷积结果的结合，公式表述：</p>\n<script type=\"math/tex; mode=display\">\nx_j^l=f\\left(\\sum_{i\\in M_j}x_i^{l-1}*k_{ij}^{l}+b_j^l\\right)</script><p>$M_j$表示输入maps的集合，在MATLAB中卷积的运算需采用”valid”模式。通常情况下，输入maps选择一对或者三个。后面我们会讨论如何自动选择需要组合的特征map。每一个输出map都会加上一个偏执项$b$，但是对于一个特定的输出map，输入maps会和相同的卷积核进行卷积运算，也就是说，如果输出map $j$ 和 $k$ 都是由map $i$通过卷积运算的结果，那么对应的卷积核是不同的。</p>\n<blockquote>\n<p>一张图片有RGB三个颜色通道，则对应的卷积核也是三维的，输出的feature map就是三个卷积结果的结合</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/CNN_02.gif\" alt=\"CNN_02\"></p>\n</blockquote>\n<p>3.1.1 Computing the Gradients</p>\n<p>我们假设每个卷积层$l$后面都接一个子采样层 $l+1$。在使用BP算法计算 $l$ 层每个节点的敏感度时，我们需要先对下一层（$l+1$层）连接当前层（$l$层）的节点的敏感度求和，再乘以这些连接对应的权值（连接$l$层和$l+1$层的权值），最后乘以当前层$l$的该神经元节点的输入$u$的激活函数$f$的导数值。因为下采样的存在，采样层的一个像素（神经元）对应的灵敏度$\\delta$对应于卷积层（上一层）的输出map的一块像素（采样窗口大小）。因此，$l$层中的map的每个节点只与$l+1$层中相应map的一个节点连接。为了有效计算$l$层的敏感度，我们可以对下采样层的敏感，度map进行“上采样(upsample)”操作，这样可以使下采样层的敏感度map的大小和卷积层的map大小相同，然后将$l$层的激活值偏导map和$l+1$层的上采样敏感度map对应元素相乘。因为下采样层map的权值均是一个常数$\\beta$（见3.2节），所以我们只需要将上一步得到的结果乘以 $ \\beta$ 就可以得到$l$层的敏感度map $\\delta^l$。我们可以在卷积层的每个feature map进行相同的计算过程：</p>\n<script type=\"math/tex; mode=display\">\n\\delta_j^l=\\beta_j^{l+1}\\left(f'(u_j^l)\\circ up(\\delta_j^{l+1})\\right)</script><p>其中的 $up(\\cdot)$表示上采样操作，如果下采样过程的采样因子为$n$，只需将每个像素点在水平方向和垂直方向复制$n$次就可以实现，一种有效的实现方式是利用 Kronecker product:</p>\n<script type=\"math/tex; mode=display\">\nup(x)=x\\otimes1_{n\\times n}</script><blockquote>\n<p>Ref:<a href=\"https://zh.wikipedia.org/zh/克罗内克积\" target=\"_blank\" rel=\"noopener\">克罗内克积</a></p>\n</blockquote>\n<p>现在对于一个给定的map，我们已经可以计算其敏感度map，然后我们可以简单的对敏感度map的所有节点求和计算出其bias（偏置项）梯度:</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{b_j}}=\\sum_{u,v}(\\delta_j^l)_{uv}</script><p>最后，使用BP算法计算权重（卷积核）的梯度，很多权重在连接中是共享的，因此我们需要对所有与该权值有联系（权值共享的连接）的连接对该点求梯度，然后对这些梯度进行求和，就像计算bias梯度一样：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{k_{ij}^l}}=\\sum_{u,v}(\\delta_j^l)_{uv}(p_i^{l-1})_{uv}\\tag{7}</script><p>其中$(p_i^{l-1})_{uv}$是$x_i^{l-1}$在卷积运算时和$k_{ij}^l$按元素相乘得到输出map的$(u,v)$位置值的patch。看上去好像我们我刻意追踪输入map中哪些patch与输出map中的哪些像素（及其对应的敏感map）相对应，但是公式(7)可以通过卷积运算获得:</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{k_{ij}^l}}=rot180(conv2(x_i^{l-1},rot180(\\delta_j^l),'valid'))</script><p>这里我们对$\\delta$敏感度map做旋转操作是为了这样就可以进行互相关计算而不是卷积，之后将输出旋转回来，以便当我们在前馈阶段执行卷积时，卷积核将具有正确的方向。</p>\n<h4 id=\"3-2-子采样层-Sub-sampling-Layers\"><a href=\"#3-2-子采样层-Sub-sampling-Layers\" class=\"headerlink\" title=\"3.2 子采样层 Sub-sampling Layers\"></a>3.2 子采样层 Sub-sampling Layers</h4><p>子采样层对输入maps进行downsample操作（池化），输入有N个maps，输出也会有N个maps，只是每个maps变小了，公式表述如下：</p>\n<script type=\"math/tex; mode=display\">\nx_j^l=f\\left(\\beta_j^ldown(x_j^{l-1})+b_j^l\\right)</script><p>其中的$down(\\cdot)$是下采样函数。典型的操作一般是对输入图像的不同$n\\times n$的块的像素进行求和。这样输出图像在两个维度上都缩小了n倍。每个输出map都有一个属于自己的乘性偏置β和一个加性偏置b。</p>\n<p>3.2.1 Computing the Gradients</p>\n<p>这里的困难在于如何计算敏感度maps。只要我们能得到敏感度maps，需要更新的只有bias参数 $\\beta$ 和 $b$ 。如果子采样层的下一层是全连接层，那么子采样层的敏感度maps只需要利用BP算法就可以容易获得。所以我们假设子采样层的上一层和下一层都是卷积层。</p>\n<p>当我们在3.1.1节计算卷积核梯度时，我们需要找到输入map中patch和输出map的像素的对应关系。这里就是必须找到当前层的敏感度map中那个patch与下一层的敏感度矩阵的的给定像素对应，这样就可以像公式 (4)那样应用$\\delta$递推。 当然，将输入patch和输出像素之间连接相乘的权重恰好是（旋转的）卷积核的权重。利用卷积可以实现该计算：</p>\n<script type=\"math/tex; mode=display\">\n\\delta_j^l=f'(u_j^l)\\circ conv2(\\delta_j^{l+1},rot180(k_j^{l+1}),full)</script><p>如前所述，我们旋转内核是为了是卷积函数实施互相关计算。同时，我们需要对卷积边界进行“full”处理，Matlab的卷积函数会自动执行这个过程，对缺少的输入像素进行补零操作。</p>\n<p>现在我们可以很容易的计算 $b$ 和 $\\beta$ 的梯度，加性基 $b$ 的处理和之前一样，将敏感度map中所有元素相加即可 ：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial E}{\\partial b_j}=\\sum_{u,v}(\\delta_j^l)_{uv}</script><p>对于乘性偏置$\\beta$ ，参与了前向传播时下采样map的运算，所以在前向计算时将这些maps保存，这样避免了在反向传播时重复计算。定义：</p>\n<script type=\"math/tex; mode=display\">\nd_j^l=down(x_j^{l-1})</script><p>$\\beta$ 梯度计算公式如下：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial E}{\\partial \\beta_j}=\\sum_{u,v}(\\delta_j^l)</script><blockquote>\n<p>补充说明：对rot180的解释</p>\n<p>假设第$l-1$层输出$x^l$是一个3x3矩阵，第$l$层卷积核$k^l$是一个2x2的矩阵，步幅为1，输出一个2x2的矩阵$z^l$，则有（简化$b^l=0$，单卷积核)</p>\n<script type=\"math/tex; mode=display\">\nx^{l-1}*k^{l}=z^{l}</script><p>矩阵形式表达：</p>\n<script type=\"math/tex; mode=display\">\n\\left( \\begin{array}{}\nx_{11}&x_{12}&x_{13}\\\\\nx_{21}&x_{22}&x_{23}\\\\\nx_{31}&x_{32}&x_{33}\n\\end{array}\n\\right)\n*\n\\left( \\begin{array}{}\nk_{11}&k_{12}\\\\\nk_{21}&k_{22}\n\\end{array}\n\\right)\n=\n\\left( \\begin{array}{}\nz_{11}&z_{12}\\\\\nz_{21}&z_{22}\n\\end{array}\n\\right)</script><p>根据卷积的定义可得：</p>\n<script type=\"math/tex; mode=display\">\nz_{11}=x_{11}k_{11}+x_{12}k_{12}+x_{21}k_{21}+x_{22}k_{22}\\\\\nz_{12}=x_{12}k_{11}+x_{13}k_{12}+x_{22}k_{21}+x_{23}k_{22}\\\\\nz_{21}=x_{21}k_{11}+x_{22}k_{12}+x_{31}k_{21}+x_{32}k_{22}\\\\\nz_{22}=x_{22}k_{11}+x_{23}k_{12}+x_{32}k_{21}+x_{33}k_{22}</script><p>第$l$层的梯度误差为$\\delta^l$，反向传导：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{k^l}}=\\frac{\\partial{E}}{\\partial{z^l}}\\frac{\\partial{z^l}}{\\partial{k^l}}=\\delta^l\\frac{z^l}{k^l}</script><p>因此对于卷积核$k^l$的梯度为第$l$层的敏感度（梯度）乘上$\\frac{\\partial{z^l}}{\\partial{k^l}}$，分别计算可得</p>\n<script type=\"math/tex; mode=display\">\n\\bigtriangledown{k_{11}}=\\delta_{11}x_{11}+\\delta_{12}x_{22}+\\delta_{21}x_{21}+\\delta_{22}x_{22}\\\\\n\\bigtriangledown{k_{12}}=\\delta_{11}x_{12}+\\delta_{12}x_{13}+\\delta_{21}x_{22}+\\delta_{22}x_{23}\\\\\n\\bigtriangledown{k_{21}}=\\delta_{11}x_{21}+\\delta_{12}x_{22}+\\delta_{21}x_{31}+\\delta_{22}x_{32}\\\\\n\\bigtriangledown{k_{22}}=\\delta_{11}x_{22}+\\delta_{12}x_{23}+\\delta_{21}x_{32}+\\delta_{22}x_{33}</script><p>上面4个式子用矩阵卷积形式表示：</p>\n<script type=\"math/tex; mode=display\">\n\\left( \\begin{array}{}\nx_{11}&x_{12}&x_{13}\\\\\nx_{21}&x_{22}&x_{23}\\\\\nx_{31}&x_{32}&x_{33}\n\\end{array}\n\\right)\n*\n\\left( \\begin{array}{}\n\\delta_{11}&\\delta_{12}\\\\\n\\delta_{21}&\\delta_{22}\n\\end{array}\n\\right)\n=\n\\left( \\begin{array}{}\n\\bigtriangledown k_{11}&\\bigtriangledown k_{12}\\\\\n\\bigtriangledown k_{21}&\\bigtriangledown k_{22}\n\\end{array}\n\\right)</script><p>公式化表达为：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{k^l}}=x^{l-1}*\\delta^l</script><p>这里需要注意，在论文中进行了两次旋转，这是因为在MATLAB中conv2函数在计算卷积时除了会对矩阵进行“0”扩展，还会将卷积核进行旋转，然后再计算。例如：</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; a =</span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">1</span>     <span class=\"number\">1</span></span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">1</span>     <span class=\"number\">1</span></span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">1</span>     <span class=\"number\">1</span></span><br><span class=\"line\">&gt; k =</span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">2</span>     <span class=\"number\">3</span></span><br><span class=\"line\">&gt;      <span class=\"number\">4</span>     <span class=\"number\">5</span>     <span class=\"number\">6</span></span><br><span class=\"line\">&gt;      <span class=\"number\">7</span>     <span class=\"number\">8</span>     <span class=\"number\">9</span></span><br><span class=\"line\">&gt;</span><br><span class=\"line\">&gt; &gt;&gt; convn(a,k,<span class=\"string\">'full'</span>)</span><br><span class=\"line\">&gt; <span class=\"built_in\">ans</span> =</span><br><span class=\"line\">&gt;</span><br><span class=\"line\">&gt;      <span class=\"number\">1</span>     <span class=\"number\">3</span>     <span class=\"number\">6</span>     <span class=\"number\">5</span>     <span class=\"number\">3</span></span><br><span class=\"line\">&gt;      <span class=\"number\">5</span>    <span class=\"number\">12</span>    <span class=\"number\">21</span>    <span class=\"number\">16</span>     <span class=\"number\">9</span></span><br><span class=\"line\">&gt;     <span class=\"number\">12</span>    <span class=\"number\">27</span>    <span class=\"number\">45</span>    <span class=\"number\">33</span>    <span class=\"number\">18</span></span><br><span class=\"line\">&gt;     <span class=\"number\">11</span>    <span class=\"number\">24</span>    <span class=\"number\">39</span>    <span class=\"number\">28</span>    <span class=\"number\">15</span></span><br><span class=\"line\">&gt;      <span class=\"number\">7</span>    <span class=\"number\">15</span>    <span class=\"number\">24</span>    <span class=\"number\">17</span>     <span class=\"number\">9</span></span><br><span class=\"line\">&gt;</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>&gt;</p>\n<blockquote>\n<p>因此在编写代码时需要注意保持一致（要么旋转，要么不旋转）。</p>\n<p>在3.2节计算 $\\delta^l_j$ 也是同理</p>\n<p>利用反向传播：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{x^{l-1}}}=\\frac{\\partial{E}}{\\partial{z^l}}\\frac{\\partial{z^l}}{\\partial{x^{l-1}}}=\\delta^l\\frac{z^l}{x^{l-1}}</script><p>利用上式，可得：</p>\n<script type=\"math/tex; mode=display\">\n\\bigtriangledown{x_{11}}=\\delta_{11}k_{11}\\\\\n\\bigtriangledown{x_{12}}=\\delta_{11}k_{12}+\\delta_{12}k_{11}\\\\\n\\bigtriangledown{x_{13}}=\\delta_{12}k_{12}\\\\\n\\bigtriangledown{x_{21}}=\\delta_{11}k_{21}+\\delta_{21}k_{11}\\\\\n\\bigtriangledown{x_{22}}=\\delta_{11}k_{22}+\\delta_{12}k_{21}+\\delta_{21}k_{12}+\\delta_{22}k_{11}\\\\\n\\bigtriangledown{x_{23}}=\\delta_{12}k_{22}+\\delta_{22}k_{12}\\\\\n\\bigtriangledown{x_{31}}=\\delta_{21}k_{21}\\\\\n\\bigtriangledown{x_{32}}=\\delta_{21}k_{22}+\\delta_{22}k_{21}\\\\\n\\bigtriangledown{x_{33}}=\\delta_{22}k_{22}</script><p>上面九个式子用矩阵卷积形式表示：</p>\n<script type=\"math/tex; mode=display\">\n\\left( \\begin{array}{}\n0&0&0&0\\\\\n0&\\delta_{11}&\\delta_{12}&0\\\\\n0&\\delta_{21}&\\delta_{22}&0\\\\\n0&0&0&0\n\\end{array}\n\\right)\n*\n\\left( \\begin{array}{}\nk_{22}&k_{21}\\\\\nk_{12}&k_{11}\n\\end{array}\n\\right)\n=\n\\left( \\begin{array}{}\n\\bigtriangledown x_{11}&\\bigtriangledown x_{12}&\\bigtriangledown x_{13}\\\\\n\\bigtriangledown x_{21}&\\bigtriangledown x_{22}&\\bigtriangledown x_{23}\\\\\n\\bigtriangledown x_{31}&\\bigtriangledown x_{32}&\\bigtriangledown x_{33}\n\\end{array}\n\\right)</script><p>公式化表达为：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial{E}}{\\partial{x^{l-1}}}=\\delta^l * rot180(k^l)</script></blockquote>\n<h4 id=\"3-3-学习特征maps组合-Learning-Combinations-of-Feature-Maps\"><a href=\"#3-3-学习特征maps组合-Learning-Combinations-of-Feature-Maps\" class=\"headerlink\" title=\"3.3 学习特征maps组合 Learning Combinations of Feature Maps\"></a>3.3 学习特征maps组合 Learning Combinations of Feature Maps</h4><p>通常，对不同的maps进行卷积并对结果求和获得一个输出map，往往能取得不错的效果。在一些文献中，通过人工选择输入maps进行组合。但是我们可以尝试通过训练获得这个组合。让 $a_{ij}$ 表示得到第 $j$ 个输出map中第 $i$ 个输入map的权重，那么第 $j$ 个输出map的定义如下：</p>\n<script type=\"math/tex; mode=display\">\nx_j^l=f\\left( \\sum_{i=1}^{N_{in}}a_{ij}(x_i^{l-1}*k_i^l)+b_j^l\\right)</script><p>同时需满足以下约束：</p>\n<script type=\"math/tex; mode=display\">\n\\sum_ia_ij=1,and \\space 0\\leq a_{ij}\\leq1</script><p>这些约束可以通过将变量$a_{ij}$表示为softmax形式来加强：</p>\n<script type=\"math/tex; mode=display\">\na_{ij}=\\frac{exp(c_{ij})}{\\sum_kexp(c_{kj})}</script><p>因为对于固定的 $j$ 来说，每组权值 $c_{ij}$ 都和其他组权值相独立，所以为了方便描述，我们把下标 $j$ 去掉，只考虑单个map的更新，其他map的更新方式是相同的过程，只是索引 $j$ 不同。</p>\n<p>softmax函数的导数：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial a_k}{\\partial c_i}=\\delta_{ki}a_i-a_ia_k\\tag{8}</script><p>这里的 $\\delta$ 是 kronecker delta，参照公式 (1) 我们可以得到在 $l$ 层误差对 $a_i$ 的偏导：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial E}{\\partial a_i}=\\frac{\\partial E}{\\partial u^l}\\frac{\\partial u^l}{\\partial a_i}=\\sum_{u,v}(\\delta^l \\circ (x_i^{l-1}*k_i^l))_{uv}</script><p>这里的$\\delta^l$对应具有输入 $u$ 的输出map的敏感度map。和前面一样，这里的卷积运算也是“valid”类型，目的是使结果和sensitivity map大小匹配。最后使用链式法则计算损失函数对权值 $c_i$ 的偏导数：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\frac{\\partial E}{\\partial c_i}&=\\sum_k\\frac{\\partial E}{\\partial a_k}\\frac{\\partial a_k}{\\partial c_i}\\tag{9}\\\\\n&=a_i\\left( \\frac{\\partial E}{\\partial a_i}-\\sum_k\\frac{\\partial E}{\\partial a_k}a_k\\right)\\tag{10}\n\\end{align}</script><p> 3.3.1 Enforcing Sparse Combinations</p>\n<p>为了给 $a_i$ 增加稀疏约束（限制一个输出map只与某些而不是全部输入map相连接），我们在代价函数中添加正则项惩罚 $\\Omega(a)$ 。这样就可以使某些权值趋于0，最后只有部分输入maps参与输出map相连接，代价函数为：</p>\n<script type=\"math/tex; mode=display\">\n\\widetilde{E}^n=E^n + \\lambda\\sum{i,j}|(a){ij}|\\tag{11}</script><p>然后求这个正则项对 $c_i$梯度的影响：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial\\Omega}{\\partial a_i}=\\lambda sign(a_i)\\tag{12}</script><p>结合公式 (8) 的结果：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\frac{\\partial\\Omega}{\\partial c_i}& = \\sum_k\\frac{\\partial\\Omega}{\\partial a_k}\\frac{\\partial a_k}{\\partial c_i} \\\\\n&=\n\\lambda\\left(|a_i|-a_i\\sum_k|a_k|\\right)\n\\end{align}</script><p>最后结合公式 (13) 和公式 (9) ，可以求的权重 $c_i$ 的梯度：</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial\\widetilde{E}^n}{\\partial c_i} = \\frac{\\partial E^n}{\\partial c_i} +\\frac{\\partial \\Omega}{\\partial c_i}</script><h4 id=\"3-4-加快MATLAB训练速度-Making-it-Fast-with-MATLAB\"><a href=\"#3-4-加快MATLAB训练速度-Making-it-Fast-with-MATLAB\" class=\"headerlink\" title=\"3.4 加快MATLAB训练速度 Making it Fast with MATLAB\"></a>3.4 加快MATLAB训练速度 Making it Fast with MATLAB</h4><blockquote>\n<p>与CNN关系不大，不做翻译，可看原文</p>\n</blockquote>\n<h3 id=\"4-实际训练问题-Practical-Training-Issues-Incomplete\"><a href=\"#4-实际训练问题-Practical-Training-Issues-Incomplete\" class=\"headerlink\" title=\"4 实际训练问题 Practical Training Issues (Incomplete)\"></a>4 实际训练问题 Practical Training Issues (Incomplete)</h3><blockquote>\n<p>与CNN关系不大，不做翻译，可看原文</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\n</script>"},{"title":"Cost Sensitive Online Classification","date":"2018-06-14T06:38:47.000Z","_content":"\npaper list:\n\nA Framework of Online Learning with Imbalanced Streaming Data\n\nOnline Asymmetric Active Learning with Imbalanced Data \n\n<!--more-->\n\n### A Framework of Online Learning with Imbalanced Streaming Data \n\n####Background\n\nMany previous works have considered cost-sensitive approaches in an online setting for streaming data, where **fixed costs** are assigned to different classes, or ad-hoc costs are adapted based on the distribution of data received so far. However, it is not necessary for them to achieve optimal performance in terms of the measures suited for imbalanced data, such as F-measure, area under ROC curve (AUROC), area under precision and recall curve (AUPRC).  \n\n#### Contribution\n\n**Motivation:** if multiple classifiers with a number of **cost** are learned simultaneously, there must exist one setting that is most appropriate to the data.  \n\n**Algorithm:**\n\n* construct a pool of multiple values of **cost**->**classifiers**.\n* choose the classifier with best (according to distribution) performance (F-measure, ROC, AUROC) on historical data to predict\n* update classifiers and performance\n\n#### Theoretical analysis\n\nWhen K is sufficiently large (the number of classifiers), there exists **a sequence of classifiers** among the K sequences that will even tually converge to a classifier that has a close-to-optimal F-measure.\n\nMaximizing F-measure is equivalent to minimizing a cost- sensitive error. \n\n### Online Asymmetric Active Learning with Imbalanced Data \n\n#### Background\n\nThis paper considers online learning with **imbalanced** streaming data under a **query budget**: the act of querying for labels is constrained to a budget limit.\n\n#### Contribution\n\n**Algorithm**\n\n* Make decision about the binary label\n* Query stage: decide whether to query the label and update the model\n  * if reaches the budget limit, use the last updated model or averaged model\n  * else, use the output of **query function**{0, 1}, if output equal 1, update model\n\nthe key concern is the **query model**.\n\n**Query model**\n\n* Compute $p_t = w_{t-1}x_t$\n* if $p_t \\ge 0$, the probability (output = 1) is $\\frac{c_+}{|p_t|+c_+}$。else the probability is $\\frac{c_-}{|p_t|+c_-}$.","source":"_posts/Cost-Sensitive-Online-Classification.md","raw":"---\ntitle: Cost Sensitive Online Classification\ndate: 2018-06-14 14:38:47\ntags: machine learning\ncategories: artificial intelligence \n---\n\npaper list:\n\nA Framework of Online Learning with Imbalanced Streaming Data\n\nOnline Asymmetric Active Learning with Imbalanced Data \n\n<!--more-->\n\n### A Framework of Online Learning with Imbalanced Streaming Data \n\n####Background\n\nMany previous works have considered cost-sensitive approaches in an online setting for streaming data, where **fixed costs** are assigned to different classes, or ad-hoc costs are adapted based on the distribution of data received so far. However, it is not necessary for them to achieve optimal performance in terms of the measures suited for imbalanced data, such as F-measure, area under ROC curve (AUROC), area under precision and recall curve (AUPRC).  \n\n#### Contribution\n\n**Motivation:** if multiple classifiers with a number of **cost** are learned simultaneously, there must exist one setting that is most appropriate to the data.  \n\n**Algorithm:**\n\n* construct a pool of multiple values of **cost**->**classifiers**.\n* choose the classifier with best (according to distribution) performance (F-measure, ROC, AUROC) on historical data to predict\n* update classifiers and performance\n\n#### Theoretical analysis\n\nWhen K is sufficiently large (the number of classifiers), there exists **a sequence of classifiers** among the K sequences that will even tually converge to a classifier that has a close-to-optimal F-measure.\n\nMaximizing F-measure is equivalent to minimizing a cost- sensitive error. \n\n### Online Asymmetric Active Learning with Imbalanced Data \n\n#### Background\n\nThis paper considers online learning with **imbalanced** streaming data under a **query budget**: the act of querying for labels is constrained to a budget limit.\n\n#### Contribution\n\n**Algorithm**\n\n* Make decision about the binary label\n* Query stage: decide whether to query the label and update the model\n  * if reaches the budget limit, use the last updated model or averaged model\n  * else, use the output of **query function**{0, 1}, if output equal 1, update model\n\nthe key concern is the **query model**.\n\n**Query model**\n\n* Compute $p_t = w_{t-1}x_t$\n* if $p_t \\ge 0$, the probability (output = 1) is $\\frac{c_+}{|p_t|+c_+}$。else the probability is $\\frac{c_-}{|p_t|+c_-}$.","slug":"Cost-Sensitive-Online-Classification","published":1,"updated":"2018-06-26T10:54:58.425Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owbq0006fb9lq3e3w7ab","content":"<p>paper list:</p>\n<p>A Framework of Online Learning with Imbalanced Streaming Data</p>\n<p>Online Asymmetric Active Learning with Imbalanced Data </p>\n<a id=\"more\"></a>\n<h3 id=\"A-Framework-of-Online-Learning-with-Imbalanced-Streaming-Data\"><a href=\"#A-Framework-of-Online-Learning-with-Imbalanced-Streaming-Data\" class=\"headerlink\" title=\"A Framework of Online Learning with Imbalanced Streaming Data\"></a>A Framework of Online Learning with Imbalanced Streaming Data</h3><h4 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h4><p>Many previous works have considered cost-sensitive approaches in an online setting for streaming data, where <strong>fixed costs</strong> are assigned to different classes, or ad-hoc costs are adapted based on the distribution of data received so far. However, it is not necessary for them to achieve optimal performance in terms of the measures suited for imbalanced data, such as F-measure, area under ROC curve (AUROC), area under precision and recall curve (AUPRC).  </p>\n<h4 id=\"Contribution\"><a href=\"#Contribution\" class=\"headerlink\" title=\"Contribution\"></a>Contribution</h4><p><strong>Motivation:</strong> if multiple classifiers with a number of <strong>cost</strong> are learned simultaneously, there must exist one setting that is most appropriate to the data.  </p>\n<p><strong>Algorithm:</strong></p>\n<ul>\n<li>construct a pool of multiple values of <strong>cost</strong>-&gt;<strong>classifiers</strong>.</li>\n<li>choose the classifier with best (according to distribution) performance (F-measure, ROC, AUROC) on historical data to predict</li>\n<li>update classifiers and performance</li>\n</ul>\n<h4 id=\"Theoretical-analysis\"><a href=\"#Theoretical-analysis\" class=\"headerlink\" title=\"Theoretical analysis\"></a>Theoretical analysis</h4><p>When K is sufficiently large (the number of classifiers), there exists <strong>a sequence of classifiers</strong> among the K sequences that will even tually converge to a classifier that has a close-to-optimal F-measure.</p>\n<p>Maximizing F-measure is equivalent to minimizing a cost- sensitive error. </p>\n<h3 id=\"Online-Asymmetric-Active-Learning-with-Imbalanced-Data\"><a href=\"#Online-Asymmetric-Active-Learning-with-Imbalanced-Data\" class=\"headerlink\" title=\"Online Asymmetric Active Learning with Imbalanced Data\"></a>Online Asymmetric Active Learning with Imbalanced Data</h3><h4 id=\"Background-1\"><a href=\"#Background-1\" class=\"headerlink\" title=\"Background\"></a>Background</h4><p>This paper considers online learning with <strong>imbalanced</strong> streaming data under a <strong>query budget</strong>: the act of querying for labels is constrained to a budget limit.</p>\n<h4 id=\"Contribution-1\"><a href=\"#Contribution-1\" class=\"headerlink\" title=\"Contribution\"></a>Contribution</h4><p><strong>Algorithm</strong></p>\n<ul>\n<li>Make decision about the binary label</li>\n<li>Query stage: decide whether to query the label and update the model<ul>\n<li>if reaches the budget limit, use the last updated model or averaged model</li>\n<li>else, use the output of <strong>query function</strong>{0, 1}, if output equal 1, update model</li>\n</ul>\n</li>\n</ul>\n<p>the key concern is the <strong>query model</strong>.</p>\n<p><strong>Query model</strong></p>\n<ul>\n<li>Compute $p_t = w_{t-1}x_t$</li>\n<li>if $p_t \\ge 0$, the probability (output = 1) is $\\frac{c_+}{|p_t|+c_+}$。else the probability is $\\frac{c_-}{|p_t|+c_-}$.</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>paper list:</p>\n<p>A Framework of Online Learning with Imbalanced Streaming Data</p>\n<p>Online Asymmetric Active Learning with Imbalanced Data </p>","more":"<h3 id=\"A-Framework-of-Online-Learning-with-Imbalanced-Streaming-Data\"><a href=\"#A-Framework-of-Online-Learning-with-Imbalanced-Streaming-Data\" class=\"headerlink\" title=\"A Framework of Online Learning with Imbalanced Streaming Data\"></a>A Framework of Online Learning with Imbalanced Streaming Data</h3><h4 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h4><p>Many previous works have considered cost-sensitive approaches in an online setting for streaming data, where <strong>fixed costs</strong> are assigned to different classes, or ad-hoc costs are adapted based on the distribution of data received so far. However, it is not necessary for them to achieve optimal performance in terms of the measures suited for imbalanced data, such as F-measure, area under ROC curve (AUROC), area under precision and recall curve (AUPRC).  </p>\n<h4 id=\"Contribution\"><a href=\"#Contribution\" class=\"headerlink\" title=\"Contribution\"></a>Contribution</h4><p><strong>Motivation:</strong> if multiple classifiers with a number of <strong>cost</strong> are learned simultaneously, there must exist one setting that is most appropriate to the data.  </p>\n<p><strong>Algorithm:</strong></p>\n<ul>\n<li>construct a pool of multiple values of <strong>cost</strong>-&gt;<strong>classifiers</strong>.</li>\n<li>choose the classifier with best (according to distribution) performance (F-measure, ROC, AUROC) on historical data to predict</li>\n<li>update classifiers and performance</li>\n</ul>\n<h4 id=\"Theoretical-analysis\"><a href=\"#Theoretical-analysis\" class=\"headerlink\" title=\"Theoretical analysis\"></a>Theoretical analysis</h4><p>When K is sufficiently large (the number of classifiers), there exists <strong>a sequence of classifiers</strong> among the K sequences that will even tually converge to a classifier that has a close-to-optimal F-measure.</p>\n<p>Maximizing F-measure is equivalent to minimizing a cost- sensitive error. </p>\n<h3 id=\"Online-Asymmetric-Active-Learning-with-Imbalanced-Data\"><a href=\"#Online-Asymmetric-Active-Learning-with-Imbalanced-Data\" class=\"headerlink\" title=\"Online Asymmetric Active Learning with Imbalanced Data\"></a>Online Asymmetric Active Learning with Imbalanced Data</h3><h4 id=\"Background-1\"><a href=\"#Background-1\" class=\"headerlink\" title=\"Background\"></a>Background</h4><p>This paper considers online learning with <strong>imbalanced</strong> streaming data under a <strong>query budget</strong>: the act of querying for labels is constrained to a budget limit.</p>\n<h4 id=\"Contribution-1\"><a href=\"#Contribution-1\" class=\"headerlink\" title=\"Contribution\"></a>Contribution</h4><p><strong>Algorithm</strong></p>\n<ul>\n<li>Make decision about the binary label</li>\n<li>Query stage: decide whether to query the label and update the model<ul>\n<li>if reaches the budget limit, use the last updated model or averaged model</li>\n<li>else, use the output of <strong>query function</strong>{0, 1}, if output equal 1, update model</li>\n</ul>\n</li>\n</ul>\n<p>the key concern is the <strong>query model</strong>.</p>\n<p><strong>Query model</strong></p>\n<ul>\n<li>Compute $p_t = w_{t-1}x_t$</li>\n<li>if $p_t \\ge 0$, the probability (output = 1) is $\\frac{c_+}{|p_t|+c_+}$。else the probability is $\\frac{c_-}{|p_t|+c_-}$.</li>\n</ul>"},{"title":"Convexity, Lipschitzness, and Smoothness","date":"2018-06-28T02:44:50.000Z","_content":"\nintroduction from \"understandingmachine learning theory algorithms\"\n\n<!--- more --->\n\n##Convexity\n\n### Convexity set\n\nA set C in a vector space is convex if for any two vector $\\mathbf{u},\\mathbf{v}$ in $C$, the line segment between $\\mathbf{u}$ and $\\mathbf{v}$ is contained in $C$. That is, for any $a\\in[0,1]$ we have that $\\alpha \\mathbf{u}+(1-\\alpha)\\mathbf{v} \\in C$.\n\n### Convexity function\n\nLet $C$ be a convex set. A function $f:C \\rightarrow \\mathbb{R}$ is convex for every $\\mathbf{u},\\mathbf{v}\\in C$ and $\\alpha\\in[0,1]$,\n$$\nf(\\alpha \\mathbf{u} + (1-\\alpha)\\mathbf{v}) \\le \\alpha f(\\mathbf{u}) + (1-\\alpha) f(\\mathbf{v}).\n$$\n**Important property**\n\n* Every local minimum of the function is also a global minimum. \n* For every $\\mathbf{w}$ we can construct a tangent to $f$ at $\\mathbf{w}$ that lies below $f$ everywhere, that is for convex differentiable function,\n\n$$\n\\forall \\mathbf{u}, f(\\mathbf{u}) \\ge f(\\mathbf{w}) + \\langle \\nabla f(\\mathbf{w}), \\mathbf{u} - \\mathbf{w} \\rangle.\n$$\n\n**LEMMA**\n\nLet $f:\\mathbb{R} \\rightarrow \\mathbb{R}$ be a scalar twice diffrential function, and Let $f',f''$ be its first and second derivatives, respectively. Then, the following are equivalent:\n\n1. $f$ is convex \n2. $f'$ is monotonically nondecreasing\n3. $f''$ is nonnegative\n\n**CLAIM**\n\n* Assume that $f:\\mathbb{R}^d \\rightarrow \\mathbb{R}$can be written as $f(\\mathbf{w}) = g(\\langle \\mathbf{w}, \\mathbf{x}) + y)$, for some $\\mathbf{x} \\in \\mathbb{R}^d, y\\in \\mathbb{R}$. Then, **convexity of $g$ implies the convexity of $f$**.\n\n  **Meaning**: The composition of a convex scalar function with a linear function yields a convex vector-valued function.\n\n* For $i=1,…,r,let f_i : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ be a convex function. The following functions $g(x)$from $\\mathbb{R}$ to $\\mathbb{R}$ are also convex.\n\n  $g(x)=max_{i\\in[r]} f_i(x)$\n\n  $g(x)=\\sum_{i=1}^r w_i f_i(x)$, where for all $i,w_i \\ge 0$.\n\n  **Meaning**:The maximum of convex functions is convex and that a weighted sum of convex functions, with nonnegative weights, is also convex.\n\n##Lipschitzness\n\n**DEFINITION**: Let $C \\subset \\mathbb{R}^d$. A function $f:\\mathbb{R}^d\\rightarrow\\mathbb{R}^k$ is $\\rho$-Lipschitz over $C$ if for every $\\mathbf{w}_1,\\mathbf{w}_2 \\in C$ we have $\\|f(\\mathbb{w_1})-f(\\mathbb{w_2}) \\| \\le \\rho\\|\\mathbf{w_1}-\\mathbf{w_2}\\|$.\n\nMEANING: if $f$ is everywhere bounded (in absolute value) by $\\rho$, then the function is $\\rho$-Lipschitz.\n\n**CLAIM**: Let $f(x) = g_1(g_2(\\mathbf{x}))$, where $g_1$ is $\\rho_1$-Lipschitz and $g_2$ is $\\rho_2$-Lipschitz. Then, $f \\space is \\space(\\rho_1\\rho_2)-Lipschitz$. In particular, if $g_2$ is the linear function, $g_2(\\mathbf{x})=\\langle \\mathbf{v},\\mathbf{x}\\rangle+b$, for some $\\mathbf{v} \\in \\mathbb{R}^d, b\\in \\mathbb{R},then \\space f \\space (\\rho_1\\|\\mathbf{v}\\|)-Lipschitz$.\n\n## Smoothness\n\n**DEFINITION**: A differentiable function $f$: $\\mathbb{R}^d \\rightarrow \\mathbb{R}$ is $\\beta$-smooth if its gradient is $\\beta$-Lipschitz; namely, for all $\\mathbf{v},\\mathbf{w}$ we have $\\|\\nabla f(\\mathbf{v}) - \\nabla f(\\mathbf{w}) \\| \\le \\beta\\|\\mathbf{v} - \\mathbf{w} \\|$.\n\n**CLAIM**: Let $f(\\mathbf{w}) = g(\\langle \\mathbf{w} , \\mathbf{x} \\rangle + b), where \\space g:\\mathbb{R} \\rightarrow \\mathbb{R}​$ is a $\\beta​$-smooth function, $\\mathbf{x} \\in \\mathbb{R}^d​$, and $b \\in \\mathbb{R}​$. Then, $f \\space is  \\space (\\beta \\|\\mathbf{x}\\|)​$-smooth.\n\n\n\n实际上，凸性要求一个函数在局部增长得比线性函数要快，而强凸性则要求其增长得比一个二次函数（二次项系数为m/2）快。","source":"_posts/Convexity-Lipschitzness-and-Smoothness.md","raw":"---\ntitle: 'Convexity, Lipschitzness, and Smoothness'\ndate: 2018-06-28 10:44:50\ntags: machine learning\ncategories: artificial intelligence\n---\n\nintroduction from \"understandingmachine learning theory algorithms\"\n\n<!--- more --->\n\n##Convexity\n\n### Convexity set\n\nA set C in a vector space is convex if for any two vector $\\mathbf{u},\\mathbf{v}$ in $C$, the line segment between $\\mathbf{u}$ and $\\mathbf{v}$ is contained in $C$. That is, for any $a\\in[0,1]$ we have that $\\alpha \\mathbf{u}+(1-\\alpha)\\mathbf{v} \\in C$.\n\n### Convexity function\n\nLet $C$ be a convex set. A function $f:C \\rightarrow \\mathbb{R}$ is convex for every $\\mathbf{u},\\mathbf{v}\\in C$ and $\\alpha\\in[0,1]$,\n$$\nf(\\alpha \\mathbf{u} + (1-\\alpha)\\mathbf{v}) \\le \\alpha f(\\mathbf{u}) + (1-\\alpha) f(\\mathbf{v}).\n$$\n**Important property**\n\n* Every local minimum of the function is also a global minimum. \n* For every $\\mathbf{w}$ we can construct a tangent to $f$ at $\\mathbf{w}$ that lies below $f$ everywhere, that is for convex differentiable function,\n\n$$\n\\forall \\mathbf{u}, f(\\mathbf{u}) \\ge f(\\mathbf{w}) + \\langle \\nabla f(\\mathbf{w}), \\mathbf{u} - \\mathbf{w} \\rangle.\n$$\n\n**LEMMA**\n\nLet $f:\\mathbb{R} \\rightarrow \\mathbb{R}$ be a scalar twice diffrential function, and Let $f',f''$ be its first and second derivatives, respectively. Then, the following are equivalent:\n\n1. $f$ is convex \n2. $f'$ is monotonically nondecreasing\n3. $f''$ is nonnegative\n\n**CLAIM**\n\n* Assume that $f:\\mathbb{R}^d \\rightarrow \\mathbb{R}$can be written as $f(\\mathbf{w}) = g(\\langle \\mathbf{w}, \\mathbf{x}) + y)$, for some $\\mathbf{x} \\in \\mathbb{R}^d, y\\in \\mathbb{R}$. Then, **convexity of $g$ implies the convexity of $f$**.\n\n  **Meaning**: The composition of a convex scalar function with a linear function yields a convex vector-valued function.\n\n* For $i=1,…,r,let f_i : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ be a convex function. The following functions $g(x)$from $\\mathbb{R}$ to $\\mathbb{R}$ are also convex.\n\n  $g(x)=max_{i\\in[r]} f_i(x)$\n\n  $g(x)=\\sum_{i=1}^r w_i f_i(x)$, where for all $i,w_i \\ge 0$.\n\n  **Meaning**:The maximum of convex functions is convex and that a weighted sum of convex functions, with nonnegative weights, is also convex.\n\n##Lipschitzness\n\n**DEFINITION**: Let $C \\subset \\mathbb{R}^d$. A function $f:\\mathbb{R}^d\\rightarrow\\mathbb{R}^k$ is $\\rho$-Lipschitz over $C$ if for every $\\mathbf{w}_1,\\mathbf{w}_2 \\in C$ we have $\\|f(\\mathbb{w_1})-f(\\mathbb{w_2}) \\| \\le \\rho\\|\\mathbf{w_1}-\\mathbf{w_2}\\|$.\n\nMEANING: if $f$ is everywhere bounded (in absolute value) by $\\rho$, then the function is $\\rho$-Lipschitz.\n\n**CLAIM**: Let $f(x) = g_1(g_2(\\mathbf{x}))$, where $g_1$ is $\\rho_1$-Lipschitz and $g_2$ is $\\rho_2$-Lipschitz. Then, $f \\space is \\space(\\rho_1\\rho_2)-Lipschitz$. In particular, if $g_2$ is the linear function, $g_2(\\mathbf{x})=\\langle \\mathbf{v},\\mathbf{x}\\rangle+b$, for some $\\mathbf{v} \\in \\mathbb{R}^d, b\\in \\mathbb{R},then \\space f \\space (\\rho_1\\|\\mathbf{v}\\|)-Lipschitz$.\n\n## Smoothness\n\n**DEFINITION**: A differentiable function $f$: $\\mathbb{R}^d \\rightarrow \\mathbb{R}$ is $\\beta$-smooth if its gradient is $\\beta$-Lipschitz; namely, for all $\\mathbf{v},\\mathbf{w}$ we have $\\|\\nabla f(\\mathbf{v}) - \\nabla f(\\mathbf{w}) \\| \\le \\beta\\|\\mathbf{v} - \\mathbf{w} \\|$.\n\n**CLAIM**: Let $f(\\mathbf{w}) = g(\\langle \\mathbf{w} , \\mathbf{x} \\rangle + b), where \\space g:\\mathbb{R} \\rightarrow \\mathbb{R}​$ is a $\\beta​$-smooth function, $\\mathbf{x} \\in \\mathbb{R}^d​$, and $b \\in \\mathbb{R}​$. Then, $f \\space is  \\space (\\beta \\|\\mathbf{x}\\|)​$-smooth.\n\n\n\n实际上，凸性要求一个函数在局部增长得比线性函数要快，而强凸性则要求其增长得比一个二次函数（二次项系数为m/2）快。","slug":"Convexity-Lipschitzness-and-Smoothness","published":1,"updated":"2018-08-15T12:37:30.789Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owbr0007fb9l6wcgzepb","content":"<p>introduction from “understandingmachine learning theory algorithms”</p>\n<a id=\"more\"></a>\n<h2 id=\"Convexity\"><a href=\"#Convexity\" class=\"headerlink\" title=\"Convexity\"></a>Convexity</h2><h3 id=\"Convexity-set\"><a href=\"#Convexity-set\" class=\"headerlink\" title=\"Convexity set\"></a>Convexity set</h3><p>A set C in a vector space is convex if for any two vector $\\mathbf{u},\\mathbf{v}$ in $C$, the line segment between $\\mathbf{u}$ and $\\mathbf{v}$ is contained in $C$. That is, for any $a\\in[0,1]$ we have that $\\alpha \\mathbf{u}+(1-\\alpha)\\mathbf{v} \\in C$.</p>\n<h3 id=\"Convexity-function\"><a href=\"#Convexity-function\" class=\"headerlink\" title=\"Convexity function\"></a>Convexity function</h3><p>Let $C$ be a convex set. A function $f:C \\rightarrow \\mathbb{R}$ is convex for every $\\mathbf{u},\\mathbf{v}\\in C$ and $\\alpha\\in[0,1]$,</p>\n<script type=\"math/tex; mode=display\">\nf(\\alpha \\mathbf{u} + (1-\\alpha)\\mathbf{v}) \\le \\alpha f(\\mathbf{u}) + (1-\\alpha) f(\\mathbf{v}).</script><p><strong>Important property</strong></p>\n<ul>\n<li>Every local minimum of the function is also a global minimum. </li>\n<li>For every $\\mathbf{w}$ we can construct a tangent to $f$ at $\\mathbf{w}$ that lies below $f$ everywhere, that is for convex differentiable function,</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\forall \\mathbf{u}, f(\\mathbf{u}) \\ge f(\\mathbf{w}) + \\langle \\nabla f(\\mathbf{w}), \\mathbf{u} - \\mathbf{w} \\rangle.</script><p><strong>LEMMA</strong></p>\n<p>Let $f:\\mathbb{R} \\rightarrow \\mathbb{R}$ be a scalar twice diffrential function, and Let $f’,f’’$ be its first and second derivatives, respectively. Then, the following are equivalent:</p>\n<ol>\n<li>$f$ is convex </li>\n<li>$f’$ is monotonically nondecreasing</li>\n<li>$f’’$ is nonnegative</li>\n</ol>\n<p><strong>CLAIM</strong></p>\n<ul>\n<li><p>Assume that $f:\\mathbb{R}^d \\rightarrow \\mathbb{R}$can be written as $f(\\mathbf{w}) = g(\\langle \\mathbf{w}, \\mathbf{x}) + y)$, for some $\\mathbf{x} \\in \\mathbb{R}^d, y\\in \\mathbb{R}$. Then, <strong>convexity of $g$ implies the convexity of $f$</strong>.</p>\n<p><strong>Meaning</strong>: The composition of a convex scalar function with a linear function yields a convex vector-valued function.</p>\n</li>\n<li><p>For $i=1,…,r,let f_i : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ be a convex function. The following functions $g(x)$from $\\mathbb{R}$ to $\\mathbb{R}$ are also convex.</p>\n<p>$g(x)=max_{i\\in[r]} f_i(x)$</p>\n<p>$g(x)=\\sum_{i=1}^r w_i f_i(x)$, where for all $i,w_i \\ge 0$.</p>\n<p><strong>Meaning</strong>:The maximum of convex functions is convex and that a weighted sum of convex functions, with nonnegative weights, is also convex.</p>\n</li>\n</ul>\n<h2 id=\"Lipschitzness\"><a href=\"#Lipschitzness\" class=\"headerlink\" title=\"Lipschitzness\"></a>Lipschitzness</h2><p><strong>DEFINITION</strong>: Let $C \\subset \\mathbb{R}^d$. A function $f:\\mathbb{R}^d\\rightarrow\\mathbb{R}^k$ is $\\rho$-Lipschitz over $C$ if for every $\\mathbf{w}_1,\\mathbf{w}_2 \\in C$ we have $|f(\\mathbb{w_1})-f(\\mathbb{w_2}) | \\le \\rho|\\mathbf{w_1}-\\mathbf{w_2}|$.</p>\n<p>MEANING: if $f$ is everywhere bounded (in absolute value) by $\\rho$, then the function is $\\rho$-Lipschitz.</p>\n<p><strong>CLAIM</strong>: Let $f(x) = g_1(g_2(\\mathbf{x}))$, where $g_1$ is $\\rho_1$-Lipschitz and $g_2$ is $\\rho_2$-Lipschitz. Then, $f \\space is \\space(\\rho_1\\rho_2)-Lipschitz$. In particular, if $g_2$ is the linear function, $g_2(\\mathbf{x})=\\langle \\mathbf{v},\\mathbf{x}\\rangle+b$, for some $\\mathbf{v} \\in \\mathbb{R}^d, b\\in \\mathbb{R},then \\space f \\space (\\rho_1|\\mathbf{v}|)-Lipschitz$.</p>\n<h2 id=\"Smoothness\"><a href=\"#Smoothness\" class=\"headerlink\" title=\"Smoothness\"></a>Smoothness</h2><p><strong>DEFINITION</strong>: A differentiable function $f$: $\\mathbb{R}^d \\rightarrow \\mathbb{R}$ is $\\beta$-smooth if its gradient is $\\beta$-Lipschitz; namely, for all $\\mathbf{v},\\mathbf{w}$ we have $|\\nabla f(\\mathbf{v}) - \\nabla f(\\mathbf{w}) | \\le \\beta|\\mathbf{v} - \\mathbf{w} |$.</p>\n<p><strong>CLAIM</strong>: Let $f(\\mathbf{w}) = g(\\langle \\mathbf{w} , \\mathbf{x} \\rangle + b), where \\space g:\\mathbb{R} \\rightarrow \\mathbb{R}​$ is a $\\beta​$-smooth function, $\\mathbf{x} \\in \\mathbb{R}^d​$, and $b \\in \\mathbb{R}​$. Then, $f \\space is  \\space (\\beta |\\mathbf{x}|)​$-smooth.</p>\n<p>实际上，凸性要求一个函数在局部增长得比线性函数要快，而强凸性则要求其增长得比一个二次函数（二次项系数为m/2）快。</p>\n","site":{"data":{}},"excerpt":"<p>introduction from “understandingmachine learning theory algorithms”</p>","more":"<h2 id=\"Convexity\"><a href=\"#Convexity\" class=\"headerlink\" title=\"Convexity\"></a>Convexity</h2><h3 id=\"Convexity-set\"><a href=\"#Convexity-set\" class=\"headerlink\" title=\"Convexity set\"></a>Convexity set</h3><p>A set C in a vector space is convex if for any two vector $\\mathbf{u},\\mathbf{v}$ in $C$, the line segment between $\\mathbf{u}$ and $\\mathbf{v}$ is contained in $C$. That is, for any $a\\in[0,1]$ we have that $\\alpha \\mathbf{u}+(1-\\alpha)\\mathbf{v} \\in C$.</p>\n<h3 id=\"Convexity-function\"><a href=\"#Convexity-function\" class=\"headerlink\" title=\"Convexity function\"></a>Convexity function</h3><p>Let $C$ be a convex set. A function $f:C \\rightarrow \\mathbb{R}$ is convex for every $\\mathbf{u},\\mathbf{v}\\in C$ and $\\alpha\\in[0,1]$,</p>\n<script type=\"math/tex; mode=display\">\nf(\\alpha \\mathbf{u} + (1-\\alpha)\\mathbf{v}) \\le \\alpha f(\\mathbf{u}) + (1-\\alpha) f(\\mathbf{v}).</script><p><strong>Important property</strong></p>\n<ul>\n<li>Every local minimum of the function is also a global minimum. </li>\n<li>For every $\\mathbf{w}$ we can construct a tangent to $f$ at $\\mathbf{w}$ that lies below $f$ everywhere, that is for convex differentiable function,</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\forall \\mathbf{u}, f(\\mathbf{u}) \\ge f(\\mathbf{w}) + \\langle \\nabla f(\\mathbf{w}), \\mathbf{u} - \\mathbf{w} \\rangle.</script><p><strong>LEMMA</strong></p>\n<p>Let $f:\\mathbb{R} \\rightarrow \\mathbb{R}$ be a scalar twice diffrential function, and Let $f’,f’’$ be its first and second derivatives, respectively. Then, the following are equivalent:</p>\n<ol>\n<li>$f$ is convex </li>\n<li>$f’$ is monotonically nondecreasing</li>\n<li>$f’’$ is nonnegative</li>\n</ol>\n<p><strong>CLAIM</strong></p>\n<ul>\n<li><p>Assume that $f:\\mathbb{R}^d \\rightarrow \\mathbb{R}$can be written as $f(\\mathbf{w}) = g(\\langle \\mathbf{w}, \\mathbf{x}) + y)$, for some $\\mathbf{x} \\in \\mathbb{R}^d, y\\in \\mathbb{R}$. Then, <strong>convexity of $g$ implies the convexity of $f$</strong>.</p>\n<p><strong>Meaning</strong>: The composition of a convex scalar function with a linear function yields a convex vector-valued function.</p>\n</li>\n<li><p>For $i=1,…,r,let f_i : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ be a convex function. The following functions $g(x)$from $\\mathbb{R}$ to $\\mathbb{R}$ are also convex.</p>\n<p>$g(x)=max_{i\\in[r]} f_i(x)$</p>\n<p>$g(x)=\\sum_{i=1}^r w_i f_i(x)$, where for all $i,w_i \\ge 0$.</p>\n<p><strong>Meaning</strong>:The maximum of convex functions is convex and that a weighted sum of convex functions, with nonnegative weights, is also convex.</p>\n</li>\n</ul>\n<h2 id=\"Lipschitzness\"><a href=\"#Lipschitzness\" class=\"headerlink\" title=\"Lipschitzness\"></a>Lipschitzness</h2><p><strong>DEFINITION</strong>: Let $C \\subset \\mathbb{R}^d$. A function $f:\\mathbb{R}^d\\rightarrow\\mathbb{R}^k$ is $\\rho$-Lipschitz over $C$ if for every $\\mathbf{w}_1,\\mathbf{w}_2 \\in C$ we have $|f(\\mathbb{w_1})-f(\\mathbb{w_2}) | \\le \\rho|\\mathbf{w_1}-\\mathbf{w_2}|$.</p>\n<p>MEANING: if $f$ is everywhere bounded (in absolute value) by $\\rho$, then the function is $\\rho$-Lipschitz.</p>\n<p><strong>CLAIM</strong>: Let $f(x) = g_1(g_2(\\mathbf{x}))$, where $g_1$ is $\\rho_1$-Lipschitz and $g_2$ is $\\rho_2$-Lipschitz. Then, $f \\space is \\space(\\rho_1\\rho_2)-Lipschitz$. In particular, if $g_2$ is the linear function, $g_2(\\mathbf{x})=\\langle \\mathbf{v},\\mathbf{x}\\rangle+b$, for some $\\mathbf{v} \\in \\mathbb{R}^d, b\\in \\mathbb{R},then \\space f \\space (\\rho_1|\\mathbf{v}|)-Lipschitz$.</p>\n<h2 id=\"Smoothness\"><a href=\"#Smoothness\" class=\"headerlink\" title=\"Smoothness\"></a>Smoothness</h2><p><strong>DEFINITION</strong>: A differentiable function $f$: $\\mathbb{R}^d \\rightarrow \\mathbb{R}$ is $\\beta$-smooth if its gradient is $\\beta$-Lipschitz; namely, for all $\\mathbf{v},\\mathbf{w}$ we have $|\\nabla f(\\mathbf{v}) - \\nabla f(\\mathbf{w}) | \\le \\beta|\\mathbf{v} - \\mathbf{w} |$.</p>\n<p><strong>CLAIM</strong>: Let $f(\\mathbf{w}) = g(\\langle \\mathbf{w} , \\mathbf{x} \\rangle + b), where \\space g:\\mathbb{R} \\rightarrow \\mathbb{R}​$ is a $\\beta​$-smooth function, $\\mathbf{x} \\in \\mathbb{R}^d​$, and $b \\in \\mathbb{R}​$. Then, $f \\space is  \\space (\\beta |\\mathbf{x}|)​$-smooth.</p>\n<p>实际上，凸性要求一个函数在局部增长得比线性函数要快，而强凸性则要求其增长得比一个二次函数（二次项系数为m/2）快。</p>"},{"layout":"title","title":"Fast Matrix Factorization for Online Recommendation with Implicit Feedback","date":"2018-08-15T11:17:16.000Z","_content":"\n> [Fast Matrix Factorization for Online Recommendation with Implicit Feedback](https://www.comp.nus.edu.sg/~xiangnan/papers/sigir16-eals-cm.pdf)\n\n<!--- more --->\n\n### Background\n\nUser Personalization has become prevalent in modern recommender system. Among its various methods, MF is important. Early work on MF have largely focused explicit feedback. (introduction of explict feedback and MF methods).\n\nHowever, explicit fimplictit ratings are not always avaliable in many applications: **implicit feedback**. (introduction of implicit feedback).\n\n(introduction of algorithm to solve implicit feedback). two challenging problem: **implicit feedback** and **online  learning**.\n\nintroduction of our algorithm, summarize key contributions.\n\n### Contribution\n\n- propose an **item popularity-aware weighting** scheme on the full missing data that effectively tailors the MF model for learning from implicit feedback.  \n- develop a new algorithm for learning model parameters efficiently and devise an incremental update strategy to support real-time **online learning**.\n- conduct extensive experiments with both offline and online protocols on two real-world datasets, showing that our method consistently **outperforms** state-of-the-art implicit MF methods\n\n### Algorithm\n\n#### 1 Item-Oriented Weighting on Missing Data\n\n**Intution**: a popular item is more likely to be known by users, thus a missing on it is more probably that the user is not interested with it. \n\nOld design : Uniform weight\n$$\nL = \\sum_{(u,i) \\in R} w(r_{ui} - \\hat{r}_{ui})^2\n+ \\sum_{(u,i)\\notin R}\\hat{r}_{ui}^2\n+ \\lambda(\\sum_{u=1}^{M}\\|\\mathbb{p}_u\\|^2 + \\sum_{i=1}^N \\|\\mathbb{q}_i\\|^2)\n$$\nNew design: Non-uniform weighing \n$$\nL = \\sum_{(u,i) \\in R} w(r_{ui} - \\hat{r}_{ui})^2\n+ \\sum_{u=1}^M \\sum_{i\\notin R_u}c_i \\hat{r}_{ui}^2\n+ \\lambda(\\sum_{u=1}^{M}\\|\\mathbb{p}_u\\|^2 + \\sum_{i=1}^N \\|\\mathbb{q}_i\\|^2)\n$$\n where $c_i = c_0 \\frac{f_i^a}{\\sum_{j=1}^N f_j^a}$,  $f_i$ denotes the popularity of item $i$, given by its frequency in the implicit feedback data: $|R_i|/\\sum_{j=1}^N|R_j|$.\n\n#### 2 Fast eALS Learning Algorithm\n\ndevelop a Coordinate Descent learner to optimize the whole-data based MF \n\n- Element-wise Alternating Least Squares Learner (eALS)\n- Optimize one latent factor with others fixed (greedy exact optimization) \n\n#### 3 Online Incremental Learning\n\nnew interaction should changel the **local features**, while the global reamain largely unchanged.\n\n\n\n","source":"_posts/Fast-Matrix-Factorization-for-Online-Recommendation-with-Implicit-Feedback.md","raw":"---\nlayout: title\ntitle: Fast Matrix Factorization for Online Recommendation with Implicit Feedback\ndate: 2018-08-15 19:17:16\ntags: machine learning\ncategories: paper notes\n---\n\n> [Fast Matrix Factorization for Online Recommendation with Implicit Feedback](https://www.comp.nus.edu.sg/~xiangnan/papers/sigir16-eals-cm.pdf)\n\n<!--- more --->\n\n### Background\n\nUser Personalization has become prevalent in modern recommender system. Among its various methods, MF is important. Early work on MF have largely focused explicit feedback. (introduction of explict feedback and MF methods).\n\nHowever, explicit fimplictit ratings are not always avaliable in many applications: **implicit feedback**. (introduction of implicit feedback).\n\n(introduction of algorithm to solve implicit feedback). two challenging problem: **implicit feedback** and **online  learning**.\n\nintroduction of our algorithm, summarize key contributions.\n\n### Contribution\n\n- propose an **item popularity-aware weighting** scheme on the full missing data that effectively tailors the MF model for learning from implicit feedback.  \n- develop a new algorithm for learning model parameters efficiently and devise an incremental update strategy to support real-time **online learning**.\n- conduct extensive experiments with both offline and online protocols on two real-world datasets, showing that our method consistently **outperforms** state-of-the-art implicit MF methods\n\n### Algorithm\n\n#### 1 Item-Oriented Weighting on Missing Data\n\n**Intution**: a popular item is more likely to be known by users, thus a missing on it is more probably that the user is not interested with it. \n\nOld design : Uniform weight\n$$\nL = \\sum_{(u,i) \\in R} w(r_{ui} - \\hat{r}_{ui})^2\n+ \\sum_{(u,i)\\notin R}\\hat{r}_{ui}^2\n+ \\lambda(\\sum_{u=1}^{M}\\|\\mathbb{p}_u\\|^2 + \\sum_{i=1}^N \\|\\mathbb{q}_i\\|^2)\n$$\nNew design: Non-uniform weighing \n$$\nL = \\sum_{(u,i) \\in R} w(r_{ui} - \\hat{r}_{ui})^2\n+ \\sum_{u=1}^M \\sum_{i\\notin R_u}c_i \\hat{r}_{ui}^2\n+ \\lambda(\\sum_{u=1}^{M}\\|\\mathbb{p}_u\\|^2 + \\sum_{i=1}^N \\|\\mathbb{q}_i\\|^2)\n$$\n where $c_i = c_0 \\frac{f_i^a}{\\sum_{j=1}^N f_j^a}$,  $f_i$ denotes the popularity of item $i$, given by its frequency in the implicit feedback data: $|R_i|/\\sum_{j=1}^N|R_j|$.\n\n#### 2 Fast eALS Learning Algorithm\n\ndevelop a Coordinate Descent learner to optimize the whole-data based MF \n\n- Element-wise Alternating Least Squares Learner (eALS)\n- Optimize one latent factor with others fixed (greedy exact optimization) \n\n#### 3 Online Incremental Learning\n\nnew interaction should changel the **local features**, while the global reamain largely unchanged.\n\n\n\n","slug":"Fast-Matrix-Factorization-for-Online-Recommendation-with-Implicit-Feedback","published":1,"updated":"2018-08-15T12:28:00.779Z","comments":1,"photos":[],"link":"","_id":"cjkv4owbt000bfb9ldzgz5660","content":"<blockquote>\n<p><a href=\"https://www.comp.nus.edu.sg/~xiangnan/papers/sigir16-eals-cm.pdf\" target=\"_blank\" rel=\"noopener\">Fast Matrix Factorization for Online Recommendation with Implicit Feedback</a></p>\n</blockquote>\n<a id=\"more\"></a>\n<h3 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h3><p>User Personalization has become prevalent in modern recommender system. Among its various methods, MF is important. Early work on MF have largely focused explicit feedback. (introduction of explict feedback and MF methods).</p>\n<p>However, explicit fimplictit ratings are not always avaliable in many applications: <strong>implicit feedback</strong>. (introduction of implicit feedback).</p>\n<p>(introduction of algorithm to solve implicit feedback). two challenging problem: <strong>implicit feedback</strong> and <strong>online  learning</strong>.</p>\n<p>introduction of our algorithm, summarize key contributions.</p>\n<h3 id=\"Contribution\"><a href=\"#Contribution\" class=\"headerlink\" title=\"Contribution\"></a>Contribution</h3><ul>\n<li>propose an <strong>item popularity-aware weighting</strong> scheme on the full missing data that effectively tailors the MF model for learning from implicit feedback.  </li>\n<li>develop a new algorithm for learning model parameters efficiently and devise an incremental update strategy to support real-time <strong>online learning</strong>.</li>\n<li>conduct extensive experiments with both offline and online protocols on two real-world datasets, showing that our method consistently <strong>outperforms</strong> state-of-the-art implicit MF methods</li>\n</ul>\n<h3 id=\"Algorithm\"><a href=\"#Algorithm\" class=\"headerlink\" title=\"Algorithm\"></a>Algorithm</h3><h4 id=\"1-Item-Oriented-Weighting-on-Missing-Data\"><a href=\"#1-Item-Oriented-Weighting-on-Missing-Data\" class=\"headerlink\" title=\"1 Item-Oriented Weighting on Missing Data\"></a>1 Item-Oriented Weighting on Missing Data</h4><p><strong>Intution</strong>: a popular item is more likely to be known by users, thus a missing on it is more probably that the user is not interested with it. </p>\n<p>Old design : Uniform weight</p>\n<script type=\"math/tex; mode=display\">\nL = \\sum_{(u,i) \\in R} w(r_{ui} - \\hat{r}_{ui})^2\n+ \\sum_{(u,i)\\notin R}\\hat{r}_{ui}^2\n+ \\lambda(\\sum_{u=1}^{M}\\|\\mathbb{p}_u\\|^2 + \\sum_{i=1}^N \\|\\mathbb{q}_i\\|^2)</script><p>New design: Non-uniform weighing </p>\n<script type=\"math/tex; mode=display\">\nL = \\sum_{(u,i) \\in R} w(r_{ui} - \\hat{r}_{ui})^2\n+ \\sum_{u=1}^M \\sum_{i\\notin R_u}c_i \\hat{r}_{ui}^2\n+ \\lambda(\\sum_{u=1}^{M}\\|\\mathbb{p}_u\\|^2 + \\sum_{i=1}^N \\|\\mathbb{q}_i\\|^2)</script><p> where $c_i = c_0 \\frac{f_i^a}{\\sum_{j=1}^N f_j^a}$,  $f_i$ denotes the popularity of item $i$, given by its frequency in the implicit feedback data: $|R_i|/\\sum_{j=1}^N|R_j|$.</p>\n<h4 id=\"2-Fast-eALS-Learning-Algorithm\"><a href=\"#2-Fast-eALS-Learning-Algorithm\" class=\"headerlink\" title=\"2 Fast eALS Learning Algorithm\"></a>2 Fast eALS Learning Algorithm</h4><p>develop a Coordinate Descent learner to optimize the whole-data based MF </p>\n<ul>\n<li>Element-wise Alternating Least Squares Learner (eALS)</li>\n<li>Optimize one latent factor with others fixed (greedy exact optimization) </li>\n</ul>\n<h4 id=\"3-Online-Incremental-Learning\"><a href=\"#3-Online-Incremental-Learning\" class=\"headerlink\" title=\"3 Online Incremental Learning\"></a>3 Online Incremental Learning</h4><p>new interaction should changel the <strong>local features</strong>, while the global reamain largely unchanged.</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p><a href=\"https://www.comp.nus.edu.sg/~xiangnan/papers/sigir16-eals-cm.pdf\" target=\"_blank\" rel=\"noopener\">Fast Matrix Factorization for Online Recommendation with Implicit Feedback</a></p>\n</blockquote>","more":"<h3 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h3><p>User Personalization has become prevalent in modern recommender system. Among its various methods, MF is important. Early work on MF have largely focused explicit feedback. (introduction of explict feedback and MF methods).</p>\n<p>However, explicit fimplictit ratings are not always avaliable in many applications: <strong>implicit feedback</strong>. (introduction of implicit feedback).</p>\n<p>(introduction of algorithm to solve implicit feedback). two challenging problem: <strong>implicit feedback</strong> and <strong>online  learning</strong>.</p>\n<p>introduction of our algorithm, summarize key contributions.</p>\n<h3 id=\"Contribution\"><a href=\"#Contribution\" class=\"headerlink\" title=\"Contribution\"></a>Contribution</h3><ul>\n<li>propose an <strong>item popularity-aware weighting</strong> scheme on the full missing data that effectively tailors the MF model for learning from implicit feedback.  </li>\n<li>develop a new algorithm for learning model parameters efficiently and devise an incremental update strategy to support real-time <strong>online learning</strong>.</li>\n<li>conduct extensive experiments with both offline and online protocols on two real-world datasets, showing that our method consistently <strong>outperforms</strong> state-of-the-art implicit MF methods</li>\n</ul>\n<h3 id=\"Algorithm\"><a href=\"#Algorithm\" class=\"headerlink\" title=\"Algorithm\"></a>Algorithm</h3><h4 id=\"1-Item-Oriented-Weighting-on-Missing-Data\"><a href=\"#1-Item-Oriented-Weighting-on-Missing-Data\" class=\"headerlink\" title=\"1 Item-Oriented Weighting on Missing Data\"></a>1 Item-Oriented Weighting on Missing Data</h4><p><strong>Intution</strong>: a popular item is more likely to be known by users, thus a missing on it is more probably that the user is not interested with it. </p>\n<p>Old design : Uniform weight</p>\n<script type=\"math/tex; mode=display\">\nL = \\sum_{(u,i) \\in R} w(r_{ui} - \\hat{r}_{ui})^2\n+ \\sum_{(u,i)\\notin R}\\hat{r}_{ui}^2\n+ \\lambda(\\sum_{u=1}^{M}\\|\\mathbb{p}_u\\|^2 + \\sum_{i=1}^N \\|\\mathbb{q}_i\\|^2)</script><p>New design: Non-uniform weighing </p>\n<script type=\"math/tex; mode=display\">\nL = \\sum_{(u,i) \\in R} w(r_{ui} - \\hat{r}_{ui})^2\n+ \\sum_{u=1}^M \\sum_{i\\notin R_u}c_i \\hat{r}_{ui}^2\n+ \\lambda(\\sum_{u=1}^{M}\\|\\mathbb{p}_u\\|^2 + \\sum_{i=1}^N \\|\\mathbb{q}_i\\|^2)</script><p> where $c_i = c_0 \\frac{f_i^a}{\\sum_{j=1}^N f_j^a}$,  $f_i$ denotes the popularity of item $i$, given by its frequency in the implicit feedback data: $|R_i|/\\sum_{j=1}^N|R_j|$.</p>\n<h4 id=\"2-Fast-eALS-Learning-Algorithm\"><a href=\"#2-Fast-eALS-Learning-Algorithm\" class=\"headerlink\" title=\"2 Fast eALS Learning Algorithm\"></a>2 Fast eALS Learning Algorithm</h4><p>develop a Coordinate Descent learner to optimize the whole-data based MF </p>\n<ul>\n<li>Element-wise Alternating Least Squares Learner (eALS)</li>\n<li>Optimize one latent factor with others fixed (greedy exact optimization) </li>\n</ul>\n<h4 id=\"3-Online-Incremental-Learning\"><a href=\"#3-Online-Incremental-Learning\" class=\"headerlink\" title=\"3 Online Incremental Learning\"></a>3 Online Incremental Learning</h4><p>new interaction should changel the <strong>local features</strong>, while the global reamain largely unchanged.</p>"},{"layout":"article","title":"Softmax and Cross Entropy Loss","date":"2018-04-11T03:01:08.000Z","_content":"\nintroduction and derivative of Softmax and Cross Entropy Loss.\n\n<!--more-->\n\n### Softmax function\n\nthe softmax function takes N-dimensional vector of real numbers and transforms it into a vector of real number in range of (0,1) which means the probability of each classification.\n$$\np_i=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\n$$\nit is easy to know  $\\sum_{k=1}^Np_i=1$ .\n\nthe code of softmax function in python:\n\n```python\ndef softmax(X):\n    exps = np.exp(X)\n    return exps / np.sum(exps)\n```\n\nsometimes the exp operation can overshot the limit of the floating point numbers in python, so we need to normalize the value by multiply a constant C.\n$$\np_i=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\n=\\frac{Ce^{a_i}}{C\\sum_{k=1}^Ne^{a_k}}\n=\\frac{e^{a_i+log(C)}}{\\sum_{k=1}^Ne^{a_k+log(C)}}\n$$\nGenerally, we max $log(C)=-max(a)$, so we need make a little change of our code:\n\n```python\ndef softmax(X):\n    exps = np.exp(X-np.max(X))\n    return exps / np.sum(exps)\n```\n\n###Cross Entropy Loss\n\nthe defination of cross entropy loss is:\n$$\nL=-\\sum_iy_i log(p_i)\n$$\nnote: \n\n$p_i$ means the softmax value of  i-th neuron  in fully connected layer;\n\nif the true label of input sample is $j$,  then $y_{i=j}=1;y_{i\\neq j}=0$.\n\nthe code of loss function in python:\n\n```python\ndef cross_entropy(X, y):\n    \"\"\"\n    X is the output of fully connected layer(N-dimensional vector)\n    y is true label(integer)\n    \"\"\"\n    p = softmax(X)\n    loss = -np.log(p[y])\n    return loss\n```\n\n### Backward propagation\n\nwe need to compute the derivative of cross entropy loss:\n$$\n\\frac{\\partial L}{\\partial a_i}=\\frac{\\partial L}{\\partial p_j}\\frac{\\partial p_j}{\\partial a_i}\n$$\nit is easy to compute $\\frac{\\partial L}{\\partial p_i}$\n$$\n\\frac{\\partial L}{\\partial p_i}=-\\sum_iy_i\\frac{1}{p_i}\\tag1\n$$\nthen compute $\\frac{\\partial p_j}{\\partial a_i}$, we need to divide it into two situations：\n\n1. if $i=j$\n\n$$\n\\begin{align*}\n\\frac{\\partial p_j}{\\partial a_i}&=\\frac{\\partial p_i}{\\partial a_i}=\\frac{\\partial{\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}}}{\\partial a_i}=\\frac{\\sum_{k=1}^{N}e^{a_i}e^{a_k}-(e^{a_i})^2}{(\\sum_{k=1}^Ne^{a_k})^2}\\\\\n&=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\\left(1-\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\\right)\\\\\n&=p_i(1-p_i)\n\\end{align*}\n$$\n\n\n\n2. If $i\\neq j$\n\n$$\n\\frac{\\partial p_j}{\\partial a_i}=\\frac{\\partial{\\frac{e^{a_j}}{\\sum_{k=1}^Ne^{a_k}}}}{\\partial a_i}=\n-\\frac{e^{a_j}}{\\sum_{k=1}^Ne^{a_k}}\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}=-p_jp_i\\tag2\n$$\n\ncombine the result of (1) and (2)\n$$\n\\begin{align*}\n\\frac{\\partial L}{\\partial a_i}& = \\left(-\\sum_iy_i\\frac{1}{p_i}\\right)\\frac{\\partial p_i}{\\partial a_i}\\\\\n&=-\\frac{y_i}{p_i}p_i(1-p_i)+\\sum_{i\\neq j}\\frac{y_i}{p_i}p_ip_j\\\\\n&=-y_i+y_ip_i+\\sum_{i\\neq j}y_ip_i\\\\\n&=-y_i+p_i\\sum_iy_i\\\\\n&=p_i-y_i\n\\end{align*}\n$$\ncode in python\n\n```python\ndef delta_entropy(X,y):\n    \"\"\"\n    X is the output of fully connected layer(N-dimensional vector)\n    y is true labels(integer)\n    \"\"\"\n    grad = softmax(X)\n    grad[y] -= 1\n    return grad\n```\n\n\n\n\n\n\n\n\n\n","source":"_posts/Softmax-and-Cross-Entropy-Loss.md","raw":"---\nlayout: article\ntitle: Softmax and Cross Entropy Loss\ndate: 2018-04-11 11:01:08\ntags: softmax\ncategories: [artificial intelligence]\n---\n\nintroduction and derivative of Softmax and Cross Entropy Loss.\n\n<!--more-->\n\n### Softmax function\n\nthe softmax function takes N-dimensional vector of real numbers and transforms it into a vector of real number in range of (0,1) which means the probability of each classification.\n$$\np_i=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\n$$\nit is easy to know  $\\sum_{k=1}^Np_i=1$ .\n\nthe code of softmax function in python:\n\n```python\ndef softmax(X):\n    exps = np.exp(X)\n    return exps / np.sum(exps)\n```\n\nsometimes the exp operation can overshot the limit of the floating point numbers in python, so we need to normalize the value by multiply a constant C.\n$$\np_i=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\n=\\frac{Ce^{a_i}}{C\\sum_{k=1}^Ne^{a_k}}\n=\\frac{e^{a_i+log(C)}}{\\sum_{k=1}^Ne^{a_k+log(C)}}\n$$\nGenerally, we max $log(C)=-max(a)$, so we need make a little change of our code:\n\n```python\ndef softmax(X):\n    exps = np.exp(X-np.max(X))\n    return exps / np.sum(exps)\n```\n\n###Cross Entropy Loss\n\nthe defination of cross entropy loss is:\n$$\nL=-\\sum_iy_i log(p_i)\n$$\nnote: \n\n$p_i$ means the softmax value of  i-th neuron  in fully connected layer;\n\nif the true label of input sample is $j$,  then $y_{i=j}=1;y_{i\\neq j}=0$.\n\nthe code of loss function in python:\n\n```python\ndef cross_entropy(X, y):\n    \"\"\"\n    X is the output of fully connected layer(N-dimensional vector)\n    y is true label(integer)\n    \"\"\"\n    p = softmax(X)\n    loss = -np.log(p[y])\n    return loss\n```\n\n### Backward propagation\n\nwe need to compute the derivative of cross entropy loss:\n$$\n\\frac{\\partial L}{\\partial a_i}=\\frac{\\partial L}{\\partial p_j}\\frac{\\partial p_j}{\\partial a_i}\n$$\nit is easy to compute $\\frac{\\partial L}{\\partial p_i}$\n$$\n\\frac{\\partial L}{\\partial p_i}=-\\sum_iy_i\\frac{1}{p_i}\\tag1\n$$\nthen compute $\\frac{\\partial p_j}{\\partial a_i}$, we need to divide it into two situations：\n\n1. if $i=j$\n\n$$\n\\begin{align*}\n\\frac{\\partial p_j}{\\partial a_i}&=\\frac{\\partial p_i}{\\partial a_i}=\\frac{\\partial{\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}}}{\\partial a_i}=\\frac{\\sum_{k=1}^{N}e^{a_i}e^{a_k}-(e^{a_i})^2}{(\\sum_{k=1}^Ne^{a_k})^2}\\\\\n&=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\\left(1-\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\\right)\\\\\n&=p_i(1-p_i)\n\\end{align*}\n$$\n\n\n\n2. If $i\\neq j$\n\n$$\n\\frac{\\partial p_j}{\\partial a_i}=\\frac{\\partial{\\frac{e^{a_j}}{\\sum_{k=1}^Ne^{a_k}}}}{\\partial a_i}=\n-\\frac{e^{a_j}}{\\sum_{k=1}^Ne^{a_k}}\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}=-p_jp_i\\tag2\n$$\n\ncombine the result of (1) and (2)\n$$\n\\begin{align*}\n\\frac{\\partial L}{\\partial a_i}& = \\left(-\\sum_iy_i\\frac{1}{p_i}\\right)\\frac{\\partial p_i}{\\partial a_i}\\\\\n&=-\\frac{y_i}{p_i}p_i(1-p_i)+\\sum_{i\\neq j}\\frac{y_i}{p_i}p_ip_j\\\\\n&=-y_i+y_ip_i+\\sum_{i\\neq j}y_ip_i\\\\\n&=-y_i+p_i\\sum_iy_i\\\\\n&=p_i-y_i\n\\end{align*}\n$$\ncode in python\n\n```python\ndef delta_entropy(X,y):\n    \"\"\"\n    X is the output of fully connected layer(N-dimensional vector)\n    y is true labels(integer)\n    \"\"\"\n    grad = softmax(X)\n    grad[y] -= 1\n    return grad\n```\n\n\n\n\n\n\n\n\n\n","slug":"Softmax-and-Cross-Entropy-Loss","published":1,"updated":"2018-04-28T09:38:13.306Z","comments":1,"photos":[],"link":"","_id":"cjkv4owbu000dfb9ld8oarcb4","content":"<p>introduction and derivative of Softmax and Cross Entropy Loss.</p>\n<a id=\"more\"></a>\n<h3 id=\"Softmax-function\"><a href=\"#Softmax-function\" class=\"headerlink\" title=\"Softmax function\"></a>Softmax function</h3><p>the softmax function takes N-dimensional vector of real numbers and transforms it into a vector of real number in range of (0,1) which means the probability of each classification.</p>\n<script type=\"math/tex; mode=display\">\np_i=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}</script><p>it is easy to know  $\\sum_{k=1}^Np_i=1$ .</p>\n<p>the code of softmax function in python:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">softmax</span><span class=\"params\">(X)</span>:</span></span><br><span class=\"line\">    exps = np.exp(X)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> exps / np.sum(exps)</span><br></pre></td></tr></table></figure>\n<p>sometimes the exp operation can overshot the limit of the floating point numbers in python, so we need to normalize the value by multiply a constant C.</p>\n<script type=\"math/tex; mode=display\">\np_i=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\n=\\frac{Ce^{a_i}}{C\\sum_{k=1}^Ne^{a_k}}\n=\\frac{e^{a_i+log(C)}}{\\sum_{k=1}^Ne^{a_k+log(C)}}</script><p>Generally, we max $log(C)=-max(a)$, so we need make a little change of our code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">softmax</span><span class=\"params\">(X)</span>:</span></span><br><span class=\"line\">    exps = np.exp(X-np.max(X))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> exps / np.sum(exps)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Cross-Entropy-Loss\"><a href=\"#Cross-Entropy-Loss\" class=\"headerlink\" title=\"Cross Entropy Loss\"></a>Cross Entropy Loss</h3><p>the defination of cross entropy loss is:</p>\n<script type=\"math/tex; mode=display\">\nL=-\\sum_iy_i log(p_i)</script><p>note: </p>\n<p>$p_i$ means the softmax value of  i-th neuron  in fully connected layer;</p>\n<p>if the true label of input sample is $j$,  then $y_{i=j}=1;y_{i\\neq j}=0$.</p>\n<p>the code of loss function in python:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cross_entropy</span><span class=\"params\">(X, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    X is the output of fully connected layer(N-dimensional vector)</span></span><br><span class=\"line\"><span class=\"string\">    y is true label(integer)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    p = softmax(X)</span><br><span class=\"line\">    loss = -np.log(p[y])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss</span><br></pre></td></tr></table></figure>\n<h3 id=\"Backward-propagation\"><a href=\"#Backward-propagation\" class=\"headerlink\" title=\"Backward propagation\"></a>Backward propagation</h3><p>we need to compute the derivative of cross entropy loss:</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial L}{\\partial a_i}=\\frac{\\partial L}{\\partial p_j}\\frac{\\partial p_j}{\\partial a_i}</script><p>it is easy to compute $\\frac{\\partial L}{\\partial p_i}$</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial L}{\\partial p_i}=-\\sum_iy_i\\frac{1}{p_i}\\tag1</script><p>then compute $\\frac{\\partial p_j}{\\partial a_i}$, we need to divide it into two situations：</p>\n<ol>\n<li>if $i=j$</li>\n</ol>\n<script type=\"math/tex; mode=display\">\n\\begin{align*}\n\\frac{\\partial p_j}{\\partial a_i}&=\\frac{\\partial p_i}{\\partial a_i}=\\frac{\\partial{\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}}}{\\partial a_i}=\\frac{\\sum_{k=1}^{N}e^{a_i}e^{a_k}-(e^{a_i})^2}{(\\sum_{k=1}^Ne^{a_k})^2}\\\\\n&=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\\left(1-\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\\right)\\\\\n&=p_i(1-p_i)\n\\end{align*}</script><ol>\n<li>If $i\\neq j$</li>\n</ol>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial p_j}{\\partial a_i}=\\frac{\\partial{\\frac{e^{a_j}}{\\sum_{k=1}^Ne^{a_k}}}}{\\partial a_i}=\n-\\frac{e^{a_j}}{\\sum_{k=1}^Ne^{a_k}}\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}=-p_jp_i\\tag2</script><p>combine the result of (1) and (2)</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align*}\n\\frac{\\partial L}{\\partial a_i}& = \\left(-\\sum_iy_i\\frac{1}{p_i}\\right)\\frac{\\partial p_i}{\\partial a_i}\\\\\n&=-\\frac{y_i}{p_i}p_i(1-p_i)+\\sum_{i\\neq j}\\frac{y_i}{p_i}p_ip_j\\\\\n&=-y_i+y_ip_i+\\sum_{i\\neq j}y_ip_i\\\\\n&=-y_i+p_i\\sum_iy_i\\\\\n&=p_i-y_i\n\\end{align*}</script><p>code in python</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">delta_entropy</span><span class=\"params\">(X,y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    X is the output of fully connected layer(N-dimensional vector)</span></span><br><span class=\"line\"><span class=\"string\">    y is true labels(integer)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    grad = softmax(X)</span><br><span class=\"line\">    grad[y] -= <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> grad</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>introduction and derivative of Softmax and Cross Entropy Loss.</p>","more":"<h3 id=\"Softmax-function\"><a href=\"#Softmax-function\" class=\"headerlink\" title=\"Softmax function\"></a>Softmax function</h3><p>the softmax function takes N-dimensional vector of real numbers and transforms it into a vector of real number in range of (0,1) which means the probability of each classification.</p>\n<script type=\"math/tex; mode=display\">\np_i=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}</script><p>it is easy to know  $\\sum_{k=1}^Np_i=1$ .</p>\n<p>the code of softmax function in python:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">softmax</span><span class=\"params\">(X)</span>:</span></span><br><span class=\"line\">    exps = np.exp(X)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> exps / np.sum(exps)</span><br></pre></td></tr></table></figure>\n<p>sometimes the exp operation can overshot the limit of the floating point numbers in python, so we need to normalize the value by multiply a constant C.</p>\n<script type=\"math/tex; mode=display\">\np_i=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\n=\\frac{Ce^{a_i}}{C\\sum_{k=1}^Ne^{a_k}}\n=\\frac{e^{a_i+log(C)}}{\\sum_{k=1}^Ne^{a_k+log(C)}}</script><p>Generally, we max $log(C)=-max(a)$, so we need make a little change of our code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">softmax</span><span class=\"params\">(X)</span>:</span></span><br><span class=\"line\">    exps = np.exp(X-np.max(X))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> exps / np.sum(exps)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Cross-Entropy-Loss\"><a href=\"#Cross-Entropy-Loss\" class=\"headerlink\" title=\"Cross Entropy Loss\"></a>Cross Entropy Loss</h3><p>the defination of cross entropy loss is:</p>\n<script type=\"math/tex; mode=display\">\nL=-\\sum_iy_i log(p_i)</script><p>note: </p>\n<p>$p_i$ means the softmax value of  i-th neuron  in fully connected layer;</p>\n<p>if the true label of input sample is $j$,  then $y_{i=j}=1;y_{i\\neq j}=0$.</p>\n<p>the code of loss function in python:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cross_entropy</span><span class=\"params\">(X, y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    X is the output of fully connected layer(N-dimensional vector)</span></span><br><span class=\"line\"><span class=\"string\">    y is true label(integer)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    p = softmax(X)</span><br><span class=\"line\">    loss = -np.log(p[y])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss</span><br></pre></td></tr></table></figure>\n<h3 id=\"Backward-propagation\"><a href=\"#Backward-propagation\" class=\"headerlink\" title=\"Backward propagation\"></a>Backward propagation</h3><p>we need to compute the derivative of cross entropy loss:</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial L}{\\partial a_i}=\\frac{\\partial L}{\\partial p_j}\\frac{\\partial p_j}{\\partial a_i}</script><p>it is easy to compute $\\frac{\\partial L}{\\partial p_i}$</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial L}{\\partial p_i}=-\\sum_iy_i\\frac{1}{p_i}\\tag1</script><p>then compute $\\frac{\\partial p_j}{\\partial a_i}$, we need to divide it into two situations：</p>\n<ol>\n<li>if $i=j$</li>\n</ol>\n<script type=\"math/tex; mode=display\">\n\\begin{align*}\n\\frac{\\partial p_j}{\\partial a_i}&=\\frac{\\partial p_i}{\\partial a_i}=\\frac{\\partial{\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}}}{\\partial a_i}=\\frac{\\sum_{k=1}^{N}e^{a_i}e^{a_k}-(e^{a_i})^2}{(\\sum_{k=1}^Ne^{a_k})^2}\\\\\n&=\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\\left(1-\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}\\right)\\\\\n&=p_i(1-p_i)\n\\end{align*}</script><ol>\n<li>If $i\\neq j$</li>\n</ol>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial p_j}{\\partial a_i}=\\frac{\\partial{\\frac{e^{a_j}}{\\sum_{k=1}^Ne^{a_k}}}}{\\partial a_i}=\n-\\frac{e^{a_j}}{\\sum_{k=1}^Ne^{a_k}}\\frac{e^{a_i}}{\\sum_{k=1}^Ne^{a_k}}=-p_jp_i\\tag2</script><p>combine the result of (1) and (2)</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align*}\n\\frac{\\partial L}{\\partial a_i}& = \\left(-\\sum_iy_i\\frac{1}{p_i}\\right)\\frac{\\partial p_i}{\\partial a_i}\\\\\n&=-\\frac{y_i}{p_i}p_i(1-p_i)+\\sum_{i\\neq j}\\frac{y_i}{p_i}p_ip_j\\\\\n&=-y_i+y_ip_i+\\sum_{i\\neq j}y_ip_i\\\\\n&=-y_i+p_i\\sum_iy_i\\\\\n&=p_i-y_i\n\\end{align*}</script><p>code in python</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">delta_entropy</span><span class=\"params\">(X,y)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    X is the output of fully connected layer(N-dimensional vector)</span></span><br><span class=\"line\"><span class=\"string\">    y is true labels(integer)</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    grad = softmax(X)</span><br><span class=\"line\">    grad[y] -= <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> grad</span><br></pre></td></tr></table></figure>"},{"title":"ZELDA-男人的浪漫","date":"2018-03-19T07:34:32.000Z","_content":"\n如果一款游戏，如果能让你回到儿时，你会去玩吗？\n\n<!-- more -->\n\n游戏时间 100 小时，四神兽和boss全灭，120神庙解锁一半，支线任务完成1/4。\n\n拿到游戏到现在过去了10天，除了实习时间，我几乎都在玩这款游戏，这段时间我没有看动漫，甚至连手机都懒得碰。直到现在，在天气晴朗的时候，登上海拉尔大陆的顶端远眺，留给我的依旧是无数秘密。\n\n![9c29d14f-ae6e-42b4-9c36-c1f81c9217af](http://oygov02sc.bkt.clouddn.com/9c29d14f-ae6e-42b4-9c36-c1f81c9217af.jpg)\n\n我无法忘记游戏开始走出出生地的震撼，一个广阔的大陆等着你探索。作为一个普通玩家，或许无法从专业性的角度去阐述这款游戏的优秀，但是我可以慢慢的回想我在游戏中的故事。\n\n开放世界、沙盒玩法可以说是游戏界经常提到的概念，在我以前玩的游戏中，我按照游戏设计者设计好的路线去解锁游戏，在这个过程中，总是会有一种压迫感，游戏设计者在不停的推着我前进。终于，游戏主线支线结束，站在广阔的地图上，我却不知道干什么。\n\n荒野之息却完全不同，游戏剧情“老套”，主线就是打魔王救公主。在游戏的过程中，我却忘记了主线，沉迷于爬山，炸鱼，采矿，做菜等等等等。看到一座很高的山，我费劲力气爬上去，只为看到更好的风景。为发现隐藏在海拉尔大陆的120个神庙而惊喜，进入神庙后又是另一番体验。就连npc都设计的非常巧妙，记得有一个npc，她对我说：“别摸鱼了，快去拯救世界”，令人爆笑。如果这些还不够，还有900个“呀哈哈”等着你去寻找，可能在石头下，也可能在山顶上。\n\n在大概两天后，我终于想起了公主，于是我开始进入主线，四大神兽每个都有不同的故事和解谜方式，不会让人厌烦。打败四大神兽后，我又开始收集13个回忆，慢慢的找到了所有林克和公主的故事，一个傲娇的公主是怎么慢慢成长，怎么喜欢上我的（笑）。接着就是面对最终boss加农了，这时候我却不想推进了，我不想结束这段旅行，还有那么多神庙没有解锁，那么多支线没有做，现在打boss总有种半途而废的感觉。不过游戏总有分别，又过了两天，我带着全村最好的剑，最好的弓，最好的盾，最好的药冲到boss，然后boss就死了，一段回忆后游戏戛然而止······\n\n在这段时间，做梦的时候我总是会梦到游戏剧情，在室外的时候，看到高楼大厦，我也不经意的会思考怎么爬上去，爬上去会看到什么样的风景。现在我大概知道为什么会沉迷这款游戏了，大概是这款游戏满足了我所有的浪漫。\n\n在童年时候，我会为钓到小鱼小虾而激动，会为爬到大坝上而激动。那时候会做梦，觉得自己是个大侠、冒险家。和小伙伴们去野外（隔壁村）探险，会去招惹村口的凶狗，会骑姥姥家养的小花狗。实际上，直到现在我还想做这些事，还对其乐此不疲，只不过没人陪我了。是的，我长大了，虽然还在校园，但烦恼却不少。所以，我感谢这款游戏，让我找到了冒险的感觉，为游戏中每一个新事物，为前方而满怀期待！\n\n最后，塞尔达天下第一！","source":"_posts/ZELDA-男人的浪漫.md","raw":"---\ntitle: ZELDA-男人的浪漫\ndate: 2018-03-19 15:34:32\ntags: 游戏\ncategories: 杂谈\n---\n\n如果一款游戏，如果能让你回到儿时，你会去玩吗？\n\n<!-- more -->\n\n游戏时间 100 小时，四神兽和boss全灭，120神庙解锁一半，支线任务完成1/4。\n\n拿到游戏到现在过去了10天，除了实习时间，我几乎都在玩这款游戏，这段时间我没有看动漫，甚至连手机都懒得碰。直到现在，在天气晴朗的时候，登上海拉尔大陆的顶端远眺，留给我的依旧是无数秘密。\n\n![9c29d14f-ae6e-42b4-9c36-c1f81c9217af](http://oygov02sc.bkt.clouddn.com/9c29d14f-ae6e-42b4-9c36-c1f81c9217af.jpg)\n\n我无法忘记游戏开始走出出生地的震撼，一个广阔的大陆等着你探索。作为一个普通玩家，或许无法从专业性的角度去阐述这款游戏的优秀，但是我可以慢慢的回想我在游戏中的故事。\n\n开放世界、沙盒玩法可以说是游戏界经常提到的概念，在我以前玩的游戏中，我按照游戏设计者设计好的路线去解锁游戏，在这个过程中，总是会有一种压迫感，游戏设计者在不停的推着我前进。终于，游戏主线支线结束，站在广阔的地图上，我却不知道干什么。\n\n荒野之息却完全不同，游戏剧情“老套”，主线就是打魔王救公主。在游戏的过程中，我却忘记了主线，沉迷于爬山，炸鱼，采矿，做菜等等等等。看到一座很高的山，我费劲力气爬上去，只为看到更好的风景。为发现隐藏在海拉尔大陆的120个神庙而惊喜，进入神庙后又是另一番体验。就连npc都设计的非常巧妙，记得有一个npc，她对我说：“别摸鱼了，快去拯救世界”，令人爆笑。如果这些还不够，还有900个“呀哈哈”等着你去寻找，可能在石头下，也可能在山顶上。\n\n在大概两天后，我终于想起了公主，于是我开始进入主线，四大神兽每个都有不同的故事和解谜方式，不会让人厌烦。打败四大神兽后，我又开始收集13个回忆，慢慢的找到了所有林克和公主的故事，一个傲娇的公主是怎么慢慢成长，怎么喜欢上我的（笑）。接着就是面对最终boss加农了，这时候我却不想推进了，我不想结束这段旅行，还有那么多神庙没有解锁，那么多支线没有做，现在打boss总有种半途而废的感觉。不过游戏总有分别，又过了两天，我带着全村最好的剑，最好的弓，最好的盾，最好的药冲到boss，然后boss就死了，一段回忆后游戏戛然而止······\n\n在这段时间，做梦的时候我总是会梦到游戏剧情，在室外的时候，看到高楼大厦，我也不经意的会思考怎么爬上去，爬上去会看到什么样的风景。现在我大概知道为什么会沉迷这款游戏了，大概是这款游戏满足了我所有的浪漫。\n\n在童年时候，我会为钓到小鱼小虾而激动，会为爬到大坝上而激动。那时候会做梦，觉得自己是个大侠、冒险家。和小伙伴们去野外（隔壁村）探险，会去招惹村口的凶狗，会骑姥姥家养的小花狗。实际上，直到现在我还想做这些事，还对其乐此不疲，只不过没人陪我了。是的，我长大了，虽然还在校园，但烦恼却不少。所以，我感谢这款游戏，让我找到了冒险的感觉，为游戏中每一个新事物，为前方而满怀期待！\n\n最后，塞尔达天下第一！","slug":"ZELDA-男人的浪漫","published":1,"updated":"2018-03-19T07:41:27.318Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owbw000ifb9l4wqxjcde","content":"<p>如果一款游戏，如果能让你回到儿时，你会去玩吗？</p>\n<a id=\"more\"></a>\n<p>游戏时间 100 小时，四神兽和boss全灭，120神庙解锁一半，支线任务完成1/4。</p>\n<p>拿到游戏到现在过去了10天，除了实习时间，我几乎都在玩这款游戏，这段时间我没有看动漫，甚至连手机都懒得碰。直到现在，在天气晴朗的时候，登上海拉尔大陆的顶端远眺，留给我的依旧是无数秘密。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/9c29d14f-ae6e-42b4-9c36-c1f81c9217af.jpg\" alt=\"9c29d14f-ae6e-42b4-9c36-c1f81c9217af\"></p>\n<p>我无法忘记游戏开始走出出生地的震撼，一个广阔的大陆等着你探索。作为一个普通玩家，或许无法从专业性的角度去阐述这款游戏的优秀，但是我可以慢慢的回想我在游戏中的故事。</p>\n<p>开放世界、沙盒玩法可以说是游戏界经常提到的概念，在我以前玩的游戏中，我按照游戏设计者设计好的路线去解锁游戏，在这个过程中，总是会有一种压迫感，游戏设计者在不停的推着我前进。终于，游戏主线支线结束，站在广阔的地图上，我却不知道干什么。</p>\n<p>荒野之息却完全不同，游戏剧情“老套”，主线就是打魔王救公主。在游戏的过程中，我却忘记了主线，沉迷于爬山，炸鱼，采矿，做菜等等等等。看到一座很高的山，我费劲力气爬上去，只为看到更好的风景。为发现隐藏在海拉尔大陆的120个神庙而惊喜，进入神庙后又是另一番体验。就连npc都设计的非常巧妙，记得有一个npc，她对我说：“别摸鱼了，快去拯救世界”，令人爆笑。如果这些还不够，还有900个“呀哈哈”等着你去寻找，可能在石头下，也可能在山顶上。</p>\n<p>在大概两天后，我终于想起了公主，于是我开始进入主线，四大神兽每个都有不同的故事和解谜方式，不会让人厌烦。打败四大神兽后，我又开始收集13个回忆，慢慢的找到了所有林克和公主的故事，一个傲娇的公主是怎么慢慢成长，怎么喜欢上我的（笑）。接着就是面对最终boss加农了，这时候我却不想推进了，我不想结束这段旅行，还有那么多神庙没有解锁，那么多支线没有做，现在打boss总有种半途而废的感觉。不过游戏总有分别，又过了两天，我带着全村最好的剑，最好的弓，最好的盾，最好的药冲到boss，然后boss就死了，一段回忆后游戏戛然而止······</p>\n<p>在这段时间，做梦的时候我总是会梦到游戏剧情，在室外的时候，看到高楼大厦，我也不经意的会思考怎么爬上去，爬上去会看到什么样的风景。现在我大概知道为什么会沉迷这款游戏了，大概是这款游戏满足了我所有的浪漫。</p>\n<p>在童年时候，我会为钓到小鱼小虾而激动，会为爬到大坝上而激动。那时候会做梦，觉得自己是个大侠、冒险家。和小伙伴们去野外（隔壁村）探险，会去招惹村口的凶狗，会骑姥姥家养的小花狗。实际上，直到现在我还想做这些事，还对其乐此不疲，只不过没人陪我了。是的，我长大了，虽然还在校园，但烦恼却不少。所以，我感谢这款游戏，让我找到了冒险的感觉，为游戏中每一个新事物，为前方而满怀期待！</p>\n<p>最后，塞尔达天下第一！</p>\n","site":{"data":{}},"excerpt":"<p>如果一款游戏，如果能让你回到儿时，你会去玩吗？</p>","more":"<p>游戏时间 100 小时，四神兽和boss全灭，120神庙解锁一半，支线任务完成1/4。</p>\n<p>拿到游戏到现在过去了10天，除了实习时间，我几乎都在玩这款游戏，这段时间我没有看动漫，甚至连手机都懒得碰。直到现在，在天气晴朗的时候，登上海拉尔大陆的顶端远眺，留给我的依旧是无数秘密。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/9c29d14f-ae6e-42b4-9c36-c1f81c9217af.jpg\" alt=\"9c29d14f-ae6e-42b4-9c36-c1f81c9217af\"></p>\n<p>我无法忘记游戏开始走出出生地的震撼，一个广阔的大陆等着你探索。作为一个普通玩家，或许无法从专业性的角度去阐述这款游戏的优秀，但是我可以慢慢的回想我在游戏中的故事。</p>\n<p>开放世界、沙盒玩法可以说是游戏界经常提到的概念，在我以前玩的游戏中，我按照游戏设计者设计好的路线去解锁游戏，在这个过程中，总是会有一种压迫感，游戏设计者在不停的推着我前进。终于，游戏主线支线结束，站在广阔的地图上，我却不知道干什么。</p>\n<p>荒野之息却完全不同，游戏剧情“老套”，主线就是打魔王救公主。在游戏的过程中，我却忘记了主线，沉迷于爬山，炸鱼，采矿，做菜等等等等。看到一座很高的山，我费劲力气爬上去，只为看到更好的风景。为发现隐藏在海拉尔大陆的120个神庙而惊喜，进入神庙后又是另一番体验。就连npc都设计的非常巧妙，记得有一个npc，她对我说：“别摸鱼了，快去拯救世界”，令人爆笑。如果这些还不够，还有900个“呀哈哈”等着你去寻找，可能在石头下，也可能在山顶上。</p>\n<p>在大概两天后，我终于想起了公主，于是我开始进入主线，四大神兽每个都有不同的故事和解谜方式，不会让人厌烦。打败四大神兽后，我又开始收集13个回忆，慢慢的找到了所有林克和公主的故事，一个傲娇的公主是怎么慢慢成长，怎么喜欢上我的（笑）。接着就是面对最终boss加农了，这时候我却不想推进了，我不想结束这段旅行，还有那么多神庙没有解锁，那么多支线没有做，现在打boss总有种半途而废的感觉。不过游戏总有分别，又过了两天，我带着全村最好的剑，最好的弓，最好的盾，最好的药冲到boss，然后boss就死了，一段回忆后游戏戛然而止······</p>\n<p>在这段时间，做梦的时候我总是会梦到游戏剧情，在室外的时候，看到高楼大厦，我也不经意的会思考怎么爬上去，爬上去会看到什么样的风景。现在我大概知道为什么会沉迷这款游戏了，大概是这款游戏满足了我所有的浪漫。</p>\n<p>在童年时候，我会为钓到小鱼小虾而激动，会为爬到大坝上而激动。那时候会做梦，觉得自己是个大侠、冒险家。和小伙伴们去野外（隔壁村）探险，会去招惹村口的凶狗，会骑姥姥家养的小花狗。实际上，直到现在我还想做这些事，还对其乐此不疲，只不过没人陪我了。是的，我长大了，虽然还在校园，但烦恼却不少。所以，我感谢这款游戏，让我找到了冒险的感觉，为游戏中每一个新事物，为前方而满怀期待！</p>\n<p>最后，塞尔达天下第一！</p>"},{"layout":"title","title":"google map 比例尺算法分析","date":"2017-12-24T05:26:14.000Z","_content":"\n比例尺即地图右下角显示地图距离与实际距离比例的控件，由于Google map自带比例尺控件存在的局限性——无法调整位置和格式，所以通过此文章，介绍比例尺算法及具体实现。\n\n<!-- more -->\n\n### 什么是比例尺\n\n比例尺是表示[图上距离](http://baike.baidu.com/view/5454725.htm)比实地距离缩小的程度，因此也叫[缩尺](http://baike.baidu.com/view/1559050.htm)。用公式表示为：比例尺=[图上距离](http://baike.baidu.com/view/5454725.htm)/实地距离。在Google map上比例尺显示在右下角，如下图\n\n![](http://oygov02sc.bkt.clouddn.com/google%20map%20%E6%AF%94%E4%BE%8B%E5%B0%BA%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90-1.png)\n\n在创建地图时只需增加设置项\n\n```\nscaleControl: true\n```\n\n如下例\n\n{% jsfiddle yinxiaojian/yL9mxdzp %}\n\n遗憾的是这样添加的比例尺会存在于右下角，而且不像其他控件一样可以调整位置。如果我们希望修改其位置或者样式，就会无从下手。\n\n### 自制比例尺\n\n实现一个比例尺的关键在于如何获取到地图距离与实际距离的比例和缩放等级及维度之间的关系。google官方api未提供相关函数，因此我们需要自己计算。核心公式为\n\n```\nScaleValue = 156543.03392 * Math.cos(latLng.lat() * Math.PI / 180) / Math.pow(2, zoom)\n```\n\n其中zoom为当前缩放等级，latLng.lat()即目标点维度值。该公式是在地球半径为6378137m的基础上计算的，这个值即google地图所采用的值。\n\n有了计算公式后，我们还需要一张表——缩放等级和比例尺对应表，也就是在什么样的缩放等级下使用多大的比例尺，表格如下:\n\n```\nZoom    Scale\n0    10000km\n1    5000km\n2    2000km\n3    1000km\n4    500km\n5    200km\n6    200km\n7    100km\n8    50km\n9    20km\n10   10km\n11   5km\n12   2km\n13   1km\n14   500m\n15   200m\n16   200m\n17   100m\n18   50m\n19   20m\n20   10m\n21   5m\n22   2m\n23   1m\n24   1m\n25   1m\n26   1m\n```\n\n通过监听地图变化事件（缩放和平移），获取当前屏幕中心点缩放等级和维度获取到scale和scalevalue，那么比例尺的长度（px） = scale/scalevalue。\n\n获取当前比例尺长度的核心代码如下：\n\n```javascript\n/**\n * 根据缩放等级和维度获取KM数(m数)和像素\n */\nfunction setScaleInfos(zoomLevel, lat, map) {\n\t// 缩放等级-比例尺\n\tvar zoomList = [{\n\t\ttext: \"10000KM\",\n\t\tvalue: 10000 * 1000\n\t}, {\n\t\ttext: \"5000KM\",\n\t\tvalue: 5000 * 1000\n\t}, {\n\t\ttext: \"2000KM\",\n\t\tvalue: 2000 * 1000\n\t}, {\n\t\ttext: \"1000KM\",\n\t\tvalue: 1000 * 1000\n\t}, {\n\t\ttext: \"500KM\",\n\t\tvalue: 500 * 1000\n\t}, {\n\t\ttext: \"200KM\",\n\t\tvalue: 200 * 1000\n\t}, {\n\t\ttext: \"200KM\",\n\t\tvalue: 200 * 1000\n\t}, {\n\t\ttext: \"100KM\",\n\t\tvalue: 100 * 1000\n\t}, {\n\t\ttext: \"50KM\",\n\t\tvalue: 50 * 1000\n\t}, {\n\t\ttext: \"20KM\",\n\t\tvalue: 20 * 1000\n\t}, {\n\t\ttext: \"10KM\",\n\t\tvalue: 10 * 1000\n\t}, {\n\t\ttext: \"5KM\",\n\t\tvalue: 5000\n\t}, {\n\t\ttext: \"2KM\",\n\t\tvalue: 2000\n\t}, {\n\t\ttext: \"1KM\",\n\t\tvalue: 1000\n\t}, {\n\t\ttext: \"500m\",\n\t\tvalue: 500\n\t}, {\n\t\ttext: \"200m\",\n\t\tvalue: 200\n\t}, {\n\t\ttext: \"200m\",\n\t\tvalue: 200\n\t}, {\n\t\ttext: \"100m\",\n\t\tvalue: 100\n\t}, {\n\t\ttext: \"50m\",\n\t\tvalue: 50\n\t}, {\n\t\ttext: \"20m\",\n\t\tvalue: 20\n\t}, {\n\t\ttext: \"10m\",\n\t\tvalue: 10\n\t}, {\n\t\ttext: \"5m\",\n\t\tvalue: 5\n\t}, {\n\t\ttext: \"2m\",\n\t\tvalue: 2\n\t}, {\n\t\ttext: \"1m\",\n\t\tvalue: 1\n\t}, {\n\t\ttext: \"1m\",\n\t\tvalue: 1\n\t}, {\n\t\ttext: \"1m\",\n\t\tvalue: 1\n\t}, {\n\t\ttext: \"1m\",\n\t\tvalue: 1\n\t}];\n\t// 宽度\n\tvar pxValue = Math.floor(zoomList[zoomLevel].value / (156543.03392 * Math.cos(lat * Math.PI / 180) / Math.pow(2, zoomLevel)));\n\t// 更新经纬度数据\n\t$W.id(\"scaleText\").innerHTML = zoomList[zoomLevel].text;\n\t$W.id(\"scaleSize\").style.width = pxValue + \"px\";\n};\n```\n\n下面是通过上述思路实现的例子，在地图右下角实现一个比例尺。\n\n{% jsfiddle yinxiaojian/6eutbuyr %}","source":"_posts/google-map-比例尺算法分析.md","raw":"---\nlayout: title\ntitle: google map 比例尺算法分析\ndate: 2017-12-24 13:26:14\ntags: google map\ncategories: 前端\n---\n\n比例尺即地图右下角显示地图距离与实际距离比例的控件，由于Google map自带比例尺控件存在的局限性——无法调整位置和格式，所以通过此文章，介绍比例尺算法及具体实现。\n\n<!-- more -->\n\n### 什么是比例尺\n\n比例尺是表示[图上距离](http://baike.baidu.com/view/5454725.htm)比实地距离缩小的程度，因此也叫[缩尺](http://baike.baidu.com/view/1559050.htm)。用公式表示为：比例尺=[图上距离](http://baike.baidu.com/view/5454725.htm)/实地距离。在Google map上比例尺显示在右下角，如下图\n\n![](http://oygov02sc.bkt.clouddn.com/google%20map%20%E6%AF%94%E4%BE%8B%E5%B0%BA%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90-1.png)\n\n在创建地图时只需增加设置项\n\n```\nscaleControl: true\n```\n\n如下例\n\n{% jsfiddle yinxiaojian/yL9mxdzp %}\n\n遗憾的是这样添加的比例尺会存在于右下角，而且不像其他控件一样可以调整位置。如果我们希望修改其位置或者样式，就会无从下手。\n\n### 自制比例尺\n\n实现一个比例尺的关键在于如何获取到地图距离与实际距离的比例和缩放等级及维度之间的关系。google官方api未提供相关函数，因此我们需要自己计算。核心公式为\n\n```\nScaleValue = 156543.03392 * Math.cos(latLng.lat() * Math.PI / 180) / Math.pow(2, zoom)\n```\n\n其中zoom为当前缩放等级，latLng.lat()即目标点维度值。该公式是在地球半径为6378137m的基础上计算的，这个值即google地图所采用的值。\n\n有了计算公式后，我们还需要一张表——缩放等级和比例尺对应表，也就是在什么样的缩放等级下使用多大的比例尺，表格如下:\n\n```\nZoom    Scale\n0    10000km\n1    5000km\n2    2000km\n3    1000km\n4    500km\n5    200km\n6    200km\n7    100km\n8    50km\n9    20km\n10   10km\n11   5km\n12   2km\n13   1km\n14   500m\n15   200m\n16   200m\n17   100m\n18   50m\n19   20m\n20   10m\n21   5m\n22   2m\n23   1m\n24   1m\n25   1m\n26   1m\n```\n\n通过监听地图变化事件（缩放和平移），获取当前屏幕中心点缩放等级和维度获取到scale和scalevalue，那么比例尺的长度（px） = scale/scalevalue。\n\n获取当前比例尺长度的核心代码如下：\n\n```javascript\n/**\n * 根据缩放等级和维度获取KM数(m数)和像素\n */\nfunction setScaleInfos(zoomLevel, lat, map) {\n\t// 缩放等级-比例尺\n\tvar zoomList = [{\n\t\ttext: \"10000KM\",\n\t\tvalue: 10000 * 1000\n\t}, {\n\t\ttext: \"5000KM\",\n\t\tvalue: 5000 * 1000\n\t}, {\n\t\ttext: \"2000KM\",\n\t\tvalue: 2000 * 1000\n\t}, {\n\t\ttext: \"1000KM\",\n\t\tvalue: 1000 * 1000\n\t}, {\n\t\ttext: \"500KM\",\n\t\tvalue: 500 * 1000\n\t}, {\n\t\ttext: \"200KM\",\n\t\tvalue: 200 * 1000\n\t}, {\n\t\ttext: \"200KM\",\n\t\tvalue: 200 * 1000\n\t}, {\n\t\ttext: \"100KM\",\n\t\tvalue: 100 * 1000\n\t}, {\n\t\ttext: \"50KM\",\n\t\tvalue: 50 * 1000\n\t}, {\n\t\ttext: \"20KM\",\n\t\tvalue: 20 * 1000\n\t}, {\n\t\ttext: \"10KM\",\n\t\tvalue: 10 * 1000\n\t}, {\n\t\ttext: \"5KM\",\n\t\tvalue: 5000\n\t}, {\n\t\ttext: \"2KM\",\n\t\tvalue: 2000\n\t}, {\n\t\ttext: \"1KM\",\n\t\tvalue: 1000\n\t}, {\n\t\ttext: \"500m\",\n\t\tvalue: 500\n\t}, {\n\t\ttext: \"200m\",\n\t\tvalue: 200\n\t}, {\n\t\ttext: \"200m\",\n\t\tvalue: 200\n\t}, {\n\t\ttext: \"100m\",\n\t\tvalue: 100\n\t}, {\n\t\ttext: \"50m\",\n\t\tvalue: 50\n\t}, {\n\t\ttext: \"20m\",\n\t\tvalue: 20\n\t}, {\n\t\ttext: \"10m\",\n\t\tvalue: 10\n\t}, {\n\t\ttext: \"5m\",\n\t\tvalue: 5\n\t}, {\n\t\ttext: \"2m\",\n\t\tvalue: 2\n\t}, {\n\t\ttext: \"1m\",\n\t\tvalue: 1\n\t}, {\n\t\ttext: \"1m\",\n\t\tvalue: 1\n\t}, {\n\t\ttext: \"1m\",\n\t\tvalue: 1\n\t}, {\n\t\ttext: \"1m\",\n\t\tvalue: 1\n\t}];\n\t// 宽度\n\tvar pxValue = Math.floor(zoomList[zoomLevel].value / (156543.03392 * Math.cos(lat * Math.PI / 180) / Math.pow(2, zoomLevel)));\n\t// 更新经纬度数据\n\t$W.id(\"scaleText\").innerHTML = zoomList[zoomLevel].text;\n\t$W.id(\"scaleSize\").style.width = pxValue + \"px\";\n};\n```\n\n下面是通过上述思路实现的例子，在地图右下角实现一个比例尺。\n\n{% jsfiddle yinxiaojian/6eutbuyr %}","slug":"google-map-比例尺算法分析","published":1,"updated":"2018-01-03T16:03:11.045Z","comments":1,"photos":[],"link":"","_id":"cjkv4owby000kfb9lglyhudwn","content":"<p>比例尺即地图右下角显示地图距离与实际距离比例的控件，由于Google map自带比例尺控件存在的局限性——无法调整位置和格式，所以通过此文章，介绍比例尺算法及具体实现。</p>\n<a id=\"more\"></a>\n<h3 id=\"什么是比例尺\"><a href=\"#什么是比例尺\" class=\"headerlink\" title=\"什么是比例尺\"></a>什么是比例尺</h3><p>比例尺是表示<a href=\"http://baike.baidu.com/view/5454725.htm\" target=\"_blank\" rel=\"noopener\">图上距离</a>比实地距离缩小的程度，因此也叫<a href=\"http://baike.baidu.com/view/1559050.htm\" target=\"_blank\" rel=\"noopener\">缩尺</a>。用公式表示为：比例尺=<a href=\"http://baike.baidu.com/view/5454725.htm\" target=\"_blank\" rel=\"noopener\">图上距离</a>/实地距离。在Google map上比例尺显示在右下角，如下图</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/google%20map%20%E6%AF%94%E4%BE%8B%E5%B0%BA%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90-1.png\" alt=\"\"></p>\n<p>在创建地图时只需增加设置项</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scaleControl: true</span><br></pre></td></tr></table></figure>\n<p>如下例</p>\n<iframe scrolling=\"no\" width=\"100%\" height=\"300\" src=\"//jsfiddle.net/yinxiaojian/yL9mxdzp/embedded/js,resources,html,css,result/light\" frameborder=\"0\" allowfullscreen></iframe>\n<p>遗憾的是这样添加的比例尺会存在于右下角，而且不像其他控件一样可以调整位置。如果我们希望修改其位置或者样式，就会无从下手。</p>\n<h3 id=\"自制比例尺\"><a href=\"#自制比例尺\" class=\"headerlink\" title=\"自制比例尺\"></a>自制比例尺</h3><p>实现一个比例尺的关键在于如何获取到地图距离与实际距离的比例和缩放等级及维度之间的关系。google官方api未提供相关函数，因此我们需要自己计算。核心公式为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ScaleValue = 156543.03392 * Math.cos(latLng.lat() * Math.PI / 180) / Math.pow(2, zoom)</span><br></pre></td></tr></table></figure>\n<p>其中zoom为当前缩放等级，latLng.lat()即目标点维度值。该公式是在地球半径为6378137m的基础上计算的，这个值即google地图所采用的值。</p>\n<p>有了计算公式后，我们还需要一张表——缩放等级和比例尺对应表，也就是在什么样的缩放等级下使用多大的比例尺，表格如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Zoom    Scale</span><br><span class=\"line\">0    10000km</span><br><span class=\"line\">1    5000km</span><br><span class=\"line\">2    2000km</span><br><span class=\"line\">3    1000km</span><br><span class=\"line\">4    500km</span><br><span class=\"line\">5    200km</span><br><span class=\"line\">6    200km</span><br><span class=\"line\">7    100km</span><br><span class=\"line\">8    50km</span><br><span class=\"line\">9    20km</span><br><span class=\"line\">10   10km</span><br><span class=\"line\">11   5km</span><br><span class=\"line\">12   2km</span><br><span class=\"line\">13   1km</span><br><span class=\"line\">14   500m</span><br><span class=\"line\">15   200m</span><br><span class=\"line\">16   200m</span><br><span class=\"line\">17   100m</span><br><span class=\"line\">18   50m</span><br><span class=\"line\">19   20m</span><br><span class=\"line\">20   10m</span><br><span class=\"line\">21   5m</span><br><span class=\"line\">22   2m</span><br><span class=\"line\">23   1m</span><br><span class=\"line\">24   1m</span><br><span class=\"line\">25   1m</span><br><span class=\"line\">26   1m</span><br></pre></td></tr></table></figure>\n<p>通过监听地图变化事件（缩放和平移），获取当前屏幕中心点缩放等级和维度获取到scale和scalevalue，那么比例尺的长度（px） = scale/scalevalue。</p>\n<p>获取当前比例尺长度的核心代码如下：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 根据缩放等级和维度获取KM数(m数)和像素</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">setScaleInfos</span>(<span class=\"params\">zoomLevel, lat, map</span>) </span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">// 缩放等级-比例尺</span></span><br><span class=\"line\">\t<span class=\"keyword\">var</span> zoomList = [&#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"10000KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">10000</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"5000KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">5000</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"2000KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">2000</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1000KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1000</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"500KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">500</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"200KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">200</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"200KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">200</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"100KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">100</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"50KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">50</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"20KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">20</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"10KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">10</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"5KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">5000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"2KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">2000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"500m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">500</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"200m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">200</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"200m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">200</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"100m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">100</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"50m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">50</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"20m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">20</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"10m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">10</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"5m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">5</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"2m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">2</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1</span></span><br><span class=\"line\">\t&#125;];</span><br><span class=\"line\">\t<span class=\"comment\">// 宽度</span></span><br><span class=\"line\">\t<span class=\"keyword\">var</span> pxValue = <span class=\"built_in\">Math</span>.floor(zoomList[zoomLevel].value / (<span class=\"number\">156543.03392</span> * <span class=\"built_in\">Math</span>.cos(lat * <span class=\"built_in\">Math</span>.PI / <span class=\"number\">180</span>) / <span class=\"built_in\">Math</span>.pow(<span class=\"number\">2</span>, zoomLevel)));</span><br><span class=\"line\">\t<span class=\"comment\">// 更新经纬度数据</span></span><br><span class=\"line\">\t$W.id(<span class=\"string\">\"scaleText\"</span>).innerHTML = zoomList[zoomLevel].text;</span><br><span class=\"line\">\t$W.id(<span class=\"string\">\"scaleSize\"</span>).style.width = pxValue + <span class=\"string\">\"px\"</span>;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>下面是通过上述思路实现的例子，在地图右下角实现一个比例尺。</p>\n<iframe scrolling=\"no\" width=\"100%\" height=\"300\" src=\"//jsfiddle.net/yinxiaojian/6eutbuyr/embedded/js,resources,html,css,result/light\" frameborder=\"0\" allowfullscreen></iframe>","site":{"data":{}},"excerpt":"<p>比例尺即地图右下角显示地图距离与实际距离比例的控件，由于Google map自带比例尺控件存在的局限性——无法调整位置和格式，所以通过此文章，介绍比例尺算法及具体实现。</p>","more":"<h3 id=\"什么是比例尺\"><a href=\"#什么是比例尺\" class=\"headerlink\" title=\"什么是比例尺\"></a>什么是比例尺</h3><p>比例尺是表示<a href=\"http://baike.baidu.com/view/5454725.htm\" target=\"_blank\" rel=\"noopener\">图上距离</a>比实地距离缩小的程度，因此也叫<a href=\"http://baike.baidu.com/view/1559050.htm\" target=\"_blank\" rel=\"noopener\">缩尺</a>。用公式表示为：比例尺=<a href=\"http://baike.baidu.com/view/5454725.htm\" target=\"_blank\" rel=\"noopener\">图上距离</a>/实地距离。在Google map上比例尺显示在右下角，如下图</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/google%20map%20%E6%AF%94%E4%BE%8B%E5%B0%BA%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90-1.png\" alt=\"\"></p>\n<p>在创建地图时只需增加设置项</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scaleControl: true</span><br></pre></td></tr></table></figure>\n<p>如下例</p>\n<iframe scrolling=\"no\" width=\"100%\" height=\"300\" src=\"//jsfiddle.net/yinxiaojian/yL9mxdzp/embedded/js,resources,html,css,result/light\" frameborder=\"0\" allowfullscreen></iframe>\n<p>遗憾的是这样添加的比例尺会存在于右下角，而且不像其他控件一样可以调整位置。如果我们希望修改其位置或者样式，就会无从下手。</p>\n<h3 id=\"自制比例尺\"><a href=\"#自制比例尺\" class=\"headerlink\" title=\"自制比例尺\"></a>自制比例尺</h3><p>实现一个比例尺的关键在于如何获取到地图距离与实际距离的比例和缩放等级及维度之间的关系。google官方api未提供相关函数，因此我们需要自己计算。核心公式为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ScaleValue = 156543.03392 * Math.cos(latLng.lat() * Math.PI / 180) / Math.pow(2, zoom)</span><br></pre></td></tr></table></figure>\n<p>其中zoom为当前缩放等级，latLng.lat()即目标点维度值。该公式是在地球半径为6378137m的基础上计算的，这个值即google地图所采用的值。</p>\n<p>有了计算公式后，我们还需要一张表——缩放等级和比例尺对应表，也就是在什么样的缩放等级下使用多大的比例尺，表格如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Zoom    Scale</span><br><span class=\"line\">0    10000km</span><br><span class=\"line\">1    5000km</span><br><span class=\"line\">2    2000km</span><br><span class=\"line\">3    1000km</span><br><span class=\"line\">4    500km</span><br><span class=\"line\">5    200km</span><br><span class=\"line\">6    200km</span><br><span class=\"line\">7    100km</span><br><span class=\"line\">8    50km</span><br><span class=\"line\">9    20km</span><br><span class=\"line\">10   10km</span><br><span class=\"line\">11   5km</span><br><span class=\"line\">12   2km</span><br><span class=\"line\">13   1km</span><br><span class=\"line\">14   500m</span><br><span class=\"line\">15   200m</span><br><span class=\"line\">16   200m</span><br><span class=\"line\">17   100m</span><br><span class=\"line\">18   50m</span><br><span class=\"line\">19   20m</span><br><span class=\"line\">20   10m</span><br><span class=\"line\">21   5m</span><br><span class=\"line\">22   2m</span><br><span class=\"line\">23   1m</span><br><span class=\"line\">24   1m</span><br><span class=\"line\">25   1m</span><br><span class=\"line\">26   1m</span><br></pre></td></tr></table></figure>\n<p>通过监听地图变化事件（缩放和平移），获取当前屏幕中心点缩放等级和维度获取到scale和scalevalue，那么比例尺的长度（px） = scale/scalevalue。</p>\n<p>获取当前比例尺长度的核心代码如下：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 根据缩放等级和维度获取KM数(m数)和像素</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">setScaleInfos</span>(<span class=\"params\">zoomLevel, lat, map</span>) </span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">// 缩放等级-比例尺</span></span><br><span class=\"line\">\t<span class=\"keyword\">var</span> zoomList = [&#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"10000KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">10000</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"5000KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">5000</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"2000KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">2000</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1000KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1000</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"500KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">500</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"200KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">200</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"200KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">200</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"100KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">100</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"50KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">50</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"20KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">20</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"10KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">10</span> * <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"5KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">5000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"2KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">2000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1KM\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1000</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"500m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">500</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"200m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">200</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"200m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">200</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"100m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">100</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"50m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">50</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"20m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">20</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"10m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">10</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"5m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">5</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"2m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">2</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1</span></span><br><span class=\"line\">\t&#125;, &#123;</span><br><span class=\"line\">\t\ttext: <span class=\"string\">\"1m\"</span>,</span><br><span class=\"line\">\t\tvalue: <span class=\"number\">1</span></span><br><span class=\"line\">\t&#125;];</span><br><span class=\"line\">\t<span class=\"comment\">// 宽度</span></span><br><span class=\"line\">\t<span class=\"keyword\">var</span> pxValue = <span class=\"built_in\">Math</span>.floor(zoomList[zoomLevel].value / (<span class=\"number\">156543.03392</span> * <span class=\"built_in\">Math</span>.cos(lat * <span class=\"built_in\">Math</span>.PI / <span class=\"number\">180</span>) / <span class=\"built_in\">Math</span>.pow(<span class=\"number\">2</span>, zoomLevel)));</span><br><span class=\"line\">\t<span class=\"comment\">// 更新经纬度数据</span></span><br><span class=\"line\">\t$W.id(<span class=\"string\">\"scaleText\"</span>).innerHTML = zoomList[zoomLevel].text;</span><br><span class=\"line\">\t$W.id(<span class=\"string\">\"scaleSize\"</span>).style.width = pxValue + <span class=\"string\">\"px\"</span>;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>下面是通过上述思路实现的例子，在地图右下角实现一个比例尺。</p>\n<iframe scrolling=\"no\" width=\"100%\" height=\"300\" src=\"//jsfiddle.net/yinxiaojian/6eutbuyr/embedded/js,resources,html,css,result/light\" frameborder=\"0\" allowfullscreen></iframe>"},{"title":"SpringMVC Controllers 说明文档","date":"2018-01-05T01:41:54.000Z","_content":"\n翻译自官方文档，并加上了自己的理解，解释更加直白。\n\n官方文档地址：[Spring Web MVC](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc)\n\n<!--more-->\n\n### 1 Declaration\n\n使用@Controller注解标记一个类，这个类就是一个SpringMVC Controller对象。\n\n```java\n@Controller\npublic class HelloController {\n\n    @GetMapping(\"/hello\")\n    public String handle(Model model) {\n        model.addAttribute(\"message\", \"Hello World!\");\n        return \"index\";\n    }\n}\n```\n\n在XML文件进行配置，告诉Spring应该到哪里去找Controller控制器，加上如下一行，base-package 即controller所在位置\n\n```java\n<context:component-scan base-package=\"org.example.web\"/>\n```\n\n完整XML配置文件\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xmlns:p=\"http://www.springframework.org/schema/p\"\n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"\n        http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        http://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <context:component-scan base-package=\"org.example.web\"/>\n\n    <!-- ... -->\n\n</beans>\n```\n\n\n\n### 2 Request Mapping\n\n@RequestMapping 注解用于映射Request请求与与controller的处理方法。该注解有多个参数可以配置Request请求的属性，如URL，HTTP method，request parameters，headers，media types。\n\n@RequestMapping 可以用于类也可以用于类方法。当@RequestMapping 标记在Controller 类上的时候，里面使用@RequestMapping 标记的方法的请求地址都是相对于类上的@RequestMapping 而言的；当Controller 类上没有标记@RequestMapping 注解时，方法上的@RequestMapping 都是绝对路径。最终路径都是相对于跟路径\"/\"的。通过这种组合的方法可以限制Request的匹配。\n\n在SpringMVC 4.3 引入了组合注解来简化@RequestMapping的写法。\n\n* @GetMapping \n* @PostMapping\n* @PutMapping\n* @DeleteMapping\n* @PatchMapping\n\n如@GetMapping等价于@RequestMapping(method = RequestMethod.GET)，组合注解通常用于method上，如下\n\n```java\n@RestController\n@RequestMapping(\"/persons\")\nclass PersonController {\n\n    @GetMapping(\"/{id}\")\n    public Person getPerson(@PathVariable Long id) {\n        // ...\n    }\n\n    @PostMapping\n    @ResponseStatus(HttpStatus.CREATED)\n    public void add(@RequestBody Person person) {\n        // ...\n    }\n}\n```\n\n#### 2.1 URI patterns\n\n我们可以使用通配符去匹配request\n\n* `?`匹配一个字符\n* `*`匹配一个路径段中的零个或多个字符\n* `**`匹配零个或多个路径段\n\n可以使用@PathVariable来声明URI变量并获取其值:\n\n```java\n@GetMapping(\"/owners/{ownerId}/pets/{petId}\")\npublic Pet findPet(@PathVariable Long ownerId, @PathVariable Long petId) {\n    // ...\n}\n```\n\nURI变量即可以在类层级声明，也可以在方法层级声明:\n\n```java\n@Controller\n@RequestMapping(\"/owners/{ownerId}\")\npublic class OwnerController {\n\n    @GetMapping(\"/pets/{petId}\")\n    public Pet findPet(@PathVariable(\"ownerId\") Long ownerId, @PathVariable Long petId) {\n        // ...\n    }\n}\n```\n\nURI变量会进行自动类型转换或者抛出`TypeMismatchException`异常，对于简单的类型，如`int, long, Data`，默认自动转换，对于复杂类型在此不做详解。\n\nURI变量作为参数时，有两种声明方式：\n\n1. 显性声明，如上代码块： `@PathVariable(\"ownerId\")`，这种声明方式明确规定使用的是URI模版里的ownerId变量。\n2. 直接使用@PathVariable，如上代码块`@PathVariable Long petId`，这种情况下会默认去URI模版寻找跟参数名相同的变量，但只能在使用debug模式才可以。\n\nRequest还支持正则匹配，语法格式：`{varName:regex}`，用regex声明了一个URI变量varName，例如：\n\n```java\n@GetMapping(\"/{name:[a-z-]+}-{version:\\\\d\\\\.\\\\d\\\\.\\\\d}{ext:\\\\.[a-z]+}\")\npublic void handle(@PathVariable String version, @PathVariable String ext) {\n    // ...\n}\n```\n\n#### 2.2 Pattern comparison\n\n当有多个patterns（模版）匹配到URL时，通过`AntPathMatcher.getPatternComparator(String path)`去获取最合适的patterns。\n\n对于每一个pattern，根据URI变量和通配符的个数计算出分数，分数越低优先度越高。相同分数则较长者优先度高。\n\n默认映射模版`/**`不参与比较，优先度最低。\n\n#### 2.3 Matrix variables\n\nMatrix variables可以出现在任意路径段，每个matrix variable由 \";\" 分割，例如`/cars;color=red;year=2012`。多个值既可以用 \",\" 分割，如`color=red,green,blue`，也可以重复变量名，如`color=red;color=green;color=blue`。\n\n如果一个URL可能含有matrix variables，那么请求映射模版必须使用URI模版去表示。这样可以确保匹配正确，即使matrix variables的位置不固定或不存在。\n\n如下例子，获取matrix variable \"q\"\n\n```java\n// GET /pets/42;q=11;r=22\n\n@GetMapping(\"/pets/{petId}\")\npublic void findPet(@PathVariable String petId, @MatrixVariable int q) {\n\n    // petId == 42\n    // q == 11\n}\n```\n\n多个路径段包含matrix variables的情况：\n\n```java\n// GET /owners/42;q=11/pets/21;q=22\n\n@GetMapping(\"/owners/{ownerId}/pets/{petId}\")\npublic void findPet(\n        @MatrixVariable(name=\"q\", pathVar=\"ownerId\") int q1,\n        @MatrixVariable(name=\"q\", pathVar=\"petId\") int q2) {\n\n    // q1 == 11\n    // q2 == 22\n}\n```\n\n可以设置matrix variable的required属性，`required = false`表示该参数不是必须存在的，同时可以设置defaultValue赋予默认值。如下：\n\n```Java\n// GET /pets/42\n\n@GetMapping(\"/pets/{petId}\")\npublic void findPet(@MatrixVariable(required=false, defaultValue=\"1\") int q) {\n\n    // q == 1\n}\n```\n\n可以将所有的matrix variables放置于一个Map中：\n\n```java\n// GET /owners/42;q=11;r=12/pets/21;q=22;s=23\n\n@GetMapping(\"/owners/{ownerId}/pets/{petId}\")\npublic void findPet(\n        @MatrixVariable MultiValueMap<String, String> matrixVars,\n        @MatrixVariable(pathVar=\"petId\"\") MultiValueMap<String, String> petMatrixVars) {\n\n    // matrixVars: [\"q\" : [11,22], \"r\" : 12, \"s\" : 23]\n    // petMatrixVars: [\"q\" : 22, \"s\" : 23]\n}\n```\n\n最后注意：matrix variables默认是不启用的，因此我们需要在xml文件中进行配置:\n\n```Xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"\n        http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/mvc\n        http://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n    <mvc:annotation-driven enable-matrix-variables=\"true\"/>\n\n</beans>\n```\n\n#### 2.4 Consumable media types\n\n利用`Content-Type`对请求匹配范围进行限制，从而缩小请求的映射范围。\n\n```java\n@PostMapping(path = \"/pets\", consumes = \"application/json\")\npublic void addPet(@RequestBody Pet pet) {\n    // ...\n}\n```\n\nconsumes 属性支持否定表达，`!text/plain`表示除了 \"text/plain\" 的所有content type。\n\nconsumes可以声明在class层级，与其他request mapping attributes不同的是，当声明在class层级时，method层级的consumes属性会覆盖而不是扩展class层级的声明。\n\n#### 2.5 Producible media types\n\n利用`Accept`对请求匹配范围进行限制，从而缩小请求的映射范围。类似2.4:\n\n```java\n@GetMapping(path = \"/pets/{petId}\", produces = \"application/json;charset=UTF-8\")\n@ResponseBody\npublic Pet getPet(@PathVariable String petId) {\n    // ...\n}\n```\n\n#### 2.6 params, method, headers\n\n* params 属性用于指定请求参数\n* method 属性用于限制能够访问的方法类型 //和组合注解@GetMapping等类似\n* headers 属性用于指定请求头信息\n\n三者都可以缩小请求的映射范围，支持否定表达。\n\n```java\n@GetMapping(path = \"/pets/{petId}\", params = \"myParam=myValue\")\npublic void findPet(@PathVariable String petId) {\n    // ...\n}\n@GetMapping(path = \"/pets\", headers = \"myHeader=myValue\")\npublic void findPet1(@PathVariable String petId) {\n    // ...\n}\n//和findPet1等价\n@RequestMapping(path = \"/pets\", headers = \"myHeader=myValue\", method = RequestMethod. GET)\npublic void findPet2(@PathVariable String petId) {\n    // ...\n}\n```\n\n\n\n### 3 Handler Methods\n\n#### 3.1 Method Arguments\n\n> 引用自官方文档\n\n| Controller method argument               | Description                              |\n| ---------------------------------------- | ---------------------------------------- |\n| `WebRequest`, `NativeWebRequest`         | Generic access to request parameters, request & session attributes, without direct use of the Servlet API. |\n| `javax.servlet.ServletRequest`, `javax.servlet.ServletResponse` | Choose any specific request or response type — e.g. `ServletRequest`, `HttpServletRequest`, or Spring’s `MultipartRequest`, `MultipartHttpServletRequest`. |\n| `javax.servlet.http.HttpSession`         | Enforces the presence of a session. As a consequence, such an argument is never `null`.**Note:** Session access is not thread-safe. Consider setting the`RequestMappingHandlerAdapter`'s \"synchronizeOnSession\" flag to \"true\" if multiple requests are allowed to access a session concurrently. |\n| `javax.servlet.http.PushBuilder`         | Servlet 4.0 push builder API for programmatic HTTP/2 resource pushes. Note that per Servlet spec, the injected `PushBuilder` instance can be null if the client does not support that HTTP/2 feature. |\n| `java.security.Principal`                | Currently authenticated user; possibly a specific `Principal` implementation class if known. |\n| `HttpMethod`                             | The HTTP method of the request.          |\n| `java.util.Locale`                       | The current request locale, determined by the most specific `LocaleResolver` available, in effect, the configured `LocaleResolver`/`LocaleContextResolver`. |\n| Java 6+: `java.util.TimeZone`Java 8+: `java.time.ZoneId` | The time zone associated with the current request, as determined by a `LocaleContextResolver`. |\n| `java.io.InputStream`, `java.io.Reader`  | For access to the raw request body as exposed by the Servlet API. |\n| `java.io.OutputStream`, `java.io.Writer` | For access to the raw response body as exposed by the Servlet API. |\n| `@PathVariable`                          | For access to URI template variables. See [URI patterns](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestmapping-uri-templates). |\n| `@MatrixVariable`                        | For access to name-value pairs in URI path segments. See [Matrix variables](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-matrix-variables). |\n| `@RequestParam`                          | For access to Servlet request parameters. Parameter values are converted to the declared method argument type. See [@RequestParam](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestparam). |\n| `@RequestHeader`                         | For access to request headers. Header values are converted to the declared method argument type. See [@RequestHeader](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestheader). |\n| `@RequestBody`                           | For access to the HTTP request body. Body content is converted to the declared method argument type using `HttpMessageConverter`s. See [@RequestBody](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestbody). |\n| `HttpEntity<B>`                          | For access to request headers and body. The body is converted with `HttpMessageConverter`s. See [HttpEntity](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-httpentity). |\n| `@RequestPart`                           | For access to a part in a \"multipart/form-data\" request. See [@RequestPart](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-multipart-forms-non-browsers) and [Multipart requests](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-multipart). |\n| `java.util.Map`, `org.springframework.ui.Model`, `org.springframework.ui.ModelMap` | For access and updates of the implicit model that is exposed to the web view. |\n| `RedirectAttributes`                     | Specify attributes to use in case of a redirect — i.e. to be appended to the query string, and/or flash attributes to be stored temporarily until the request after redirect. See [Redirect attributes](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-redirecting-passing-data) and [Flash attributes](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-flash-attributes). |\n| Command or form object (with optional `@ModelAttribute`) | Command object whose properties to bind to request parameters — via setters or directly to fields, with customizable type conversion, depending on `@InitBinder` methods and/or the HandlerAdapter configuration (see the `webBindingInitializer` property on`RequestMappingHandlerAdapter`).Command objects along with their validation results are exposed as model attributes, by default using the command class name - e.g. model attribute \"orderAddress\" for a command object of type \"some.package.OrderAddress\". `@ModelAttribute` can be used to customize the model attribute name. |\n| `Errors`, `BindingResult`                | Validation results for the command/form object data binding; this argument must be declared immediately after the command/form object in the controller method signature. |\n| `SessionStatus`                          | For marking form processing complete which triggers cleanup of session attributes declared through a class-level `@SessionAttributes`annotation. |\n| `UriComponentsBuilder`                   | For preparing a URL relative to the current request’s host, port, scheme, context path, and the literal part of the servlet mapping also taking into account `Forwarded` and `X-Forwarded-*` headers. |\n| `@SessionAttribute`                      | For access to any session attribute; in contrast to model attributes stored in the session as a result of a class-level `@SessionAttributes`declaration. |\n| `@RequestAttribute`                      | For access to request attributes.        |\n\n#### 3.2 Return Values\n\n> 引用自官方文档\n\n| Controller method return value           | Description                              |\n| ---------------------------------------- | ---------------------------------------- |\n| `@ResponseBody`                          | The return value is converted through `HttpMessageConverter`s and written to the response. See [@ResponseBody](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-responsebody). |\n| `HttpEntity<B>`, `ResponseEntity<B>`     | The return value specifies the full response including HTTP headers and body be converted through `HttpMessageConverter`s and written to the response. See [HttpEntity](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-httpentity). |\n| `HttpHeaders`                            | For returning a response with headers and no body. |\n| `String`                                 | A view name to be resolved with `ViewResolver`'s and used together with the implicit model — determined through command objects and `@ModelAttribute`methods. The handler method may also programmatically enrich the model by declaring a `Model`argument (see above). |\n| `View`                                   | A `View` instance to use for rendering together with the implicit model — determined through command objects and `@ModelAttribute` methods. The handler method may also programmatically enrich the model by declaring a `Model` argument (see above). |\n| `java.util.Map`, `org.springframework.ui.Model` | Attributes to be added to the implicit model with the view name implicitly determined through a `RequestToViewNameTranslator`. |\n| `ModelAndView` object                    | The view and model attributes to use, and optionally a response status. |\n| `void`                                   | A method with a `void` return type (or `null` return value) is considered to have fully handled the response if it also has a `ServletResponse`, or an `OutputStream` argument, or an `@ResponseStatus` annotation. The same is true also if the controller has made a positive ETag or lastModified timestamp check (see [@Controller caching](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-caching-etag-lastmodified) for details).If none of the above is true, a `void`return type may also indicate \"no response body\" for REST controllers, or default view name selection for HTML controllers. |\n| `Callable<V>`                            | Produce any of the above return values asynchronously in a Spring MVC managed thread. |\n| `DeferredResult<V>`                      | Produce any of the above return values asynchronously from any thread — e.g. possibly as a result of some event or callback. |\n| ListenableFuture<V>, java.util.concurrent.CompletionStage<V>, java.util.concurrent.CompletableFuture<V> | Alternative to `DeferredResult` as a convenience for example when an underlying service returns one of those. |\n| `ResponseBodyEmitter`, `SseEmitter`      | Emit a stream of objects asynchronously to be written to the response with`HttpMessageConverter`'s; also supported as the body of a `ResponseEntity`. |\n| `StreamingResponseBody`                  | Write to the response `OutputStream` asynchronously; also supported as the body of a`ResponseEntity`. |\n| Reactive types — Reactor, RxJava, or others via `ReactiveAdapterRegistry` | Alternative to ``DeferredResult`with multi-value streams (e.g. `Flux`, `Observable`) collected to a `List`.For streaming scenarios — .e.g. `text/event-stream`, `application/json+stream`,`SseEmitter` and `ResponseBodyEmitter` are used instead, where `ServletOutputStream` blocking I/O is performed on a Spring MVC managed thread and back pressure applied against the completion of each write.See [Reactive return values](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-async-reactive-types). |\n| Any other return type                    | A single model attribute to be added to the implicit model with the view name implicitly determined through a `RequestToViewNameTranslator`; the attribute name may be specified through a method-level `@ModelAttribute` or otherwise a name is selected based on the class name of the return type. |\n\n#### 3.3 @RequestParam\n\n使用 @RequestParam 绑定 HttpServletRequest 请求参数到控制器方法参数：\n\n```java\n@Controller\n@RequestMapping(\"/pets\")\n@SessionAttributes(\"pet\")\npublic class EditPetForm {\n\n    // ...\n\n    @GetMapping\n    public String setupForm(@RequestParam(\"petId\") int petId, ModelMap model) {\n        Pet pet = this.clinic.loadPet(petId);\n        model.addAttribute(\"pet\", pet);\n        return \"petForm\";\n    }\n\n    // ...\n\n}\n```\n\n绑定的参数默认必须存在，可以通过required属性修改，如`@RequestParam(name=\"id\", required=false)`。\n\n如果控制器方法参数类型不是string，将会执行自动类型转换。\n\n#### 3.4 @RequestHeader\n\n使用@RequestHeader绑定绑定 HttpServletRequest 头信息到控制器方法参数。\n\n一个request header例子:\n\n```\nHost                    localhost:8080\nAccept                  text/html,application/xhtml+xml,application/xml;q=0.9\nAccept-Language         fr,en-gb;q=0.7,en;q=0.3\nAccept-Encoding         gzip,deflate\nAccept-Charset          ISO-8859-1,utf-8;q=0.7,*;q=0.7\nKeep-Alive              300\n```\n\n下面的例子演示了如何获取 `Accept-Encoding`和 `Keep-Alive` 的值：\n\n```java\n@RequestMapping(\"/displayHeaderInfo.do\")\npublic void displayHeaderInfo(@RequestHeader(\"Accept-Encoding\") String encoding,\n        @RequestHeader(\"Keep-Alive\") long keepAlive) {\n    //...\n}\n```\n\n如果控制器方法参数类型不是string，将会执行自动类型转换。\n\n#### 3.5 @CookieValue\n\n使用@CookieValue绑定绑定 HttpServletRequest 的cookie信息到控制器方法参数。\n\n假设http request中有如下cookie信息：\n\n```\nJSESSIONID=415A4AC178C59DACE0B2C9CA727CDD84\n```\n\n下面的例子演示了如何获取JESSIONID的值：\n\n```java\n@RequestMapping(\"/displayHeaderInfo.do\")\npublic void displayHeaderInfo(@CookieValue(\"JSESSIONID\") String cookie) {\n    //...\n}\n```\n\n#### 3.6 @ModelAttribute\n\n//TODO","source":"_posts/SpringMVC-Controllers-说明文档.md","raw":"---\ntitle: SpringMVC Controllers 说明文档\ndate: 2018-01-05 09:41:54\ntags: Controllers\ncategories: SpringMVC\n---\n\n翻译自官方文档，并加上了自己的理解，解释更加直白。\n\n官方文档地址：[Spring Web MVC](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc)\n\n<!--more-->\n\n### 1 Declaration\n\n使用@Controller注解标记一个类，这个类就是一个SpringMVC Controller对象。\n\n```java\n@Controller\npublic class HelloController {\n\n    @GetMapping(\"/hello\")\n    public String handle(Model model) {\n        model.addAttribute(\"message\", \"Hello World!\");\n        return \"index\";\n    }\n}\n```\n\n在XML文件进行配置，告诉Spring应该到哪里去找Controller控制器，加上如下一行，base-package 即controller所在位置\n\n```java\n<context:component-scan base-package=\"org.example.web\"/>\n```\n\n完整XML配置文件\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xmlns:p=\"http://www.springframework.org/schema/p\"\n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"\n        http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        http://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <context:component-scan base-package=\"org.example.web\"/>\n\n    <!-- ... -->\n\n</beans>\n```\n\n\n\n### 2 Request Mapping\n\n@RequestMapping 注解用于映射Request请求与与controller的处理方法。该注解有多个参数可以配置Request请求的属性，如URL，HTTP method，request parameters，headers，media types。\n\n@RequestMapping 可以用于类也可以用于类方法。当@RequestMapping 标记在Controller 类上的时候，里面使用@RequestMapping 标记的方法的请求地址都是相对于类上的@RequestMapping 而言的；当Controller 类上没有标记@RequestMapping 注解时，方法上的@RequestMapping 都是绝对路径。最终路径都是相对于跟路径\"/\"的。通过这种组合的方法可以限制Request的匹配。\n\n在SpringMVC 4.3 引入了组合注解来简化@RequestMapping的写法。\n\n* @GetMapping \n* @PostMapping\n* @PutMapping\n* @DeleteMapping\n* @PatchMapping\n\n如@GetMapping等价于@RequestMapping(method = RequestMethod.GET)，组合注解通常用于method上，如下\n\n```java\n@RestController\n@RequestMapping(\"/persons\")\nclass PersonController {\n\n    @GetMapping(\"/{id}\")\n    public Person getPerson(@PathVariable Long id) {\n        // ...\n    }\n\n    @PostMapping\n    @ResponseStatus(HttpStatus.CREATED)\n    public void add(@RequestBody Person person) {\n        // ...\n    }\n}\n```\n\n#### 2.1 URI patterns\n\n我们可以使用通配符去匹配request\n\n* `?`匹配一个字符\n* `*`匹配一个路径段中的零个或多个字符\n* `**`匹配零个或多个路径段\n\n可以使用@PathVariable来声明URI变量并获取其值:\n\n```java\n@GetMapping(\"/owners/{ownerId}/pets/{petId}\")\npublic Pet findPet(@PathVariable Long ownerId, @PathVariable Long petId) {\n    // ...\n}\n```\n\nURI变量即可以在类层级声明，也可以在方法层级声明:\n\n```java\n@Controller\n@RequestMapping(\"/owners/{ownerId}\")\npublic class OwnerController {\n\n    @GetMapping(\"/pets/{petId}\")\n    public Pet findPet(@PathVariable(\"ownerId\") Long ownerId, @PathVariable Long petId) {\n        // ...\n    }\n}\n```\n\nURI变量会进行自动类型转换或者抛出`TypeMismatchException`异常，对于简单的类型，如`int, long, Data`，默认自动转换，对于复杂类型在此不做详解。\n\nURI变量作为参数时，有两种声明方式：\n\n1. 显性声明，如上代码块： `@PathVariable(\"ownerId\")`，这种声明方式明确规定使用的是URI模版里的ownerId变量。\n2. 直接使用@PathVariable，如上代码块`@PathVariable Long petId`，这种情况下会默认去URI模版寻找跟参数名相同的变量，但只能在使用debug模式才可以。\n\nRequest还支持正则匹配，语法格式：`{varName:regex}`，用regex声明了一个URI变量varName，例如：\n\n```java\n@GetMapping(\"/{name:[a-z-]+}-{version:\\\\d\\\\.\\\\d\\\\.\\\\d}{ext:\\\\.[a-z]+}\")\npublic void handle(@PathVariable String version, @PathVariable String ext) {\n    // ...\n}\n```\n\n#### 2.2 Pattern comparison\n\n当有多个patterns（模版）匹配到URL时，通过`AntPathMatcher.getPatternComparator(String path)`去获取最合适的patterns。\n\n对于每一个pattern，根据URI变量和通配符的个数计算出分数，分数越低优先度越高。相同分数则较长者优先度高。\n\n默认映射模版`/**`不参与比较，优先度最低。\n\n#### 2.3 Matrix variables\n\nMatrix variables可以出现在任意路径段，每个matrix variable由 \";\" 分割，例如`/cars;color=red;year=2012`。多个值既可以用 \",\" 分割，如`color=red,green,blue`，也可以重复变量名，如`color=red;color=green;color=blue`。\n\n如果一个URL可能含有matrix variables，那么请求映射模版必须使用URI模版去表示。这样可以确保匹配正确，即使matrix variables的位置不固定或不存在。\n\n如下例子，获取matrix variable \"q\"\n\n```java\n// GET /pets/42;q=11;r=22\n\n@GetMapping(\"/pets/{petId}\")\npublic void findPet(@PathVariable String petId, @MatrixVariable int q) {\n\n    // petId == 42\n    // q == 11\n}\n```\n\n多个路径段包含matrix variables的情况：\n\n```java\n// GET /owners/42;q=11/pets/21;q=22\n\n@GetMapping(\"/owners/{ownerId}/pets/{petId}\")\npublic void findPet(\n        @MatrixVariable(name=\"q\", pathVar=\"ownerId\") int q1,\n        @MatrixVariable(name=\"q\", pathVar=\"petId\") int q2) {\n\n    // q1 == 11\n    // q2 == 22\n}\n```\n\n可以设置matrix variable的required属性，`required = false`表示该参数不是必须存在的，同时可以设置defaultValue赋予默认值。如下：\n\n```Java\n// GET /pets/42\n\n@GetMapping(\"/pets/{petId}\")\npublic void findPet(@MatrixVariable(required=false, defaultValue=\"1\") int q) {\n\n    // q == 1\n}\n```\n\n可以将所有的matrix variables放置于一个Map中：\n\n```java\n// GET /owners/42;q=11;r=12/pets/21;q=22;s=23\n\n@GetMapping(\"/owners/{ownerId}/pets/{petId}\")\npublic void findPet(\n        @MatrixVariable MultiValueMap<String, String> matrixVars,\n        @MatrixVariable(pathVar=\"petId\"\") MultiValueMap<String, String> petMatrixVars) {\n\n    // matrixVars: [\"q\" : [11,22], \"r\" : 12, \"s\" : 23]\n    // petMatrixVars: [\"q\" : 22, \"s\" : 23]\n}\n```\n\n最后注意：matrix variables默认是不启用的，因此我们需要在xml文件中进行配置:\n\n```Xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"\n        http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/mvc\n        http://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n    <mvc:annotation-driven enable-matrix-variables=\"true\"/>\n\n</beans>\n```\n\n#### 2.4 Consumable media types\n\n利用`Content-Type`对请求匹配范围进行限制，从而缩小请求的映射范围。\n\n```java\n@PostMapping(path = \"/pets\", consumes = \"application/json\")\npublic void addPet(@RequestBody Pet pet) {\n    // ...\n}\n```\n\nconsumes 属性支持否定表达，`!text/plain`表示除了 \"text/plain\" 的所有content type。\n\nconsumes可以声明在class层级，与其他request mapping attributes不同的是，当声明在class层级时，method层级的consumes属性会覆盖而不是扩展class层级的声明。\n\n#### 2.5 Producible media types\n\n利用`Accept`对请求匹配范围进行限制，从而缩小请求的映射范围。类似2.4:\n\n```java\n@GetMapping(path = \"/pets/{petId}\", produces = \"application/json;charset=UTF-8\")\n@ResponseBody\npublic Pet getPet(@PathVariable String petId) {\n    // ...\n}\n```\n\n#### 2.6 params, method, headers\n\n* params 属性用于指定请求参数\n* method 属性用于限制能够访问的方法类型 //和组合注解@GetMapping等类似\n* headers 属性用于指定请求头信息\n\n三者都可以缩小请求的映射范围，支持否定表达。\n\n```java\n@GetMapping(path = \"/pets/{petId}\", params = \"myParam=myValue\")\npublic void findPet(@PathVariable String petId) {\n    // ...\n}\n@GetMapping(path = \"/pets\", headers = \"myHeader=myValue\")\npublic void findPet1(@PathVariable String petId) {\n    // ...\n}\n//和findPet1等价\n@RequestMapping(path = \"/pets\", headers = \"myHeader=myValue\", method = RequestMethod. GET)\npublic void findPet2(@PathVariable String petId) {\n    // ...\n}\n```\n\n\n\n### 3 Handler Methods\n\n#### 3.1 Method Arguments\n\n> 引用自官方文档\n\n| Controller method argument               | Description                              |\n| ---------------------------------------- | ---------------------------------------- |\n| `WebRequest`, `NativeWebRequest`         | Generic access to request parameters, request & session attributes, without direct use of the Servlet API. |\n| `javax.servlet.ServletRequest`, `javax.servlet.ServletResponse` | Choose any specific request or response type — e.g. `ServletRequest`, `HttpServletRequest`, or Spring’s `MultipartRequest`, `MultipartHttpServletRequest`. |\n| `javax.servlet.http.HttpSession`         | Enforces the presence of a session. As a consequence, such an argument is never `null`.**Note:** Session access is not thread-safe. Consider setting the`RequestMappingHandlerAdapter`'s \"synchronizeOnSession\" flag to \"true\" if multiple requests are allowed to access a session concurrently. |\n| `javax.servlet.http.PushBuilder`         | Servlet 4.0 push builder API for programmatic HTTP/2 resource pushes. Note that per Servlet spec, the injected `PushBuilder` instance can be null if the client does not support that HTTP/2 feature. |\n| `java.security.Principal`                | Currently authenticated user; possibly a specific `Principal` implementation class if known. |\n| `HttpMethod`                             | The HTTP method of the request.          |\n| `java.util.Locale`                       | The current request locale, determined by the most specific `LocaleResolver` available, in effect, the configured `LocaleResolver`/`LocaleContextResolver`. |\n| Java 6+: `java.util.TimeZone`Java 8+: `java.time.ZoneId` | The time zone associated with the current request, as determined by a `LocaleContextResolver`. |\n| `java.io.InputStream`, `java.io.Reader`  | For access to the raw request body as exposed by the Servlet API. |\n| `java.io.OutputStream`, `java.io.Writer` | For access to the raw response body as exposed by the Servlet API. |\n| `@PathVariable`                          | For access to URI template variables. See [URI patterns](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestmapping-uri-templates). |\n| `@MatrixVariable`                        | For access to name-value pairs in URI path segments. See [Matrix variables](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-matrix-variables). |\n| `@RequestParam`                          | For access to Servlet request parameters. Parameter values are converted to the declared method argument type. See [@RequestParam](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestparam). |\n| `@RequestHeader`                         | For access to request headers. Header values are converted to the declared method argument type. See [@RequestHeader](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestheader). |\n| `@RequestBody`                           | For access to the HTTP request body. Body content is converted to the declared method argument type using `HttpMessageConverter`s. See [@RequestBody](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestbody). |\n| `HttpEntity<B>`                          | For access to request headers and body. The body is converted with `HttpMessageConverter`s. See [HttpEntity](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-httpentity). |\n| `@RequestPart`                           | For access to a part in a \"multipart/form-data\" request. See [@RequestPart](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-multipart-forms-non-browsers) and [Multipart requests](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-multipart). |\n| `java.util.Map`, `org.springframework.ui.Model`, `org.springframework.ui.ModelMap` | For access and updates of the implicit model that is exposed to the web view. |\n| `RedirectAttributes`                     | Specify attributes to use in case of a redirect — i.e. to be appended to the query string, and/or flash attributes to be stored temporarily until the request after redirect. See [Redirect attributes](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-redirecting-passing-data) and [Flash attributes](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-flash-attributes). |\n| Command or form object (with optional `@ModelAttribute`) | Command object whose properties to bind to request parameters — via setters or directly to fields, with customizable type conversion, depending on `@InitBinder` methods and/or the HandlerAdapter configuration (see the `webBindingInitializer` property on`RequestMappingHandlerAdapter`).Command objects along with their validation results are exposed as model attributes, by default using the command class name - e.g. model attribute \"orderAddress\" for a command object of type \"some.package.OrderAddress\". `@ModelAttribute` can be used to customize the model attribute name. |\n| `Errors`, `BindingResult`                | Validation results for the command/form object data binding; this argument must be declared immediately after the command/form object in the controller method signature. |\n| `SessionStatus`                          | For marking form processing complete which triggers cleanup of session attributes declared through a class-level `@SessionAttributes`annotation. |\n| `UriComponentsBuilder`                   | For preparing a URL relative to the current request’s host, port, scheme, context path, and the literal part of the servlet mapping also taking into account `Forwarded` and `X-Forwarded-*` headers. |\n| `@SessionAttribute`                      | For access to any session attribute; in contrast to model attributes stored in the session as a result of a class-level `@SessionAttributes`declaration. |\n| `@RequestAttribute`                      | For access to request attributes.        |\n\n#### 3.2 Return Values\n\n> 引用自官方文档\n\n| Controller method return value           | Description                              |\n| ---------------------------------------- | ---------------------------------------- |\n| `@ResponseBody`                          | The return value is converted through `HttpMessageConverter`s and written to the response. See [@ResponseBody](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-responsebody). |\n| `HttpEntity<B>`, `ResponseEntity<B>`     | The return value specifies the full response including HTTP headers and body be converted through `HttpMessageConverter`s and written to the response. See [HttpEntity](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-httpentity). |\n| `HttpHeaders`                            | For returning a response with headers and no body. |\n| `String`                                 | A view name to be resolved with `ViewResolver`'s and used together with the implicit model — determined through command objects and `@ModelAttribute`methods. The handler method may also programmatically enrich the model by declaring a `Model`argument (see above). |\n| `View`                                   | A `View` instance to use for rendering together with the implicit model — determined through command objects and `@ModelAttribute` methods. The handler method may also programmatically enrich the model by declaring a `Model` argument (see above). |\n| `java.util.Map`, `org.springframework.ui.Model` | Attributes to be added to the implicit model with the view name implicitly determined through a `RequestToViewNameTranslator`. |\n| `ModelAndView` object                    | The view and model attributes to use, and optionally a response status. |\n| `void`                                   | A method with a `void` return type (or `null` return value) is considered to have fully handled the response if it also has a `ServletResponse`, or an `OutputStream` argument, or an `@ResponseStatus` annotation. The same is true also if the controller has made a positive ETag or lastModified timestamp check (see [@Controller caching](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-caching-etag-lastmodified) for details).If none of the above is true, a `void`return type may also indicate \"no response body\" for REST controllers, or default view name selection for HTML controllers. |\n| `Callable<V>`                            | Produce any of the above return values asynchronously in a Spring MVC managed thread. |\n| `DeferredResult<V>`                      | Produce any of the above return values asynchronously from any thread — e.g. possibly as a result of some event or callback. |\n| ListenableFuture<V>, java.util.concurrent.CompletionStage<V>, java.util.concurrent.CompletableFuture<V> | Alternative to `DeferredResult` as a convenience for example when an underlying service returns one of those. |\n| `ResponseBodyEmitter`, `SseEmitter`      | Emit a stream of objects asynchronously to be written to the response with`HttpMessageConverter`'s; also supported as the body of a `ResponseEntity`. |\n| `StreamingResponseBody`                  | Write to the response `OutputStream` asynchronously; also supported as the body of a`ResponseEntity`. |\n| Reactive types — Reactor, RxJava, or others via `ReactiveAdapterRegistry` | Alternative to ``DeferredResult`with multi-value streams (e.g. `Flux`, `Observable`) collected to a `List`.For streaming scenarios — .e.g. `text/event-stream`, `application/json+stream`,`SseEmitter` and `ResponseBodyEmitter` are used instead, where `ServletOutputStream` blocking I/O is performed on a Spring MVC managed thread and back pressure applied against the completion of each write.See [Reactive return values](https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-async-reactive-types). |\n| Any other return type                    | A single model attribute to be added to the implicit model with the view name implicitly determined through a `RequestToViewNameTranslator`; the attribute name may be specified through a method-level `@ModelAttribute` or otherwise a name is selected based on the class name of the return type. |\n\n#### 3.3 @RequestParam\n\n使用 @RequestParam 绑定 HttpServletRequest 请求参数到控制器方法参数：\n\n```java\n@Controller\n@RequestMapping(\"/pets\")\n@SessionAttributes(\"pet\")\npublic class EditPetForm {\n\n    // ...\n\n    @GetMapping\n    public String setupForm(@RequestParam(\"petId\") int petId, ModelMap model) {\n        Pet pet = this.clinic.loadPet(petId);\n        model.addAttribute(\"pet\", pet);\n        return \"petForm\";\n    }\n\n    // ...\n\n}\n```\n\n绑定的参数默认必须存在，可以通过required属性修改，如`@RequestParam(name=\"id\", required=false)`。\n\n如果控制器方法参数类型不是string，将会执行自动类型转换。\n\n#### 3.4 @RequestHeader\n\n使用@RequestHeader绑定绑定 HttpServletRequest 头信息到控制器方法参数。\n\n一个request header例子:\n\n```\nHost                    localhost:8080\nAccept                  text/html,application/xhtml+xml,application/xml;q=0.9\nAccept-Language         fr,en-gb;q=0.7,en;q=0.3\nAccept-Encoding         gzip,deflate\nAccept-Charset          ISO-8859-1,utf-8;q=0.7,*;q=0.7\nKeep-Alive              300\n```\n\n下面的例子演示了如何获取 `Accept-Encoding`和 `Keep-Alive` 的值：\n\n```java\n@RequestMapping(\"/displayHeaderInfo.do\")\npublic void displayHeaderInfo(@RequestHeader(\"Accept-Encoding\") String encoding,\n        @RequestHeader(\"Keep-Alive\") long keepAlive) {\n    //...\n}\n```\n\n如果控制器方法参数类型不是string，将会执行自动类型转换。\n\n#### 3.5 @CookieValue\n\n使用@CookieValue绑定绑定 HttpServletRequest 的cookie信息到控制器方法参数。\n\n假设http request中有如下cookie信息：\n\n```\nJSESSIONID=415A4AC178C59DACE0B2C9CA727CDD84\n```\n\n下面的例子演示了如何获取JESSIONID的值：\n\n```java\n@RequestMapping(\"/displayHeaderInfo.do\")\npublic void displayHeaderInfo(@CookieValue(\"JSESSIONID\") String cookie) {\n    //...\n}\n```\n\n#### 3.6 @ModelAttribute\n\n//TODO","slug":"SpringMVC-Controllers-说明文档","published":1,"updated":"2018-01-06T13:57:02.781Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owc0000pfb9lmsftyumg","content":"<p>翻译自官方文档，并加上了自己的理解，解释更加直白。</p>\n<p>官方文档地址：<a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc\" target=\"_blank\" rel=\"noopener\">Spring Web MVC</a></p>\n<a id=\"more\"></a>\n<h3 id=\"1-Declaration\"><a href=\"#1-Declaration\" class=\"headerlink\" title=\"1 Declaration\"></a>1 Declaration</h3><p>使用@Controller注解标记一个类，这个类就是一个SpringMVC Controller对象。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Controller</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HelloController</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/hello\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">handle</span><span class=\"params\">(Model model)</span> </span>&#123;</span><br><span class=\"line\">        model.addAttribute(<span class=\"string\">\"message\"</span>, <span class=\"string\">\"Hello World!\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"index\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在XML文件进行配置，告诉Spring应该到哪里去找Controller控制器，加上如下一行，base-package 即controller所在位置</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;context:component-scan base-<span class=\"keyword\">package</span>=<span class=\"string\">\"org.example.web\"</span>/&gt;</span><br></pre></td></tr></table></figure>\n<p>完整XML配置文件</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">beans</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://www.springframework.org/schema/beans\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:p</span>=<span class=\"string\">\"http://www.springframework.org/schema/p\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:context</span>=<span class=\"string\">\"http://www.springframework.org/schema/context\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/beans</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/context</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/context/spring-context.xsd\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">context:component-scan</span> <span class=\"attr\">base-package</span>=<span class=\"string\">\"org.example.web\"</span>/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- ... --&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"2-Request-Mapping\"><a href=\"#2-Request-Mapping\" class=\"headerlink\" title=\"2 Request Mapping\"></a>2 Request Mapping</h3><p>@RequestMapping 注解用于映射Request请求与与controller的处理方法。该注解有多个参数可以配置Request请求的属性，如URL，HTTP method，request parameters，headers，media types。</p>\n<p>@RequestMapping 可以用于类也可以用于类方法。当@RequestMapping 标记在Controller 类上的时候，里面使用@RequestMapping 标记的方法的请求地址都是相对于类上的@RequestMapping 而言的；当Controller 类上没有标记@RequestMapping 注解时，方法上的@RequestMapping 都是绝对路径。最终路径都是相对于跟路径”/“的。通过这种组合的方法可以限制Request的匹配。</p>\n<p>在SpringMVC 4.3 引入了组合注解来简化@RequestMapping的写法。</p>\n<ul>\n<li>@GetMapping </li>\n<li>@PostMapping</li>\n<li>@PutMapping</li>\n<li>@DeleteMapping</li>\n<li>@PatchMapping</li>\n</ul>\n<p>如@GetMapping等价于@RequestMapping(method = RequestMethod.GET)，组合注解通常用于method上，如下</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RestController</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/persons\"</span>)</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PersonController</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/&#123;id&#125;\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Person <span class=\"title\">getPerson</span><span class=\"params\">(@PathVariable Long id)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// ...</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@PostMapping</span></span><br><span class=\"line\">    <span class=\"meta\">@ResponseStatus</span>(HttpStatus.CREATED)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">add</span><span class=\"params\">(@RequestBody Person person)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// ...</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-1-URI-patterns\"><a href=\"#2-1-URI-patterns\" class=\"headerlink\" title=\"2.1 URI patterns\"></a>2.1 URI patterns</h4><p>我们可以使用通配符去匹配request</p>\n<ul>\n<li><code>?</code>匹配一个字符</li>\n<li><code>*</code>匹配一个路径段中的零个或多个字符</li>\n<li><code>**</code>匹配零个或多个路径段</li>\n</ul>\n<p>可以使用@PathVariable来声明URI变量并获取其值:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Pet <span class=\"title\">findPet</span><span class=\"params\">(@PathVariable Long ownerId, @PathVariable Long petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>URI变量即可以在类层级声明，也可以在方法层级声明:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Controller</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/owners/&#123;ownerId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">OwnerController</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Pet <span class=\"title\">findPet</span><span class=\"params\">(@PathVariable(<span class=\"string\">\"ownerId\"</span>)</span> Long ownerId, @PathVariable Long petId) </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// ...</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>URI变量会进行自动类型转换或者抛出<code>TypeMismatchException</code>异常，对于简单的类型，如<code>int, long, Data</code>，默认自动转换，对于复杂类型在此不做详解。</p>\n<p>URI变量作为参数时，有两种声明方式：</p>\n<ol>\n<li>显性声明，如上代码块： <code>@PathVariable(&quot;ownerId&quot;)</code>，这种声明方式明确规定使用的是URI模版里的ownerId变量。</li>\n<li>直接使用@PathVariable，如上代码块<code>@PathVariable Long petId</code>，这种情况下会默认去URI模版寻找跟参数名相同的变量，但只能在使用debug模式才可以。</li>\n</ol>\n<p>Request还支持正则匹配，语法格式：<code>{varName:regex}</code>，用regex声明了一个URI变量varName，例如：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/&#123;name:[a-z-]+&#125;-&#123;version:\\\\d\\\\.\\\\d\\\\.\\\\d&#125;&#123;ext:\\\\.[a-z]+&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">handle</span><span class=\"params\">(@PathVariable String version, @PathVariable String ext)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-2-Pattern-comparison\"><a href=\"#2-2-Pattern-comparison\" class=\"headerlink\" title=\"2.2 Pattern comparison\"></a>2.2 Pattern comparison</h4><p>当有多个patterns（模版）匹配到URL时，通过<code>AntPathMatcher.getPatternComparator(String path)</code>去获取最合适的patterns。</p>\n<p>对于每一个pattern，根据URI变量和通配符的个数计算出分数，分数越低优先度越高。相同分数则较长者优先度高。</p>\n<p>默认映射模版<code>/**</code>不参与比较，优先度最低。</p>\n<h4 id=\"2-3-Matrix-variables\"><a href=\"#2-3-Matrix-variables\" class=\"headerlink\" title=\"2.3 Matrix variables\"></a>2.3 Matrix variables</h4><p>Matrix variables可以出现在任意路径段，每个matrix variable由 “;” 分割，例如<code>/cars;color=red;year=2012</code>。多个值既可以用 “,” 分割，如<code>color=red,green,blue</code>，也可以重复变量名，如<code>color=red;color=green;color=blue</code>。</p>\n<p>如果一个URL可能含有matrix variables，那么请求映射模版必须使用URI模版去表示。这样可以确保匹配正确，即使matrix variables的位置不固定或不存在。</p>\n<p>如下例子，获取matrix variable “q”</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// GET /pets/42;q=11;r=22</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(@PathVariable String petId, @MatrixVariable <span class=\"keyword\">int</span> q)</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// petId == 42</span></span><br><span class=\"line\">    <span class=\"comment\">// q == 11</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>多个路径段包含matrix variables的情况：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// GET /owners/42;q=11/pets/21;q=22</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        @MatrixVariable(name=<span class=\"string\">\"q\"</span>, pathVar=<span class=\"string\">\"ownerId\"</span>)</span> <span class=\"keyword\">int</span> q1,</span></span><br><span class=\"line\"><span class=\"function\">        @<span class=\"title\">MatrixVariable</span><span class=\"params\">(name=<span class=\"string\">\"q\"</span>, pathVar=<span class=\"string\">\"petId\"</span>)</span> <span class=\"keyword\">int</span> q2) </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// q1 == 11</span></span><br><span class=\"line\">    <span class=\"comment\">// q2 == 22</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以设置matrix variable的required属性，<code>required = false</code>表示该参数不是必须存在的，同时可以设置defaultValue赋予默认值。如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// GET /pets/42</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(@MatrixVariable(required=<span class=\"keyword\">false</span>, defaultValue=<span class=\"string\">\"1\"</span>)</span> <span class=\"keyword\">int</span> q) </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// q == 1</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以将所有的matrix variables放置于一个Map中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// GET /owners/42;q=11;r=12/pets/21;q=22;s=23</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        @MatrixVariable MultiValueMap&lt;String, String&gt; matrixVars,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        @MatrixVariable(pathVar=<span class=\"string\">\"petId\"</span><span class=\"string\">\") MultiValueMap&lt;String, String&gt; petMatrixVars) &#123;</span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"><span class=\"string\"></span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"><span class=\"string\">    // matrixVars: [\"</span>q<span class=\"string\">\" : [11,22], \"</span>r<span class=\"string\">\" : 12, \"</span>s<span class=\"string\">\" : 23]</span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"><span class=\"string\">    // petMatrixVars: [\"</span>q<span class=\"string\">\" : 22, \"</span>s<span class=\"string\">\" : 23]</span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"><span class=\"string\">&#125;</span></span></span></span><br></pre></td></tr></table></figure>\n<p>最后注意：matrix variables默认是不启用的，因此我们需要在xml文件中进行配置:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">beans</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://www.springframework.org/schema/beans\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:mvc</span>=<span class=\"string\">\"http://www.springframework.org/schema/mvc\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/beans</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/mvc</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/mvc/spring-mvc.xsd\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">mvc:annotation-driven</span> <span class=\"attr\">enable-matrix-variables</span>=<span class=\"string\">\"true\"</span>/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"2-4-Consumable-media-types\"><a href=\"#2-4-Consumable-media-types\" class=\"headerlink\" title=\"2.4 Consumable media types\"></a>2.4 Consumable media types</h4><p>利用<code>Content-Type</code>对请求匹配范围进行限制，从而缩小请求的映射范围。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping</span>(path = <span class=\"string\">\"/pets\"</span>, consumes = <span class=\"string\">\"application/json\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">addPet</span><span class=\"params\">(@RequestBody Pet pet)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>consumes 属性支持否定表达，<code>!text/plain</code>表示除了 “text/plain” 的所有content type。</p>\n<p>consumes可以声明在class层级，与其他request mapping attributes不同的是，当声明在class层级时，method层级的consumes属性会覆盖而不是扩展class层级的声明。</p>\n<h4 id=\"2-5-Producible-media-types\"><a href=\"#2-5-Producible-media-types\" class=\"headerlink\" title=\"2.5 Producible media types\"></a>2.5 Producible media types</h4><p>利用<code>Accept</code>对请求匹配范围进行限制，从而缩小请求的映射范围。类似2.4:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@GetMapping</span>(path = <span class=\"string\">\"/pets/&#123;petId&#125;\"</span>, produces = <span class=\"string\">\"application/json;charset=UTF-8\"</span>)</span><br><span class=\"line\"><span class=\"meta\">@ResponseBody</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Pet <span class=\"title\">getPet</span><span class=\"params\">(@PathVariable String petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-6-params-method-headers\"><a href=\"#2-6-params-method-headers\" class=\"headerlink\" title=\"2.6 params, method, headers\"></a>2.6 params, method, headers</h4><ul>\n<li>params 属性用于指定请求参数</li>\n<li>method 属性用于限制能够访问的方法类型 //和组合注解@GetMapping等类似</li>\n<li>headers 属性用于指定请求头信息</li>\n</ul>\n<p>三者都可以缩小请求的映射范围，支持否定表达。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@GetMapping</span>(path = <span class=\"string\">\"/pets/&#123;petId&#125;\"</span>, params = <span class=\"string\">\"myParam=myValue\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(@PathVariable String petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(path = <span class=\"string\">\"/pets\"</span>, headers = <span class=\"string\">\"myHeader=myValue\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet1</span><span class=\"params\">(@PathVariable String petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//和findPet1等价</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(path = <span class=\"string\">\"/pets\"</span>, headers = <span class=\"string\">\"myHeader=myValue\"</span>, method = RequestMethod. GET)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet2</span><span class=\"params\">(@PathVariable String petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-Handler-Methods\"><a href=\"#3-Handler-Methods\" class=\"headerlink\" title=\"3 Handler Methods\"></a>3 Handler Methods</h3><h4 id=\"3-1-Method-Arguments\"><a href=\"#3-1-Method-Arguments\" class=\"headerlink\" title=\"3.1 Method Arguments\"></a>3.1 Method Arguments</h4><blockquote>\n<p>引用自官方文档</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Controller method argument</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>WebRequest</code>, <code>NativeWebRequest</code></td>\n<td>Generic access to request parameters, request &amp; session attributes, without direct use of the Servlet API.</td>\n</tr>\n<tr>\n<td><code>javax.servlet.ServletRequest</code>, <code>javax.servlet.ServletResponse</code></td>\n<td>Choose any specific request or response type — e.g. <code>ServletRequest</code>, <code>HttpServletRequest</code>, or Spring’s <code>MultipartRequest</code>, <code>MultipartHttpServletRequest</code>.</td>\n</tr>\n<tr>\n<td><code>javax.servlet.http.HttpSession</code></td>\n<td>Enforces the presence of a session. As a consequence, such an argument is never <code>null</code>.<strong>Note:</strong> Session access is not thread-safe. Consider setting the<code>RequestMappingHandlerAdapter</code>‘s “synchronizeOnSession” flag to “true” if multiple requests are allowed to access a session concurrently.</td>\n</tr>\n<tr>\n<td><code>javax.servlet.http.PushBuilder</code></td>\n<td>Servlet 4.0 push builder API for programmatic HTTP/2 resource pushes. Note that per Servlet spec, the injected <code>PushBuilder</code> instance can be null if the client does not support that HTTP/2 feature.</td>\n</tr>\n<tr>\n<td><code>java.security.Principal</code></td>\n<td>Currently authenticated user; possibly a specific <code>Principal</code> implementation class if known.</td>\n</tr>\n<tr>\n<td><code>HttpMethod</code></td>\n<td>The HTTP method of the request.</td>\n</tr>\n<tr>\n<td><code>java.util.Locale</code></td>\n<td>The current request locale, determined by the most specific <code>LocaleResolver</code> available, in effect, the configured <code>LocaleResolver</code>/<code>LocaleContextResolver</code>.</td>\n</tr>\n<tr>\n<td>Java 6+: <code>java.util.TimeZone</code>Java 8+: <code>java.time.ZoneId</code></td>\n<td>The time zone associated with the current request, as determined by a <code>LocaleContextResolver</code>.</td>\n</tr>\n<tr>\n<td><code>java.io.InputStream</code>, <code>java.io.Reader</code></td>\n<td>For access to the raw request body as exposed by the Servlet API.</td>\n</tr>\n<tr>\n<td><code>java.io.OutputStream</code>, <code>java.io.Writer</code></td>\n<td>For access to the raw response body as exposed by the Servlet API.</td>\n</tr>\n<tr>\n<td><code>@PathVariable</code></td>\n<td>For access to URI template variables. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestmapping-uri-templates\" target=\"_blank\" rel=\"noopener\">URI patterns</a>.</td>\n</tr>\n<tr>\n<td><code>@MatrixVariable</code></td>\n<td>For access to name-value pairs in URI path segments. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-matrix-variables\" target=\"_blank\" rel=\"noopener\">Matrix variables</a>.</td>\n</tr>\n<tr>\n<td><code>@RequestParam</code></td>\n<td>For access to Servlet request parameters. Parameter values are converted to the declared method argument type. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestparam\" target=\"_blank\" rel=\"noopener\">@RequestParam</a>.</td>\n</tr>\n<tr>\n<td><code>@RequestHeader</code></td>\n<td>For access to request headers. Header values are converted to the declared method argument type. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestheader\" target=\"_blank\" rel=\"noopener\">@RequestHeader</a>.</td>\n</tr>\n<tr>\n<td><code>@RequestBody</code></td>\n<td>For access to the HTTP request body. Body content is converted to the declared method argument type using <code>HttpMessageConverter</code>s. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestbody\" target=\"_blank\" rel=\"noopener\">@RequestBody</a>.</td>\n</tr>\n<tr>\n<td><code>HttpEntity&lt;B&gt;</code></td>\n<td>For access to request headers and body. The body is converted with <code>HttpMessageConverter</code>s. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-httpentity\" target=\"_blank\" rel=\"noopener\">HttpEntity</a>.</td>\n</tr>\n<tr>\n<td><code>@RequestPart</code></td>\n<td>For access to a part in a “multipart/form-data” request. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-multipart-forms-non-browsers\" target=\"_blank\" rel=\"noopener\">@RequestPart</a> and <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-multipart\" target=\"_blank\" rel=\"noopener\">Multipart requests</a>.</td>\n</tr>\n<tr>\n<td><code>java.util.Map</code>, <code>org.springframework.ui.Model</code>, <code>org.springframework.ui.ModelMap</code></td>\n<td>For access and updates of the implicit model that is exposed to the web view.</td>\n</tr>\n<tr>\n<td><code>RedirectAttributes</code></td>\n<td>Specify attributes to use in case of a redirect — i.e. to be appended to the query string, and/or flash attributes to be stored temporarily until the request after redirect. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-redirecting-passing-data\" target=\"_blank\" rel=\"noopener\">Redirect attributes</a> and <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-flash-attributes\" target=\"_blank\" rel=\"noopener\">Flash attributes</a>.</td>\n</tr>\n<tr>\n<td>Command or form object (with optional <code>@ModelAttribute</code>)</td>\n<td>Command object whose properties to bind to request parameters — via setters or directly to fields, with customizable type conversion, depending on <code>@InitBinder</code> methods and/or the HandlerAdapter configuration (see the <code>webBindingInitializer</code> property on<code>RequestMappingHandlerAdapter</code>).Command objects along with their validation results are exposed as model attributes, by default using the command class name - e.g. model attribute “orderAddress” for a command object of type “some.package.OrderAddress”. <code>@ModelAttribute</code> can be used to customize the model attribute name.</td>\n</tr>\n<tr>\n<td><code>Errors</code>, <code>BindingResult</code></td>\n<td>Validation results for the command/form object data binding; this argument must be declared immediately after the command/form object in the controller method signature.</td>\n</tr>\n<tr>\n<td><code>SessionStatus</code></td>\n<td>For marking form processing complete which triggers cleanup of session attributes declared through a class-level <code>@SessionAttributes</code>annotation.</td>\n</tr>\n<tr>\n<td><code>UriComponentsBuilder</code></td>\n<td>For preparing a URL relative to the current request’s host, port, scheme, context path, and the literal part of the servlet mapping also taking into account <code>Forwarded</code> and <code>X-Forwarded-*</code> headers.</td>\n</tr>\n<tr>\n<td><code>@SessionAttribute</code></td>\n<td>For access to any session attribute; in contrast to model attributes stored in the session as a result of a class-level <code>@SessionAttributes</code>declaration.</td>\n</tr>\n<tr>\n<td><code>@RequestAttribute</code></td>\n<td>For access to request attributes.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"3-2-Return-Values\"><a href=\"#3-2-Return-Values\" class=\"headerlink\" title=\"3.2 Return Values\"></a>3.2 Return Values</h4><blockquote>\n<p>引用自官方文档</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Controller method return value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>@ResponseBody</code></td>\n<td>The return value is converted through <code>HttpMessageConverter</code>s and written to the response. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-responsebody\" target=\"_blank\" rel=\"noopener\">@ResponseBody</a>.</td>\n</tr>\n<tr>\n<td><code>HttpEntity&lt;B&gt;</code>, <code>ResponseEntity&lt;B&gt;</code></td>\n<td>The return value specifies the full response including HTTP headers and body be converted through <code>HttpMessageConverter</code>s and written to the response. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-httpentity\" target=\"_blank\" rel=\"noopener\">HttpEntity</a>.</td>\n</tr>\n<tr>\n<td><code>HttpHeaders</code></td>\n<td>For returning a response with headers and no body.</td>\n</tr>\n<tr>\n<td><code>String</code></td>\n<td>A view name to be resolved with <code>ViewResolver</code>‘s and used together with the implicit model — determined through command objects and <code>@ModelAttribute</code>methods. The handler method may also programmatically enrich the model by declaring a <code>Model</code>argument (see above).</td>\n</tr>\n<tr>\n<td><code>View</code></td>\n<td>A <code>View</code> instance to use for rendering together with the implicit model — determined through command objects and <code>@ModelAttribute</code> methods. The handler method may also programmatically enrich the model by declaring a <code>Model</code> argument (see above).</td>\n</tr>\n<tr>\n<td><code>java.util.Map</code>, <code>org.springframework.ui.Model</code></td>\n<td>Attributes to be added to the implicit model with the view name implicitly determined through a <code>RequestToViewNameTranslator</code>.</td>\n</tr>\n<tr>\n<td><code>ModelAndView</code> object</td>\n<td>The view and model attributes to use, and optionally a response status.</td>\n</tr>\n<tr>\n<td><code>void</code></td>\n<td>A method with a <code>void</code> return type (or <code>null</code> return value) is considered to have fully handled the response if it also has a <code>ServletResponse</code>, or an <code>OutputStream</code> argument, or an <code>@ResponseStatus</code> annotation. The same is true also if the controller has made a positive ETag or lastModified timestamp check (see <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-caching-etag-lastmodified\" target=\"_blank\" rel=\"noopener\">@Controller caching</a> for details).If none of the above is true, a <code>void</code>return type may also indicate “no response body” for REST controllers, or default view name selection for HTML controllers.</td>\n</tr>\n<tr>\n<td><code>Callable&lt;V&gt;</code></td>\n<td>Produce any of the above return values asynchronously in a Spring MVC managed thread.</td>\n</tr>\n<tr>\n<td><code>DeferredResult&lt;V&gt;</code></td>\n<td>Produce any of the above return values asynchronously from any thread — e.g. possibly as a result of some event or callback.</td>\n</tr>\n<tr>\n<td>ListenableFuture<v>, java.util.concurrent.CompletionStage<v>, java.util.concurrent.CompletableFuture<v></v></v></v></td>\n<td>Alternative to <code>DeferredResult</code> as a convenience for example when an underlying service returns one of those.</td>\n</tr>\n<tr>\n<td><code>ResponseBodyEmitter</code>, <code>SseEmitter</code></td>\n<td>Emit a stream of objects asynchronously to be written to the response with<code>HttpMessageConverter</code>‘s; also supported as the body of a <code>ResponseEntity</code>.</td>\n</tr>\n<tr>\n<td><code>StreamingResponseBody</code></td>\n<td>Write to the response <code>OutputStream</code> asynchronously; also supported as the body of a<code>ResponseEntity</code>.</td>\n</tr>\n<tr>\n<td>Reactive types — Reactor, RxJava, or others via <code>ReactiveAdapterRegistry</code></td>\n<td>Alternative to <code>`DeferredResult</code>with multi-value streams (e.g. <code>Flux</code>, <code>Observable</code>) collected to a <code>List</code>.For streaming scenarios — .e.g. <code>text/event-stream</code>, <code>application/json+stream</code>,<code>SseEmitter</code> and <code>ResponseBodyEmitter</code> are used instead, where <code>ServletOutputStream</code> blocking I/O is performed on a Spring MVC managed thread and back pressure applied against the completion of each write.See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-async-reactive-types\" target=\"_blank\" rel=\"noopener\">Reactive return values</a>.</td>\n</tr>\n<tr>\n<td>Any other return type</td>\n<td>A single model attribute to be added to the implicit model with the view name implicitly determined through a <code>RequestToViewNameTranslator</code>; the attribute name may be specified through a method-level <code>@ModelAttribute</code> or otherwise a name is selected based on the class name of the return type.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"3-3-RequestParam\"><a href=\"#3-3-RequestParam\" class=\"headerlink\" title=\"3.3 @RequestParam\"></a>3.3 @RequestParam</h4><p>使用 @RequestParam 绑定 HttpServletRequest 请求参数到控制器方法参数：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Controller</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/pets\"</span>)</span><br><span class=\"line\"><span class=\"meta\">@SessionAttributes</span>(<span class=\"string\">\"pet\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EditPetForm</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">setupForm</span><span class=\"params\">(@RequestParam(<span class=\"string\">\"petId\"</span>)</span> <span class=\"keyword\">int</span> petId, ModelMap model) </span>&#123;</span><br><span class=\"line\">        Pet pet = <span class=\"keyword\">this</span>.clinic.loadPet(petId);</span><br><span class=\"line\">        model.addAttribute(<span class=\"string\">\"pet\"</span>, pet);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"petForm\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>绑定的参数默认必须存在，可以通过required属性修改，如<code>@RequestParam(name=&quot;id&quot;, required=false)</code>。</p>\n<p>如果控制器方法参数类型不是string，将会执行自动类型转换。</p>\n<h4 id=\"3-4-RequestHeader\"><a href=\"#3-4-RequestHeader\" class=\"headerlink\" title=\"3.4 @RequestHeader\"></a>3.4 @RequestHeader</h4><p>使用@RequestHeader绑定绑定 HttpServletRequest 头信息到控制器方法参数。</p>\n<p>一个request header例子:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host                    localhost:8080</span><br><span class=\"line\">Accept                  text/html,application/xhtml+xml,application/xml;q=0.9</span><br><span class=\"line\">Accept-Language         fr,en-gb;q=0.7,en;q=0.3</span><br><span class=\"line\">Accept-Encoding         gzip,deflate</span><br><span class=\"line\">Accept-Charset          ISO-8859-1,utf-8;q=0.7,*;q=0.7</span><br><span class=\"line\">Keep-Alive              300</span><br></pre></td></tr></table></figure>\n<p>下面的例子演示了如何获取 <code>Accept-Encoding</code>和 <code>Keep-Alive</code> 的值：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/displayHeaderInfo.do\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">displayHeaderInfo</span><span class=\"params\">(@RequestHeader(<span class=\"string\">\"Accept-Encoding\"</span>)</span> String encoding,</span></span><br><span class=\"line\"><span class=\"function\">        @<span class=\"title\">RequestHeader</span><span class=\"params\">(<span class=\"string\">\"Keep-Alive\"</span>)</span> <span class=\"keyword\">long</span> keepAlive) </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果控制器方法参数类型不是string，将会执行自动类型转换。</p>\n<h4 id=\"3-5-CookieValue\"><a href=\"#3-5-CookieValue\" class=\"headerlink\" title=\"3.5 @CookieValue\"></a>3.5 @CookieValue</h4><p>使用@CookieValue绑定绑定 HttpServletRequest 的cookie信息到控制器方法参数。</p>\n<p>假设http request中有如下cookie信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JSESSIONID=415A4AC178C59DACE0B2C9CA727CDD84</span><br></pre></td></tr></table></figure>\n<p>下面的例子演示了如何获取JESSIONID的值：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/displayHeaderInfo.do\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">displayHeaderInfo</span><span class=\"params\">(@CookieValue(<span class=\"string\">\"JSESSIONID\"</span>)</span> String cookie) </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-6-ModelAttribute\"><a href=\"#3-6-ModelAttribute\" class=\"headerlink\" title=\"3.6 @ModelAttribute\"></a>3.6 @ModelAttribute</h4><p>//TODO</p>\n","site":{"data":{}},"excerpt":"<p>翻译自官方文档，并加上了自己的理解，解释更加直白。</p>\n<p>官方文档地址：<a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc\" target=\"_blank\" rel=\"noopener\">Spring Web MVC</a></p>","more":"<h3 id=\"1-Declaration\"><a href=\"#1-Declaration\" class=\"headerlink\" title=\"1 Declaration\"></a>1 Declaration</h3><p>使用@Controller注解标记一个类，这个类就是一个SpringMVC Controller对象。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Controller</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HelloController</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/hello\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">handle</span><span class=\"params\">(Model model)</span> </span>&#123;</span><br><span class=\"line\">        model.addAttribute(<span class=\"string\">\"message\"</span>, <span class=\"string\">\"Hello World!\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"index\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在XML文件进行配置，告诉Spring应该到哪里去找Controller控制器，加上如下一行，base-package 即controller所在位置</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;context:component-scan base-<span class=\"keyword\">package</span>=<span class=\"string\">\"org.example.web\"</span>/&gt;</span><br></pre></td></tr></table></figure>\n<p>完整XML配置文件</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">beans</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://www.springframework.org/schema/beans\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:p</span>=<span class=\"string\">\"http://www.springframework.org/schema/p\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:context</span>=<span class=\"string\">\"http://www.springframework.org/schema/context\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/beans</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/context</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/context/spring-context.xsd\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">context:component-scan</span> <span class=\"attr\">base-package</span>=<span class=\"string\">\"org.example.web\"</span>/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">&lt;!-- ... --&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"2-Request-Mapping\"><a href=\"#2-Request-Mapping\" class=\"headerlink\" title=\"2 Request Mapping\"></a>2 Request Mapping</h3><p>@RequestMapping 注解用于映射Request请求与与controller的处理方法。该注解有多个参数可以配置Request请求的属性，如URL，HTTP method，request parameters，headers，media types。</p>\n<p>@RequestMapping 可以用于类也可以用于类方法。当@RequestMapping 标记在Controller 类上的时候，里面使用@RequestMapping 标记的方法的请求地址都是相对于类上的@RequestMapping 而言的；当Controller 类上没有标记@RequestMapping 注解时，方法上的@RequestMapping 都是绝对路径。最终路径都是相对于跟路径”/“的。通过这种组合的方法可以限制Request的匹配。</p>\n<p>在SpringMVC 4.3 引入了组合注解来简化@RequestMapping的写法。</p>\n<ul>\n<li>@GetMapping </li>\n<li>@PostMapping</li>\n<li>@PutMapping</li>\n<li>@DeleteMapping</li>\n<li>@PatchMapping</li>\n</ul>\n<p>如@GetMapping等价于@RequestMapping(method = RequestMethod.GET)，组合注解通常用于method上，如下</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RestController</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/persons\"</span>)</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PersonController</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/&#123;id&#125;\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Person <span class=\"title\">getPerson</span><span class=\"params\">(@PathVariable Long id)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// ...</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@PostMapping</span></span><br><span class=\"line\">    <span class=\"meta\">@ResponseStatus</span>(HttpStatus.CREATED)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">add</span><span class=\"params\">(@RequestBody Person person)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// ...</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-1-URI-patterns\"><a href=\"#2-1-URI-patterns\" class=\"headerlink\" title=\"2.1 URI patterns\"></a>2.1 URI patterns</h4><p>我们可以使用通配符去匹配request</p>\n<ul>\n<li><code>?</code>匹配一个字符</li>\n<li><code>*</code>匹配一个路径段中的零个或多个字符</li>\n<li><code>**</code>匹配零个或多个路径段</li>\n</ul>\n<p>可以使用@PathVariable来声明URI变量并获取其值:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Pet <span class=\"title\">findPet</span><span class=\"params\">(@PathVariable Long ownerId, @PathVariable Long petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>URI变量即可以在类层级声明，也可以在方法层级声明:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Controller</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/owners/&#123;ownerId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">OwnerController</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Pet <span class=\"title\">findPet</span><span class=\"params\">(@PathVariable(<span class=\"string\">\"ownerId\"</span>)</span> Long ownerId, @PathVariable Long petId) </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// ...</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>URI变量会进行自动类型转换或者抛出<code>TypeMismatchException</code>异常，对于简单的类型，如<code>int, long, Data</code>，默认自动转换，对于复杂类型在此不做详解。</p>\n<p>URI变量作为参数时，有两种声明方式：</p>\n<ol>\n<li>显性声明，如上代码块： <code>@PathVariable(&quot;ownerId&quot;)</code>，这种声明方式明确规定使用的是URI模版里的ownerId变量。</li>\n<li>直接使用@PathVariable，如上代码块<code>@PathVariable Long petId</code>，这种情况下会默认去URI模版寻找跟参数名相同的变量，但只能在使用debug模式才可以。</li>\n</ol>\n<p>Request还支持正则匹配，语法格式：<code>{varName:regex}</code>，用regex声明了一个URI变量varName，例如：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/&#123;name:[a-z-]+&#125;-&#123;version:\\\\d\\\\.\\\\d\\\\.\\\\d&#125;&#123;ext:\\\\.[a-z]+&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">handle</span><span class=\"params\">(@PathVariable String version, @PathVariable String ext)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-2-Pattern-comparison\"><a href=\"#2-2-Pattern-comparison\" class=\"headerlink\" title=\"2.2 Pattern comparison\"></a>2.2 Pattern comparison</h4><p>当有多个patterns（模版）匹配到URL时，通过<code>AntPathMatcher.getPatternComparator(String path)</code>去获取最合适的patterns。</p>\n<p>对于每一个pattern，根据URI变量和通配符的个数计算出分数，分数越低优先度越高。相同分数则较长者优先度高。</p>\n<p>默认映射模版<code>/**</code>不参与比较，优先度最低。</p>\n<h4 id=\"2-3-Matrix-variables\"><a href=\"#2-3-Matrix-variables\" class=\"headerlink\" title=\"2.3 Matrix variables\"></a>2.3 Matrix variables</h4><p>Matrix variables可以出现在任意路径段，每个matrix variable由 “;” 分割，例如<code>/cars;color=red;year=2012</code>。多个值既可以用 “,” 分割，如<code>color=red,green,blue</code>，也可以重复变量名，如<code>color=red;color=green;color=blue</code>。</p>\n<p>如果一个URL可能含有matrix variables，那么请求映射模版必须使用URI模版去表示。这样可以确保匹配正确，即使matrix variables的位置不固定或不存在。</p>\n<p>如下例子，获取matrix variable “q”</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// GET /pets/42;q=11;r=22</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(@PathVariable String petId, @MatrixVariable <span class=\"keyword\">int</span> q)</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// petId == 42</span></span><br><span class=\"line\">    <span class=\"comment\">// q == 11</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>多个路径段包含matrix variables的情况：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// GET /owners/42;q=11/pets/21;q=22</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        @MatrixVariable(name=<span class=\"string\">\"q\"</span>, pathVar=<span class=\"string\">\"ownerId\"</span>)</span> <span class=\"keyword\">int</span> q1,</span></span><br><span class=\"line\"><span class=\"function\">        @<span class=\"title\">MatrixVariable</span><span class=\"params\">(name=<span class=\"string\">\"q\"</span>, pathVar=<span class=\"string\">\"petId\"</span>)</span> <span class=\"keyword\">int</span> q2) </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// q1 == 11</span></span><br><span class=\"line\">    <span class=\"comment\">// q2 == 22</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以设置matrix variable的required属性，<code>required = false</code>表示该参数不是必须存在的，同时可以设置defaultValue赋予默认值。如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// GET /pets/42</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(@MatrixVariable(required=<span class=\"keyword\">false</span>, defaultValue=<span class=\"string\">\"1\"</span>)</span> <span class=\"keyword\">int</span> q) </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// q == 1</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以将所有的matrix variables放置于一个Map中：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// GET /owners/42;q=11;r=12/pets/21;q=22;s=23</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(<span class=\"string\">\"/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        @MatrixVariable MultiValueMap&lt;String, String&gt; matrixVars,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        @MatrixVariable(pathVar=<span class=\"string\">\"petId\"</span><span class=\"string\">\") MultiValueMap&lt;String, String&gt; petMatrixVars) &#123;</span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"><span class=\"string\"></span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"><span class=\"string\">    // matrixVars: [\"</span>q<span class=\"string\">\" : [11,22], \"</span>r<span class=\"string\">\" : 12, \"</span>s<span class=\"string\">\" : 23]</span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"><span class=\"string\">    // petMatrixVars: [\"</span>q<span class=\"string\">\" : 22, \"</span>s<span class=\"string\">\" : 23]</span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\"><span class=\"string\">&#125;</span></span></span></span><br></pre></td></tr></table></figure>\n<p>最后注意：matrix variables默认是不启用的，因此我们需要在xml文件中进行配置:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">beans</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://www.springframework.org/schema/beans\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:mvc</span>=<span class=\"string\">\"http://www.springframework.org/schema/mvc\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">    <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/beans</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/mvc</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">        http://www.springframework.org/schema/mvc/spring-mvc.xsd\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">mvc:annotation-driven</span> <span class=\"attr\">enable-matrix-variables</span>=<span class=\"string\">\"true\"</span>/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"2-4-Consumable-media-types\"><a href=\"#2-4-Consumable-media-types\" class=\"headerlink\" title=\"2.4 Consumable media types\"></a>2.4 Consumable media types</h4><p>利用<code>Content-Type</code>对请求匹配范围进行限制，从而缩小请求的映射范围。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@PostMapping</span>(path = <span class=\"string\">\"/pets\"</span>, consumes = <span class=\"string\">\"application/json\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">addPet</span><span class=\"params\">(@RequestBody Pet pet)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>consumes 属性支持否定表达，<code>!text/plain</code>表示除了 “text/plain” 的所有content type。</p>\n<p>consumes可以声明在class层级，与其他request mapping attributes不同的是，当声明在class层级时，method层级的consumes属性会覆盖而不是扩展class层级的声明。</p>\n<h4 id=\"2-5-Producible-media-types\"><a href=\"#2-5-Producible-media-types\" class=\"headerlink\" title=\"2.5 Producible media types\"></a>2.5 Producible media types</h4><p>利用<code>Accept</code>对请求匹配范围进行限制，从而缩小请求的映射范围。类似2.4:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@GetMapping</span>(path = <span class=\"string\">\"/pets/&#123;petId&#125;\"</span>, produces = <span class=\"string\">\"application/json;charset=UTF-8\"</span>)</span><br><span class=\"line\"><span class=\"meta\">@ResponseBody</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Pet <span class=\"title\">getPet</span><span class=\"params\">(@PathVariable String petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-6-params-method-headers\"><a href=\"#2-6-params-method-headers\" class=\"headerlink\" title=\"2.6 params, method, headers\"></a>2.6 params, method, headers</h4><ul>\n<li>params 属性用于指定请求参数</li>\n<li>method 属性用于限制能够访问的方法类型 //和组合注解@GetMapping等类似</li>\n<li>headers 属性用于指定请求头信息</li>\n</ul>\n<p>三者都可以缩小请求的映射范围，支持否定表达。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@GetMapping</span>(path = <span class=\"string\">\"/pets/&#123;petId&#125;\"</span>, params = <span class=\"string\">\"myParam=myValue\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet</span><span class=\"params\">(@PathVariable String petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">@GetMapping</span>(path = <span class=\"string\">\"/pets\"</span>, headers = <span class=\"string\">\"myHeader=myValue\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet1</span><span class=\"params\">(@PathVariable String petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//和findPet1等价</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(path = <span class=\"string\">\"/pets\"</span>, headers = <span class=\"string\">\"myHeader=myValue\"</span>, method = RequestMethod. GET)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">findPet2</span><span class=\"params\">(@PathVariable String petId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-Handler-Methods\"><a href=\"#3-Handler-Methods\" class=\"headerlink\" title=\"3 Handler Methods\"></a>3 Handler Methods</h3><h4 id=\"3-1-Method-Arguments\"><a href=\"#3-1-Method-Arguments\" class=\"headerlink\" title=\"3.1 Method Arguments\"></a>3.1 Method Arguments</h4><blockquote>\n<p>引用自官方文档</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Controller method argument</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>WebRequest</code>, <code>NativeWebRequest</code></td>\n<td>Generic access to request parameters, request &amp; session attributes, without direct use of the Servlet API.</td>\n</tr>\n<tr>\n<td><code>javax.servlet.ServletRequest</code>, <code>javax.servlet.ServletResponse</code></td>\n<td>Choose any specific request or response type — e.g. <code>ServletRequest</code>, <code>HttpServletRequest</code>, or Spring’s <code>MultipartRequest</code>, <code>MultipartHttpServletRequest</code>.</td>\n</tr>\n<tr>\n<td><code>javax.servlet.http.HttpSession</code></td>\n<td>Enforces the presence of a session. As a consequence, such an argument is never <code>null</code>.<strong>Note:</strong> Session access is not thread-safe. Consider setting the<code>RequestMappingHandlerAdapter</code>‘s “synchronizeOnSession” flag to “true” if multiple requests are allowed to access a session concurrently.</td>\n</tr>\n<tr>\n<td><code>javax.servlet.http.PushBuilder</code></td>\n<td>Servlet 4.0 push builder API for programmatic HTTP/2 resource pushes. Note that per Servlet spec, the injected <code>PushBuilder</code> instance can be null if the client does not support that HTTP/2 feature.</td>\n</tr>\n<tr>\n<td><code>java.security.Principal</code></td>\n<td>Currently authenticated user; possibly a specific <code>Principal</code> implementation class if known.</td>\n</tr>\n<tr>\n<td><code>HttpMethod</code></td>\n<td>The HTTP method of the request.</td>\n</tr>\n<tr>\n<td><code>java.util.Locale</code></td>\n<td>The current request locale, determined by the most specific <code>LocaleResolver</code> available, in effect, the configured <code>LocaleResolver</code>/<code>LocaleContextResolver</code>.</td>\n</tr>\n<tr>\n<td>Java 6+: <code>java.util.TimeZone</code>Java 8+: <code>java.time.ZoneId</code></td>\n<td>The time zone associated with the current request, as determined by a <code>LocaleContextResolver</code>.</td>\n</tr>\n<tr>\n<td><code>java.io.InputStream</code>, <code>java.io.Reader</code></td>\n<td>For access to the raw request body as exposed by the Servlet API.</td>\n</tr>\n<tr>\n<td><code>java.io.OutputStream</code>, <code>java.io.Writer</code></td>\n<td>For access to the raw response body as exposed by the Servlet API.</td>\n</tr>\n<tr>\n<td><code>@PathVariable</code></td>\n<td>For access to URI template variables. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestmapping-uri-templates\" target=\"_blank\" rel=\"noopener\">URI patterns</a>.</td>\n</tr>\n<tr>\n<td><code>@MatrixVariable</code></td>\n<td>For access to name-value pairs in URI path segments. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-matrix-variables\" target=\"_blank\" rel=\"noopener\">Matrix variables</a>.</td>\n</tr>\n<tr>\n<td><code>@RequestParam</code></td>\n<td>For access to Servlet request parameters. Parameter values are converted to the declared method argument type. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestparam\" target=\"_blank\" rel=\"noopener\">@RequestParam</a>.</td>\n</tr>\n<tr>\n<td><code>@RequestHeader</code></td>\n<td>For access to request headers. Header values are converted to the declared method argument type. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestheader\" target=\"_blank\" rel=\"noopener\">@RequestHeader</a>.</td>\n</tr>\n<tr>\n<td><code>@RequestBody</code></td>\n<td>For access to the HTTP request body. Body content is converted to the declared method argument type using <code>HttpMessageConverter</code>s. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-requestbody\" target=\"_blank\" rel=\"noopener\">@RequestBody</a>.</td>\n</tr>\n<tr>\n<td><code>HttpEntity&lt;B&gt;</code></td>\n<td>For access to request headers and body. The body is converted with <code>HttpMessageConverter</code>s. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-httpentity\" target=\"_blank\" rel=\"noopener\">HttpEntity</a>.</td>\n</tr>\n<tr>\n<td><code>@RequestPart</code></td>\n<td>For access to a part in a “multipart/form-data” request. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-multipart-forms-non-browsers\" target=\"_blank\" rel=\"noopener\">@RequestPart</a> and <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-multipart\" target=\"_blank\" rel=\"noopener\">Multipart requests</a>.</td>\n</tr>\n<tr>\n<td><code>java.util.Map</code>, <code>org.springframework.ui.Model</code>, <code>org.springframework.ui.ModelMap</code></td>\n<td>For access and updates of the implicit model that is exposed to the web view.</td>\n</tr>\n<tr>\n<td><code>RedirectAttributes</code></td>\n<td>Specify attributes to use in case of a redirect — i.e. to be appended to the query string, and/or flash attributes to be stored temporarily until the request after redirect. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-redirecting-passing-data\" target=\"_blank\" rel=\"noopener\">Redirect attributes</a> and <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-flash-attributes\" target=\"_blank\" rel=\"noopener\">Flash attributes</a>.</td>\n</tr>\n<tr>\n<td>Command or form object (with optional <code>@ModelAttribute</code>)</td>\n<td>Command object whose properties to bind to request parameters — via setters or directly to fields, with customizable type conversion, depending on <code>@InitBinder</code> methods and/or the HandlerAdapter configuration (see the <code>webBindingInitializer</code> property on<code>RequestMappingHandlerAdapter</code>).Command objects along with their validation results are exposed as model attributes, by default using the command class name - e.g. model attribute “orderAddress” for a command object of type “some.package.OrderAddress”. <code>@ModelAttribute</code> can be used to customize the model attribute name.</td>\n</tr>\n<tr>\n<td><code>Errors</code>, <code>BindingResult</code></td>\n<td>Validation results for the command/form object data binding; this argument must be declared immediately after the command/form object in the controller method signature.</td>\n</tr>\n<tr>\n<td><code>SessionStatus</code></td>\n<td>For marking form processing complete which triggers cleanup of session attributes declared through a class-level <code>@SessionAttributes</code>annotation.</td>\n</tr>\n<tr>\n<td><code>UriComponentsBuilder</code></td>\n<td>For preparing a URL relative to the current request’s host, port, scheme, context path, and the literal part of the servlet mapping also taking into account <code>Forwarded</code> and <code>X-Forwarded-*</code> headers.</td>\n</tr>\n<tr>\n<td><code>@SessionAttribute</code></td>\n<td>For access to any session attribute; in contrast to model attributes stored in the session as a result of a class-level <code>@SessionAttributes</code>declaration.</td>\n</tr>\n<tr>\n<td><code>@RequestAttribute</code></td>\n<td>For access to request attributes.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"3-2-Return-Values\"><a href=\"#3-2-Return-Values\" class=\"headerlink\" title=\"3.2 Return Values\"></a>3.2 Return Values</h4><blockquote>\n<p>引用自官方文档</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Controller method return value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>@ResponseBody</code></td>\n<td>The return value is converted through <code>HttpMessageConverter</code>s and written to the response. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-responsebody\" target=\"_blank\" rel=\"noopener\">@ResponseBody</a>.</td>\n</tr>\n<tr>\n<td><code>HttpEntity&lt;B&gt;</code>, <code>ResponseEntity&lt;B&gt;</code></td>\n<td>The return value specifies the full response including HTTP headers and body be converted through <code>HttpMessageConverter</code>s and written to the response. See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-httpentity\" target=\"_blank\" rel=\"noopener\">HttpEntity</a>.</td>\n</tr>\n<tr>\n<td><code>HttpHeaders</code></td>\n<td>For returning a response with headers and no body.</td>\n</tr>\n<tr>\n<td><code>String</code></td>\n<td>A view name to be resolved with <code>ViewResolver</code>‘s and used together with the implicit model — determined through command objects and <code>@ModelAttribute</code>methods. The handler method may also programmatically enrich the model by declaring a <code>Model</code>argument (see above).</td>\n</tr>\n<tr>\n<td><code>View</code></td>\n<td>A <code>View</code> instance to use for rendering together with the implicit model — determined through command objects and <code>@ModelAttribute</code> methods. The handler method may also programmatically enrich the model by declaring a <code>Model</code> argument (see above).</td>\n</tr>\n<tr>\n<td><code>java.util.Map</code>, <code>org.springframework.ui.Model</code></td>\n<td>Attributes to be added to the implicit model with the view name implicitly determined through a <code>RequestToViewNameTranslator</code>.</td>\n</tr>\n<tr>\n<td><code>ModelAndView</code> object</td>\n<td>The view and model attributes to use, and optionally a response status.</td>\n</tr>\n<tr>\n<td><code>void</code></td>\n<td>A method with a <code>void</code> return type (or <code>null</code> return value) is considered to have fully handled the response if it also has a <code>ServletResponse</code>, or an <code>OutputStream</code> argument, or an <code>@ResponseStatus</code> annotation. The same is true also if the controller has made a positive ETag or lastModified timestamp check (see <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-caching-etag-lastmodified\" target=\"_blank\" rel=\"noopener\">@Controller caching</a> for details).If none of the above is true, a <code>void</code>return type may also indicate “no response body” for REST controllers, or default view name selection for HTML controllers.</td>\n</tr>\n<tr>\n<td><code>Callable&lt;V&gt;</code></td>\n<td>Produce any of the above return values asynchronously in a Spring MVC managed thread.</td>\n</tr>\n<tr>\n<td><code>DeferredResult&lt;V&gt;</code></td>\n<td>Produce any of the above return values asynchronously from any thread — e.g. possibly as a result of some event or callback.</td>\n</tr>\n<tr>\n<td>ListenableFuture<v>, java.util.concurrent.CompletionStage<v>, java.util.concurrent.CompletableFuture<v></v></v></v></td>\n<td>Alternative to <code>DeferredResult</code> as a convenience for example when an underlying service returns one of those.</td>\n</tr>\n<tr>\n<td><code>ResponseBodyEmitter</code>, <code>SseEmitter</code></td>\n<td>Emit a stream of objects asynchronously to be written to the response with<code>HttpMessageConverter</code>‘s; also supported as the body of a <code>ResponseEntity</code>.</td>\n</tr>\n<tr>\n<td><code>StreamingResponseBody</code></td>\n<td>Write to the response <code>OutputStream</code> asynchronously; also supported as the body of a<code>ResponseEntity</code>.</td>\n</tr>\n<tr>\n<td>Reactive types — Reactor, RxJava, or others via <code>ReactiveAdapterRegistry</code></td>\n<td>Alternative to <code>`DeferredResult</code>with multi-value streams (e.g. <code>Flux</code>, <code>Observable</code>) collected to a <code>List</code>.For streaming scenarios — .e.g. <code>text/event-stream</code>, <code>application/json+stream</code>,<code>SseEmitter</code> and <code>ResponseBodyEmitter</code> are used instead, where <code>ServletOutputStream</code> blocking I/O is performed on a Spring MVC managed thread and back pressure applied against the completion of each write.See <a href=\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#mvc-ann-async-reactive-types\" target=\"_blank\" rel=\"noopener\">Reactive return values</a>.</td>\n</tr>\n<tr>\n<td>Any other return type</td>\n<td>A single model attribute to be added to the implicit model with the view name implicitly determined through a <code>RequestToViewNameTranslator</code>; the attribute name may be specified through a method-level <code>@ModelAttribute</code> or otherwise a name is selected based on the class name of the return type.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"3-3-RequestParam\"><a href=\"#3-3-RequestParam\" class=\"headerlink\" title=\"3.3 @RequestParam\"></a>3.3 @RequestParam</h4><p>使用 @RequestParam 绑定 HttpServletRequest 请求参数到控制器方法参数：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Controller</span></span><br><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/pets\"</span>)</span><br><span class=\"line\"><span class=\"meta\">@SessionAttributes</span>(<span class=\"string\">\"pet\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EditPetForm</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@GetMapping</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">setupForm</span><span class=\"params\">(@RequestParam(<span class=\"string\">\"petId\"</span>)</span> <span class=\"keyword\">int</span> petId, ModelMap model) </span>&#123;</span><br><span class=\"line\">        Pet pet = <span class=\"keyword\">this</span>.clinic.loadPet(petId);</span><br><span class=\"line\">        model.addAttribute(<span class=\"string\">\"pet\"</span>, pet);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"petForm\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>绑定的参数默认必须存在，可以通过required属性修改，如<code>@RequestParam(name=&quot;id&quot;, required=false)</code>。</p>\n<p>如果控制器方法参数类型不是string，将会执行自动类型转换。</p>\n<h4 id=\"3-4-RequestHeader\"><a href=\"#3-4-RequestHeader\" class=\"headerlink\" title=\"3.4 @RequestHeader\"></a>3.4 @RequestHeader</h4><p>使用@RequestHeader绑定绑定 HttpServletRequest 头信息到控制器方法参数。</p>\n<p>一个request header例子:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host                    localhost:8080</span><br><span class=\"line\">Accept                  text/html,application/xhtml+xml,application/xml;q=0.9</span><br><span class=\"line\">Accept-Language         fr,en-gb;q=0.7,en;q=0.3</span><br><span class=\"line\">Accept-Encoding         gzip,deflate</span><br><span class=\"line\">Accept-Charset          ISO-8859-1,utf-8;q=0.7,*;q=0.7</span><br><span class=\"line\">Keep-Alive              300</span><br></pre></td></tr></table></figure>\n<p>下面的例子演示了如何获取 <code>Accept-Encoding</code>和 <code>Keep-Alive</code> 的值：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/displayHeaderInfo.do\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">displayHeaderInfo</span><span class=\"params\">(@RequestHeader(<span class=\"string\">\"Accept-Encoding\"</span>)</span> String encoding,</span></span><br><span class=\"line\"><span class=\"function\">        @<span class=\"title\">RequestHeader</span><span class=\"params\">(<span class=\"string\">\"Keep-Alive\"</span>)</span> <span class=\"keyword\">long</span> keepAlive) </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如果控制器方法参数类型不是string，将会执行自动类型转换。</p>\n<h4 id=\"3-5-CookieValue\"><a href=\"#3-5-CookieValue\" class=\"headerlink\" title=\"3.5 @CookieValue\"></a>3.5 @CookieValue</h4><p>使用@CookieValue绑定绑定 HttpServletRequest 的cookie信息到控制器方法参数。</p>\n<p>假设http request中有如下cookie信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JSESSIONID=415A4AC178C59DACE0B2C9CA727CDD84</span><br></pre></td></tr></table></figure>\n<p>下面的例子演示了如何获取JESSIONID的值：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@RequestMapping</span>(<span class=\"string\">\"/displayHeaderInfo.do\"</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">displayHeaderInfo</span><span class=\"params\">(@CookieValue(<span class=\"string\">\"JSESSIONID\"</span>)</span> String cookie) </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-6-ModelAttribute\"><a href=\"#3-6-ModelAttribute\" class=\"headerlink\" title=\"3.6 @ModelAttribute\"></a>3.6 @ModelAttribute</h4><p>//TODO</p>"},{"title":"hexo 双线部署及seo优化","date":"2017-10-27T02:16:39.000Z","_content":"\n### 前言\n\n断断续续大概半个月，终于把个人博客搭建好，整个过程虽然简单，但是也有很多”坑“。在查询资料的过程中，阅读的博文质量参差不齐，因此想细致的写出我搭建的过程，供大家参考。文章重点在于双线部署及seo，最开始的部署和搭建将简要略过。\n\n<!-- more -->\n\n### 安装\n\n官方文档永远是最清楚正确的\n\nhttps://hexo.io/zh-cn/docs/index.html\n\n### 主题\n\n选择hexo的很大原因是因为其主题和插件很多，而且配置方便，这里选择的主题是大名鼎鼎的**next**，强烈推荐使用。next的插件配置非常便捷，而且设计符合大众审美。\n\n配置过程详见官方文档\n\nhttp://theme-next.iissnan.com/\n\n### 双线部署\n\n由于大部分人使用hexo都是将其部署在github上，省去了服务器的钱。由于“国情”原因，github的访问速度较慢，所以才有了双线部署得必要性。将国内访问流量导向coding（国内类似github的网站），国外流量导向github，从而提高访问质量。\n\n#### 域名申请\n\n在部署之前，我们必须申请一个域名，便宜的域名1元/年，我的域名是在阿里云买的。进入阿里云官网，点击图片中的域名注册，根据自己的需求选择想要的域名。我的域名为yinjianwen.site，在部署得时候我将博客部署在该域名的二级域名blog下，因此以后访问地址为**blog.yinjianwen.site**。当然你也可以直接部署在主站。\n\n![](http://oygov02sc.bkt.clouddn.com/1.png)\n\n#### coding\n\n进入官网[coding](https://coding.net/)，注册账号并登录。配置好SSH公钥，这里默认你会使用git，如果不会，可以查询相关资料。\n\n新建一个项目，名字格式为yourname.coding.me，其中yourname即为你的用户名。\n\n![](http://oygov02sc.bkt.clouddn.com/2.png)\n\n选择该项目，进入代码->pages服务，绑定你之前注册的域名。\n\n![](http://oygov02sc.bkt.clouddn.com/3.png)\n\n#### github\n\n与上述过程类似，登陆之后，点击页面右上角的加号，选择New repository，在Repository name下填写yourname.github.io，其中yourname即为你的用户名。\n\n![](http://oygov02sc.bkt.clouddn.com/4.png)\n\n#### 域名解析配置\n\n进入阿里云官网，在控制台选择域名服务，进入解析页面。然后即可进行配置。\n\n![](http://oygov02sc.bkt.clouddn.com/5.png)\n\n配置的意思是，blog子域名下的世界流量（国外）访问yinxiaojian.github.io，而国内流量访问yinxiaojian.coding.me。\n\n#### hexo配置\n\n最后我们需要在本地的hexo项目中进行相关配置，打开主项目下的_config.yml文件，在其中任意位置添加如下代码\n\n```c++\ndeploy:\n  type: git\n  repo: \n    github: https://github.com/yinxiaojian/yinxiaojian.github.io.git,master\n    coding: https://coding.net/yinxiaojian/yinxiaojian.coding.me.git,master\n```\n\n将其中的yinxiaojian修改为你的coding和github用户名，这行代码的意思是在你通过本地```hexo deploy```指令时，会将本地hexo同步到这两个网站。\n\n之后需要在项目->source中添加文件CNAME，注意文件名大写且没有后缀。文件中写入你申请的域名，比如我的文件中写入的是\n\n```blog.yinjianwen.site```\n\n实际上由于github不想coding一样可以自己绑定域名，因此我们需要自己上传CNAME文件。\n\n#### 部署\n\n在上述操作完成后，输入以上命令，将本地项目推送到github和coding，双线部署完成。\n\n```C++\nhexo clean\nhexo generate\nhexo deploy\n```\n\n","source":"_posts/hexo-双线部署及seo优化.md","raw":"---\ntitle: hexo 双线部署及seo优化\ndate: 2017-10-27 10:16:39\ntags: hexo\ncategories: 技术分享\n---\n\n### 前言\n\n断断续续大概半个月，终于把个人博客搭建好，整个过程虽然简单，但是也有很多”坑“。在查询资料的过程中，阅读的博文质量参差不齐，因此想细致的写出我搭建的过程，供大家参考。文章重点在于双线部署及seo，最开始的部署和搭建将简要略过。\n\n<!-- more -->\n\n### 安装\n\n官方文档永远是最清楚正确的\n\nhttps://hexo.io/zh-cn/docs/index.html\n\n### 主题\n\n选择hexo的很大原因是因为其主题和插件很多，而且配置方便，这里选择的主题是大名鼎鼎的**next**，强烈推荐使用。next的插件配置非常便捷，而且设计符合大众审美。\n\n配置过程详见官方文档\n\nhttp://theme-next.iissnan.com/\n\n### 双线部署\n\n由于大部分人使用hexo都是将其部署在github上，省去了服务器的钱。由于“国情”原因，github的访问速度较慢，所以才有了双线部署得必要性。将国内访问流量导向coding（国内类似github的网站），国外流量导向github，从而提高访问质量。\n\n#### 域名申请\n\n在部署之前，我们必须申请一个域名，便宜的域名1元/年，我的域名是在阿里云买的。进入阿里云官网，点击图片中的域名注册，根据自己的需求选择想要的域名。我的域名为yinjianwen.site，在部署得时候我将博客部署在该域名的二级域名blog下，因此以后访问地址为**blog.yinjianwen.site**。当然你也可以直接部署在主站。\n\n![](http://oygov02sc.bkt.clouddn.com/1.png)\n\n#### coding\n\n进入官网[coding](https://coding.net/)，注册账号并登录。配置好SSH公钥，这里默认你会使用git，如果不会，可以查询相关资料。\n\n新建一个项目，名字格式为yourname.coding.me，其中yourname即为你的用户名。\n\n![](http://oygov02sc.bkt.clouddn.com/2.png)\n\n选择该项目，进入代码->pages服务，绑定你之前注册的域名。\n\n![](http://oygov02sc.bkt.clouddn.com/3.png)\n\n#### github\n\n与上述过程类似，登陆之后，点击页面右上角的加号，选择New repository，在Repository name下填写yourname.github.io，其中yourname即为你的用户名。\n\n![](http://oygov02sc.bkt.clouddn.com/4.png)\n\n#### 域名解析配置\n\n进入阿里云官网，在控制台选择域名服务，进入解析页面。然后即可进行配置。\n\n![](http://oygov02sc.bkt.clouddn.com/5.png)\n\n配置的意思是，blog子域名下的世界流量（国外）访问yinxiaojian.github.io，而国内流量访问yinxiaojian.coding.me。\n\n#### hexo配置\n\n最后我们需要在本地的hexo项目中进行相关配置，打开主项目下的_config.yml文件，在其中任意位置添加如下代码\n\n```c++\ndeploy:\n  type: git\n  repo: \n    github: https://github.com/yinxiaojian/yinxiaojian.github.io.git,master\n    coding: https://coding.net/yinxiaojian/yinxiaojian.coding.me.git,master\n```\n\n将其中的yinxiaojian修改为你的coding和github用户名，这行代码的意思是在你通过本地```hexo deploy```指令时，会将本地hexo同步到这两个网站。\n\n之后需要在项目->source中添加文件CNAME，注意文件名大写且没有后缀。文件中写入你申请的域名，比如我的文件中写入的是\n\n```blog.yinjianwen.site```\n\n实际上由于github不想coding一样可以自己绑定域名，因此我们需要自己上传CNAME文件。\n\n#### 部署\n\n在上述操作完成后，输入以上命令，将本地项目推送到github和coding，双线部署完成。\n\n```C++\nhexo clean\nhexo generate\nhexo deploy\n```\n\n","slug":"hexo-双线部署及seo优化","published":1,"updated":"2018-01-03T16:03:11.045Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owc2000sfb9ln10bxsim","content":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>断断续续大概半个月，终于把个人博客搭建好，整个过程虽然简单，但是也有很多”坑“。在查询资料的过程中，阅读的博文质量参差不齐，因此想细致的写出我搭建的过程，供大家参考。文章重点在于双线部署及seo，最开始的部署和搭建将简要略过。</p>\n<a id=\"more\"></a>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>官方文档永远是最清楚正确的</p>\n<p><a href=\"https://hexo.io/zh-cn/docs/index.html\" target=\"_blank\" rel=\"noopener\">https://hexo.io/zh-cn/docs/index.html</a></p>\n<h3 id=\"主题\"><a href=\"#主题\" class=\"headerlink\" title=\"主题\"></a>主题</h3><p>选择hexo的很大原因是因为其主题和插件很多，而且配置方便，这里选择的主题是大名鼎鼎的<strong>next</strong>，强烈推荐使用。next的插件配置非常便捷，而且设计符合大众审美。</p>\n<p>配置过程详见官方文档</p>\n<p><a href=\"http://theme-next.iissnan.com/\" target=\"_blank\" rel=\"noopener\">http://theme-next.iissnan.com/</a></p>\n<h3 id=\"双线部署\"><a href=\"#双线部署\" class=\"headerlink\" title=\"双线部署\"></a>双线部署</h3><p>由于大部分人使用hexo都是将其部署在github上，省去了服务器的钱。由于“国情”原因，github的访问速度较慢，所以才有了双线部署得必要性。将国内访问流量导向coding（国内类似github的网站），国外流量导向github，从而提高访问质量。</p>\n<h4 id=\"域名申请\"><a href=\"#域名申请\" class=\"headerlink\" title=\"域名申请\"></a>域名申请</h4><p>在部署之前，我们必须申请一个域名，便宜的域名1元/年，我的域名是在阿里云买的。进入阿里云官网，点击图片中的域名注册，根据自己的需求选择想要的域名。我的域名为yinjianwen.site，在部署得时候我将博客部署在该域名的二级域名blog下，因此以后访问地址为<strong>blog.yinjianwen.site</strong>。当然你也可以直接部署在主站。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/1.png\" alt=\"\"></p>\n<h4 id=\"coding\"><a href=\"#coding\" class=\"headerlink\" title=\"coding\"></a>coding</h4><p>进入官网<a href=\"https://coding.net/\" target=\"_blank\" rel=\"noopener\">coding</a>，注册账号并登录。配置好SSH公钥，这里默认你会使用git，如果不会，可以查询相关资料。</p>\n<p>新建一个项目，名字格式为yourname.coding.me，其中yourname即为你的用户名。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/2.png\" alt=\"\"></p>\n<p>选择该项目，进入代码-&gt;pages服务，绑定你之前注册的域名。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/3.png\" alt=\"\"></p>\n<h4 id=\"github\"><a href=\"#github\" class=\"headerlink\" title=\"github\"></a>github</h4><p>与上述过程类似，登陆之后，点击页面右上角的加号，选择New repository，在Repository name下填写yourname.github.io，其中yourname即为你的用户名。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/4.png\" alt=\"\"></p>\n<h4 id=\"域名解析配置\"><a href=\"#域名解析配置\" class=\"headerlink\" title=\"域名解析配置\"></a>域名解析配置</h4><p>进入阿里云官网，在控制台选择域名服务，进入解析页面。然后即可进行配置。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/5.png\" alt=\"\"></p>\n<p>配置的意思是，blog子域名下的世界流量（国外）访问yinxiaojian.github.io，而国内流量访问yinxiaojian.coding.me。</p>\n<h4 id=\"hexo配置\"><a href=\"#hexo配置\" class=\"headerlink\" title=\"hexo配置\"></a>hexo配置</h4><p>最后我们需要在本地的hexo项目中进行相关配置，打开主项目下的_config.yml文件，在其中任意位置添加如下代码</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repo: </span><br><span class=\"line\">    github: https:<span class=\"comment\">//github.com/yinxiaojian/yinxiaojian.github.io.git,master</span></span><br><span class=\"line\">    coding: https:<span class=\"comment\">//coding.net/yinxiaojian/yinxiaojian.coding.me.git,master</span></span><br></pre></td></tr></table></figure>\n<p>将其中的yinxiaojian修改为你的coding和github用户名，这行代码的意思是在你通过本地<figure class=\"highlight plain\"><figcaption><span>deploy```指令时，会将本地hexo同步到这两个网站。</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">之后需要在项目-&gt;source中添加文件CNAME，注意文件名大写且没有后缀。文件中写入你申请的域名，比如我的文件中写入的是</span><br><span class=\"line\"></span><br><span class=\"line\">```blog.yinjianwen.site</span><br></pre></td></tr></table></figure></p>\n<p>实际上由于github不想coding一样可以自己绑定域名，因此我们需要自己上传CNAME文件。</p>\n<h4 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h4><p>在上述操作完成后，输入以上命令，将本地项目推送到github和coding，双线部署完成。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean</span><br><span class=\"line\">hexo generate</span><br><span class=\"line\">hexo deploy</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>断断续续大概半个月，终于把个人博客搭建好，整个过程虽然简单，但是也有很多”坑“。在查询资料的过程中，阅读的博文质量参差不齐，因此想细致的写出我搭建的过程，供大家参考。文章重点在于双线部署及seo，最开始的部署和搭建将简要略过。</p>","more":"<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>官方文档永远是最清楚正确的</p>\n<p><a href=\"https://hexo.io/zh-cn/docs/index.html\" target=\"_blank\" rel=\"noopener\">https://hexo.io/zh-cn/docs/index.html</a></p>\n<h3 id=\"主题\"><a href=\"#主题\" class=\"headerlink\" title=\"主题\"></a>主题</h3><p>选择hexo的很大原因是因为其主题和插件很多，而且配置方便，这里选择的主题是大名鼎鼎的<strong>next</strong>，强烈推荐使用。next的插件配置非常便捷，而且设计符合大众审美。</p>\n<p>配置过程详见官方文档</p>\n<p><a href=\"http://theme-next.iissnan.com/\" target=\"_blank\" rel=\"noopener\">http://theme-next.iissnan.com/</a></p>\n<h3 id=\"双线部署\"><a href=\"#双线部署\" class=\"headerlink\" title=\"双线部署\"></a>双线部署</h3><p>由于大部分人使用hexo都是将其部署在github上，省去了服务器的钱。由于“国情”原因，github的访问速度较慢，所以才有了双线部署得必要性。将国内访问流量导向coding（国内类似github的网站），国外流量导向github，从而提高访问质量。</p>\n<h4 id=\"域名申请\"><a href=\"#域名申请\" class=\"headerlink\" title=\"域名申请\"></a>域名申请</h4><p>在部署之前，我们必须申请一个域名，便宜的域名1元/年，我的域名是在阿里云买的。进入阿里云官网，点击图片中的域名注册，根据自己的需求选择想要的域名。我的域名为yinjianwen.site，在部署得时候我将博客部署在该域名的二级域名blog下，因此以后访问地址为<strong>blog.yinjianwen.site</strong>。当然你也可以直接部署在主站。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/1.png\" alt=\"\"></p>\n<h4 id=\"coding\"><a href=\"#coding\" class=\"headerlink\" title=\"coding\"></a>coding</h4><p>进入官网<a href=\"https://coding.net/\" target=\"_blank\" rel=\"noopener\">coding</a>，注册账号并登录。配置好SSH公钥，这里默认你会使用git，如果不会，可以查询相关资料。</p>\n<p>新建一个项目，名字格式为yourname.coding.me，其中yourname即为你的用户名。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/2.png\" alt=\"\"></p>\n<p>选择该项目，进入代码-&gt;pages服务，绑定你之前注册的域名。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/3.png\" alt=\"\"></p>\n<h4 id=\"github\"><a href=\"#github\" class=\"headerlink\" title=\"github\"></a>github</h4><p>与上述过程类似，登陆之后，点击页面右上角的加号，选择New repository，在Repository name下填写yourname.github.io，其中yourname即为你的用户名。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/4.png\" alt=\"\"></p>\n<h4 id=\"域名解析配置\"><a href=\"#域名解析配置\" class=\"headerlink\" title=\"域名解析配置\"></a>域名解析配置</h4><p>进入阿里云官网，在控制台选择域名服务，进入解析页面。然后即可进行配置。</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/5.png\" alt=\"\"></p>\n<p>配置的意思是，blog子域名下的世界流量（国外）访问yinxiaojian.github.io，而国内流量访问yinxiaojian.coding.me。</p>\n<h4 id=\"hexo配置\"><a href=\"#hexo配置\" class=\"headerlink\" title=\"hexo配置\"></a>hexo配置</h4><p>最后我们需要在本地的hexo项目中进行相关配置，打开主项目下的_config.yml文件，在其中任意位置添加如下代码</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repo: </span><br><span class=\"line\">    github: https:<span class=\"comment\">//github.com/yinxiaojian/yinxiaojian.github.io.git,master</span></span><br><span class=\"line\">    coding: https:<span class=\"comment\">//coding.net/yinxiaojian/yinxiaojian.coding.me.git,master</span></span><br></pre></td></tr></table></figure>\n<p>将其中的yinxiaojian修改为你的coding和github用户名，这行代码的意思是在你通过本地<figure class=\"highlight plain\"><figcaption><span>deploy```指令时，会将本地hexo同步到这两个网站。</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">之后需要在项目-&gt;source中添加文件CNAME，注意文件名大写且没有后缀。文件中写入你申请的域名，比如我的文件中写入的是</span><br><span class=\"line\"></span><br><span class=\"line\">```blog.yinjianwen.site</span><br></pre></td></tr></table></figure></p>\n<p>实际上由于github不想coding一样可以自己绑定域名，因此我们需要自己上传CNAME文件。</p>\n<h4 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h4><p>在上述操作完成后，输入以上命令，将本地项目推送到github和coding，双线部署完成。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean</span><br><span class=\"line\">hexo generate</span><br><span class=\"line\">hexo deploy</span><br></pre></td></tr></table></figure>"},{"title":"java类与成员访问控制","date":"2017-10-27T07:22:29.000Z","_content":"\njava访问控制是基础中的基础，有public/private/protected/default四个类型，一般分为类的访问控制和成员访问控制两个类型。\n<!-- more -->\n\n### 修饰类\n\n修饰类只能使用public和default，不可以声明为protected或private。用public修饰的类任何情况下都可以访问。用default即不加任何修饰词，权限为包访问权限，在同一个包内的类可以访问。\n\n在修饰类的时候有以下几点需要注意\n\n* 每个编译单元（文件）只能有一个public类，如果有一个以上的public类，编译器会报错\n* 实际上类可以既不是public也可以不失default，这涉及到内部类，此处不介绍。\n\n### 修饰成员\n\n| 权限修饰符     | 同类   | 同包   | 不同包的子类 | 不同包的非子类 |\n| --------- | ---- | ---- | ------ | ------- |\n| public    | Y    | Y    | Y      | Y       |\n| protected | Y    | Y    | Y      | N       |\n| default   | Y    | Y    | N      | N       |\n| private   | Y    | N    | N      | N       |\n\n### 有趣的类比\n\npublic：全世界共享\ndefault：只属于中国这个国家，权限收缩\nprotected：属于中国这个国家，当然不在中国的国人也有权使用\nprivate：只属于单一的中国人\n\n\n\n","source":"_posts/java类与成员访问控制.md","raw":"---\ntitle: java类与成员访问控制\ndate: 2017-10-27 15:22:29\ntags: java基础\ncategories: java\n---\n\njava访问控制是基础中的基础，有public/private/protected/default四个类型，一般分为类的访问控制和成员访问控制两个类型。\n<!-- more -->\n\n### 修饰类\n\n修饰类只能使用public和default，不可以声明为protected或private。用public修饰的类任何情况下都可以访问。用default即不加任何修饰词，权限为包访问权限，在同一个包内的类可以访问。\n\n在修饰类的时候有以下几点需要注意\n\n* 每个编译单元（文件）只能有一个public类，如果有一个以上的public类，编译器会报错\n* 实际上类可以既不是public也可以不失default，这涉及到内部类，此处不介绍。\n\n### 修饰成员\n\n| 权限修饰符     | 同类   | 同包   | 不同包的子类 | 不同包的非子类 |\n| --------- | ---- | ---- | ------ | ------- |\n| public    | Y    | Y    | Y      | Y       |\n| protected | Y    | Y    | Y      | N       |\n| default   | Y    | Y    | N      | N       |\n| private   | Y    | N    | N      | N       |\n\n### 有趣的类比\n\npublic：全世界共享\ndefault：只属于中国这个国家，权限收缩\nprotected：属于中国这个国家，当然不在中国的国人也有权使用\nprivate：只属于单一的中国人\n\n\n\n","slug":"java类与成员访问控制","published":1,"updated":"2018-01-03T16:03:11.046Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owc4000wfb9lk4p71avv","content":"<p>java访问控制是基础中的基础，有public/private/protected/default四个类型，一般分为类的访问控制和成员访问控制两个类型。<br><a id=\"more\"></a></p>\n<h3 id=\"修饰类\"><a href=\"#修饰类\" class=\"headerlink\" title=\"修饰类\"></a>修饰类</h3><p>修饰类只能使用public和default，不可以声明为protected或private。用public修饰的类任何情况下都可以访问。用default即不加任何修饰词，权限为包访问权限，在同一个包内的类可以访问。</p>\n<p>在修饰类的时候有以下几点需要注意</p>\n<ul>\n<li>每个编译单元（文件）只能有一个public类，如果有一个以上的public类，编译器会报错</li>\n<li>实际上类可以既不是public也可以不失default，这涉及到内部类，此处不介绍。</li>\n</ul>\n<h3 id=\"修饰成员\"><a href=\"#修饰成员\" class=\"headerlink\" title=\"修饰成员\"></a>修饰成员</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>权限修饰符</th>\n<th>同类</th>\n<th>同包</th>\n<th>不同包的子类</th>\n<th>不同包的非子类</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>public</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>protected</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n</tr>\n<tr>\n<td>default</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n<td>N</td>\n</tr>\n<tr>\n<td>private</td>\n<td>Y</td>\n<td>N</td>\n<td>N</td>\n<td>N</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"有趣的类比\"><a href=\"#有趣的类比\" class=\"headerlink\" title=\"有趣的类比\"></a>有趣的类比</h3><p>public：全世界共享<br>default：只属于中国这个国家，权限收缩<br>protected：属于中国这个国家，当然不在中国的国人也有权使用<br>private：只属于单一的中国人</p>\n","site":{"data":{}},"excerpt":"<p>java访问控制是基础中的基础，有public/private/protected/default四个类型，一般分为类的访问控制和成员访问控制两个类型。<br>","more":"</p>\n<h3 id=\"修饰类\"><a href=\"#修饰类\" class=\"headerlink\" title=\"修饰类\"></a>修饰类</h3><p>修饰类只能使用public和default，不可以声明为protected或private。用public修饰的类任何情况下都可以访问。用default即不加任何修饰词，权限为包访问权限，在同一个包内的类可以访问。</p>\n<p>在修饰类的时候有以下几点需要注意</p>\n<ul>\n<li>每个编译单元（文件）只能有一个public类，如果有一个以上的public类，编译器会报错</li>\n<li>实际上类可以既不是public也可以不失default，这涉及到内部类，此处不介绍。</li>\n</ul>\n<h3 id=\"修饰成员\"><a href=\"#修饰成员\" class=\"headerlink\" title=\"修饰成员\"></a>修饰成员</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>权限修饰符</th>\n<th>同类</th>\n<th>同包</th>\n<th>不同包的子类</th>\n<th>不同包的非子类</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>public</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>protected</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n</tr>\n<tr>\n<td>default</td>\n<td>Y</td>\n<td>Y</td>\n<td>N</td>\n<td>N</td>\n</tr>\n<tr>\n<td>private</td>\n<td>Y</td>\n<td>N</td>\n<td>N</td>\n<td>N</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"有趣的类比\"><a href=\"#有趣的类比\" class=\"headerlink\" title=\"有趣的类比\"></a>有趣的类比</h3><p>public：全世界共享<br>default：只属于中国这个国家，权限收缩<br>protected：属于中国这个国家，当然不在中国的国人也有权使用<br>private：只属于单一的中国人</p>"},{"title":"robust optimization in ML","date":"2018-04-25T05:25:41.000Z","_content":"In real large application where the training data may have noise and outliers, general ML algorithm may be very sensitive to noise and outliers. algorithm with robust can overcome this situation. \n\n<!--more-->\n\n### 1. Robust Factorization Machines for User Response Prediction\n\n####contributions\n\nthe work aims at characterizing the environment-induced un- certainty in the user signals and reformulating the FM and FFM objective functions to be immune against data fluctuations. \nmain contributions:\n\n* employ robust optimization principles to model the noise arising in online advertising signals as boundes box-type interval uncertainty sets.\n* propose two novel algorithms: robust factorization machine (RFM) and robust field-aware factorization machine(RFFM).\n* using parallel stochastic gradient decent.\n* evaluate on three publicly available response prediction datasets from criteo and avazu. for classification robust version takes a slight performance hit in the standard setting but significantly outperforms the non-robust counterparts when subjected to noise.\n* provide guidelines for selection of uncertainly sets.\n* a general model\n\n\n#### model\n\nwe associate uncertainty vector $\\mu\\in \\mathbb{R}^d\\space s.t. \\space |\\mu_j|\\leq\\eta_j,\\forall j\\in \\{1,…,d\\}$ for characterizing noise in linear interactions and matrix $\\sum\\in\\mathbb{R}^{d\\times d} \\space s.t. \\space \\sum_{j,k}=\\sigma_j\\sigma_k,|\\sigma_j|\\le \\rho_j,\\forall j\\in\\{1,…,d\\}$ for capturing noise induced by pairwise interaction terms. Define robust factorization machines as $\\phi _{RFM}$：\n$$\n\\phi_{RFM}(\\mathbf{x},\\mathbf{w},\\mathbf{V},\\mathbf{x},\\mathbf{\\Sigma})=w_0+\\sum_{j=1}^dw_j(x_j+\\mu_j)+\\frac{1}{2}\\sum_{j=1}^{d}\\sum_{k=j}^{d}\\langle \\mathbf{v}_j,\\mathbf{v}_k\\rangle(x_jx_k+\\Sigma_{j,k})\n$$\nafter expanding:\n$$\n\\phi_{RFM}(\\mathbf{x},\\mathbf{w},\\mathbf{V},\\mathbf{x},\\mathbf{\\Sigma})=w_0+\\sum_{j=1}^{d}w_jx_j+\\sum_{j=1}^{d}w_j\\mu_j+\\frac{1}{2}\\sum_{f=1}^{p}(\\sum_{j=1}^{d}v_{j,f}x_j)^2+\n\\\\\n\\frac{1}{2}\\sum_{f=1}^{p}(\\sum_{j=1}^{d}v_{j,f}\\sigma_j)^2+\n+\\frac{1}{2}\\sum_{f=1}^{p}\\sum_{j=1}^{d}v_{j,f}^2x_j^2+\\frac{1}{2}\\sum_{f=1}^{p}\\sum_{j=1}^{d}v_{j,f}^2\\sigma_j^2\n$$\n\n#### how to robust\n\nchange the model, use uncertainty sets.\n\n### 2. Robust Top-k Multiclass SVM for Visual Category Recognition\n\n#### contributions\n\nThe major limitation of the existing top-k extension is its sensitivity to abnormal observations, i.e., outliers, after all its loss is still convex. to overcome this problem, we proposed a robust multiclass SVM formulation that directly aims at minimizing a weighted and truncated combination of the ordered prediction score. the algorithm includes many previous multiclass SVMs as special cases.\n\n#### model\n\nGiven a training sample $(x_i,y_i),i=1,…,n$, where $x_i\\in\\mathcal{X}\\subseteq \\mathbb{R}^d$ and $y_i \\in \\mathcal{Y}:=\\{1,…,c\\}$, loss function for the multiclass SVM:\n$$\n\\ell_i=\\ell_i(W):=\\max_{j\\in\\mathcal{Y}} \\{\\mathbb{I}_{j\\neq y_i}+\\langle\\mathbf{w}_j,\\mathbf{x}_i\\rangle-\\langle\\mathbf{w}_{y_i},\\mathbf{x}_i\\rangle\\}\n$$\n\n\nWe use $a_{[k]}$ to denote the k-th largest entry of the vector a, and the matrix $W_{\\backslash y}\\in \\mathbb{R}^{(c-1)\\times d}$ remove the y-th row of $W$. then loss function for top-k multiclass SVM:\n$$\n\\ell_i(W):=\\max \\{0,(W_{\\backslash y_i}\\mathbf{x}_i)_{[k]}+1-\\langle\\mathbf{w}_{y_i},\\mathbf{x}_i\\rangle\\}\n\\\\\n=\\max \\{0, \\left ( (W-\\mathbf{1}\\mathbf{w}_{y_i}^{T})\\mathbf{x}_i+1-\\mathbf{e}_{y_i}\\right )_{[k]}\\}\n$$\n\n\nwhere $\\mathbf{e}_j$ is the j-th canonical basis vector, and $\\mathbf{1}$ is the all ones vector.\n\nthe major limitation of the original nonconvex top-k loss equation is their sensitivity to abnormal observations, i.e. outliers. This is mostly due to the unboundedness of the corresponding losses. To overcome this limitation and make it more robust, change the loss function:\n$$\n\\ell_i(W):=\\min \\{ \\max \\{0,\\sum_{j=1}^c \\alpha_j s_{[j]}^i\\},\\tau \\}\n$$\nwhere we use the following abbreviations for the scores\n$$\ns^i=(W-\\mathbf{1}\\mathbf{w}_{y_i}^T)\\mathbf{x}_i+1-\\mathbf{e}_{y_i}\n$$\nand $\\alpha \\in \\mathbb{R}^k$ is an arbitrary weight that choose to combine the ordered scores. $\\tau > 0$ is a hyperparameter that we use to cap the loss for any training pair.\n\n#### how to robust\n\nchange the loss function by use capped form, make algorithm can \"give up\" focusing any training pair that incurs an excessively large loss, namely, outliers. \n\n","source":"_posts/robust-optimization-in-ML.md","raw":"---\ntitle: robust optimization in ML\ndate: 2018-04-25 13:25:41\ntags: machine learning\ncategories: artificial intelligence\n---\nIn real large application where the training data may have noise and outliers, general ML algorithm may be very sensitive to noise and outliers. algorithm with robust can overcome this situation. \n\n<!--more-->\n\n### 1. Robust Factorization Machines for User Response Prediction\n\n####contributions\n\nthe work aims at characterizing the environment-induced un- certainty in the user signals and reformulating the FM and FFM objective functions to be immune against data fluctuations. \nmain contributions:\n\n* employ robust optimization principles to model the noise arising in online advertising signals as boundes box-type interval uncertainty sets.\n* propose two novel algorithms: robust factorization machine (RFM) and robust field-aware factorization machine(RFFM).\n* using parallel stochastic gradient decent.\n* evaluate on three publicly available response prediction datasets from criteo and avazu. for classification robust version takes a slight performance hit in the standard setting but significantly outperforms the non-robust counterparts when subjected to noise.\n* provide guidelines for selection of uncertainly sets.\n* a general model\n\n\n#### model\n\nwe associate uncertainty vector $\\mu\\in \\mathbb{R}^d\\space s.t. \\space |\\mu_j|\\leq\\eta_j,\\forall j\\in \\{1,…,d\\}$ for characterizing noise in linear interactions and matrix $\\sum\\in\\mathbb{R}^{d\\times d} \\space s.t. \\space \\sum_{j,k}=\\sigma_j\\sigma_k,|\\sigma_j|\\le \\rho_j,\\forall j\\in\\{1,…,d\\}$ for capturing noise induced by pairwise interaction terms. Define robust factorization machines as $\\phi _{RFM}$：\n$$\n\\phi_{RFM}(\\mathbf{x},\\mathbf{w},\\mathbf{V},\\mathbf{x},\\mathbf{\\Sigma})=w_0+\\sum_{j=1}^dw_j(x_j+\\mu_j)+\\frac{1}{2}\\sum_{j=1}^{d}\\sum_{k=j}^{d}\\langle \\mathbf{v}_j,\\mathbf{v}_k\\rangle(x_jx_k+\\Sigma_{j,k})\n$$\nafter expanding:\n$$\n\\phi_{RFM}(\\mathbf{x},\\mathbf{w},\\mathbf{V},\\mathbf{x},\\mathbf{\\Sigma})=w_0+\\sum_{j=1}^{d}w_jx_j+\\sum_{j=1}^{d}w_j\\mu_j+\\frac{1}{2}\\sum_{f=1}^{p}(\\sum_{j=1}^{d}v_{j,f}x_j)^2+\n\\\\\n\\frac{1}{2}\\sum_{f=1}^{p}(\\sum_{j=1}^{d}v_{j,f}\\sigma_j)^2+\n+\\frac{1}{2}\\sum_{f=1}^{p}\\sum_{j=1}^{d}v_{j,f}^2x_j^2+\\frac{1}{2}\\sum_{f=1}^{p}\\sum_{j=1}^{d}v_{j,f}^2\\sigma_j^2\n$$\n\n#### how to robust\n\nchange the model, use uncertainty sets.\n\n### 2. Robust Top-k Multiclass SVM for Visual Category Recognition\n\n#### contributions\n\nThe major limitation of the existing top-k extension is its sensitivity to abnormal observations, i.e., outliers, after all its loss is still convex. to overcome this problem, we proposed a robust multiclass SVM formulation that directly aims at minimizing a weighted and truncated combination of the ordered prediction score. the algorithm includes many previous multiclass SVMs as special cases.\n\n#### model\n\nGiven a training sample $(x_i,y_i),i=1,…,n$, where $x_i\\in\\mathcal{X}\\subseteq \\mathbb{R}^d$ and $y_i \\in \\mathcal{Y}:=\\{1,…,c\\}$, loss function for the multiclass SVM:\n$$\n\\ell_i=\\ell_i(W):=\\max_{j\\in\\mathcal{Y}} \\{\\mathbb{I}_{j\\neq y_i}+\\langle\\mathbf{w}_j,\\mathbf{x}_i\\rangle-\\langle\\mathbf{w}_{y_i},\\mathbf{x}_i\\rangle\\}\n$$\n\n\nWe use $a_{[k]}$ to denote the k-th largest entry of the vector a, and the matrix $W_{\\backslash y}\\in \\mathbb{R}^{(c-1)\\times d}$ remove the y-th row of $W$. then loss function for top-k multiclass SVM:\n$$\n\\ell_i(W):=\\max \\{0,(W_{\\backslash y_i}\\mathbf{x}_i)_{[k]}+1-\\langle\\mathbf{w}_{y_i},\\mathbf{x}_i\\rangle\\}\n\\\\\n=\\max \\{0, \\left ( (W-\\mathbf{1}\\mathbf{w}_{y_i}^{T})\\mathbf{x}_i+1-\\mathbf{e}_{y_i}\\right )_{[k]}\\}\n$$\n\n\nwhere $\\mathbf{e}_j$ is the j-th canonical basis vector, and $\\mathbf{1}$ is the all ones vector.\n\nthe major limitation of the original nonconvex top-k loss equation is their sensitivity to abnormal observations, i.e. outliers. This is mostly due to the unboundedness of the corresponding losses. To overcome this limitation and make it more robust, change the loss function:\n$$\n\\ell_i(W):=\\min \\{ \\max \\{0,\\sum_{j=1}^c \\alpha_j s_{[j]}^i\\},\\tau \\}\n$$\nwhere we use the following abbreviations for the scores\n$$\ns^i=(W-\\mathbf{1}\\mathbf{w}_{y_i}^T)\\mathbf{x}_i+1-\\mathbf{e}_{y_i}\n$$\nand $\\alpha \\in \\mathbb{R}^k$ is an arbitrary weight that choose to combine the ordered scores. $\\tau > 0$ is a hyperparameter that we use to cap the loss for any training pair.\n\n#### how to robust\n\nchange the loss function by use capped form, make algorithm can \"give up\" focusing any training pair that incurs an excessively large loss, namely, outliers. \n\n","slug":"robust-optimization-in-ML","published":1,"updated":"2018-08-15T11:16:06.521Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owc5000yfb9lsxh3o9g2","content":"<p>In real large application where the training data may have noise and outliers, general ML algorithm may be very sensitive to noise and outliers. algorithm with robust can overcome this situation. </p>\n<a id=\"more\"></a>\n<h3 id=\"1-Robust-Factorization-Machines-for-User-Response-Prediction\"><a href=\"#1-Robust-Factorization-Machines-for-User-Response-Prediction\" class=\"headerlink\" title=\"1. Robust Factorization Machines for User Response Prediction\"></a>1. Robust Factorization Machines for User Response Prediction</h3><h4 id=\"contributions\"><a href=\"#contributions\" class=\"headerlink\" title=\"contributions\"></a>contributions</h4><p>the work aims at characterizing the environment-induced un- certainty in the user signals and reformulating the FM and FFM objective functions to be immune against data fluctuations.<br>main contributions:</p>\n<ul>\n<li>employ robust optimization principles to model the noise arising in online advertising signals as boundes box-type interval uncertainty sets.</li>\n<li>propose two novel algorithms: robust factorization machine (RFM) and robust field-aware factorization machine(RFFM).</li>\n<li>using parallel stochastic gradient decent.</li>\n<li>evaluate on three publicly available response prediction datasets from criteo and avazu. for classification robust version takes a slight performance hit in the standard setting but significantly outperforms the non-robust counterparts when subjected to noise.</li>\n<li>provide guidelines for selection of uncertainly sets.</li>\n<li>a general model</li>\n</ul>\n<h4 id=\"model\"><a href=\"#model\" class=\"headerlink\" title=\"model\"></a>model</h4><p>we associate uncertainty vector $\\mu\\in \\mathbb{R}^d\\space s.t. \\space |\\mu_j|\\leq\\eta_j,\\forall j\\in \\{1,…,d\\}$ for characterizing noise in linear interactions and matrix $\\sum\\in\\mathbb{R}^{d\\times d} \\space s.t. \\space \\sum_{j,k}=\\sigma_j\\sigma_k,|\\sigma_j|\\le \\rho_j,\\forall j\\in\\{1,…,d\\}$ for capturing noise induced by pairwise interaction terms. Define robust factorization machines as $\\phi _{RFM}$：</p>\n<script type=\"math/tex; mode=display\">\n\\phi_{RFM}(\\mathbf{x},\\mathbf{w},\\mathbf{V},\\mathbf{x},\\mathbf{\\Sigma})=w_0+\\sum_{j=1}^dw_j(x_j+\\mu_j)+\\frac{1}{2}\\sum_{j=1}^{d}\\sum_{k=j}^{d}\\langle \\mathbf{v}_j,\\mathbf{v}_k\\rangle(x_jx_k+\\Sigma_{j,k})</script><p>after expanding:</p>\n<script type=\"math/tex; mode=display\">\n\\phi_{RFM}(\\mathbf{x},\\mathbf{w},\\mathbf{V},\\mathbf{x},\\mathbf{\\Sigma})=w_0+\\sum_{j=1}^{d}w_jx_j+\\sum_{j=1}^{d}w_j\\mu_j+\\frac{1}{2}\\sum_{f=1}^{p}(\\sum_{j=1}^{d}v_{j,f}x_j)^2+\n\\\\\n\\frac{1}{2}\\sum_{f=1}^{p}(\\sum_{j=1}^{d}v_{j,f}\\sigma_j)^2+\n+\\frac{1}{2}\\sum_{f=1}^{p}\\sum_{j=1}^{d}v_{j,f}^2x_j^2+\\frac{1}{2}\\sum_{f=1}^{p}\\sum_{j=1}^{d}v_{j,f}^2\\sigma_j^2</script><h4 id=\"how-to-robust\"><a href=\"#how-to-robust\" class=\"headerlink\" title=\"how to robust\"></a>how to robust</h4><p>change the model, use uncertainty sets.</p>\n<h3 id=\"2-Robust-Top-k-Multiclass-SVM-for-Visual-Category-Recognition\"><a href=\"#2-Robust-Top-k-Multiclass-SVM-for-Visual-Category-Recognition\" class=\"headerlink\" title=\"2. Robust Top-k Multiclass SVM for Visual Category Recognition\"></a>2. Robust Top-k Multiclass SVM for Visual Category Recognition</h3><h4 id=\"contributions-1\"><a href=\"#contributions-1\" class=\"headerlink\" title=\"contributions\"></a>contributions</h4><p>The major limitation of the existing top-k extension is its sensitivity to abnormal observations, i.e., outliers, after all its loss is still convex. to overcome this problem, we proposed a robust multiclass SVM formulation that directly aims at minimizing a weighted and truncated combination of the ordered prediction score. the algorithm includes many previous multiclass SVMs as special cases.</p>\n<h4 id=\"model-1\"><a href=\"#model-1\" class=\"headerlink\" title=\"model\"></a>model</h4><p>Given a training sample $(x_i,y_i),i=1,…,n$, where $x_i\\in\\mathcal{X}\\subseteq \\mathbb{R}^d$ and $y_i \\in \\mathcal{Y}:=\\{1,…,c\\}$, loss function for the multiclass SVM:</p>\n<script type=\"math/tex; mode=display\">\n\\ell_i=\\ell_i(W):=\\max_{j\\in\\mathcal{Y}} \\{\\mathbb{I}_{j\\neq y_i}+\\langle\\mathbf{w}_j,\\mathbf{x}_i\\rangle-\\langle\\mathbf{w}_{y_i},\\mathbf{x}_i\\rangle\\}</script><p>We use $a_{[k]}$ to denote the k-th largest entry of the vector a, and the matrix $W_{\\backslash y}\\in \\mathbb{R}^{(c-1)\\times d}$ remove the y-th row of $W$. then loss function for top-k multiclass SVM:</p>\n<script type=\"math/tex; mode=display\">\n\\ell_i(W):=\\max \\{0,(W_{\\backslash y_i}\\mathbf{x}_i)_{[k]}+1-\\langle\\mathbf{w}_{y_i},\\mathbf{x}_i\\rangle\\}\n\\\\\n=\\max \\{0, \\left ( (W-\\mathbf{1}\\mathbf{w}_{y_i}^{T})\\mathbf{x}_i+1-\\mathbf{e}_{y_i}\\right )_{[k]}\\}</script><p>where $\\mathbf{e}_j$ is the j-th canonical basis vector, and $\\mathbf{1}$ is the all ones vector.</p>\n<p>the major limitation of the original nonconvex top-k loss equation is their sensitivity to abnormal observations, i.e. outliers. This is mostly due to the unboundedness of the corresponding losses. To overcome this limitation and make it more robust, change the loss function:</p>\n<script type=\"math/tex; mode=display\">\n\\ell_i(W):=\\min \\{ \\max \\{0,\\sum_{j=1}^c \\alpha_j s_{[j]}^i\\},\\tau \\}</script><p>where we use the following abbreviations for the scores</p>\n<script type=\"math/tex; mode=display\">\ns^i=(W-\\mathbf{1}\\mathbf{w}_{y_i}^T)\\mathbf{x}_i+1-\\mathbf{e}_{y_i}</script><p>and $\\alpha \\in \\mathbb{R}^k$ is an arbitrary weight that choose to combine the ordered scores. $\\tau &gt; 0$ is a hyperparameter that we use to cap the loss for any training pair.</p>\n<h4 id=\"how-to-robust-1\"><a href=\"#how-to-robust-1\" class=\"headerlink\" title=\"how to robust\"></a>how to robust</h4><p>change the loss function by use capped form, make algorithm can “give up” focusing any training pair that incurs an excessively large loss, namely, outliers. </p>\n","site":{"data":{}},"excerpt":"<p>In real large application where the training data may have noise and outliers, general ML algorithm may be very sensitive to noise and outliers. algorithm with robust can overcome this situation. </p>","more":"<h3 id=\"1-Robust-Factorization-Machines-for-User-Response-Prediction\"><a href=\"#1-Robust-Factorization-Machines-for-User-Response-Prediction\" class=\"headerlink\" title=\"1. Robust Factorization Machines for User Response Prediction\"></a>1. Robust Factorization Machines for User Response Prediction</h3><h4 id=\"contributions\"><a href=\"#contributions\" class=\"headerlink\" title=\"contributions\"></a>contributions</h4><p>the work aims at characterizing the environment-induced un- certainty in the user signals and reformulating the FM and FFM objective functions to be immune against data fluctuations.<br>main contributions:</p>\n<ul>\n<li>employ robust optimization principles to model the noise arising in online advertising signals as boundes box-type interval uncertainty sets.</li>\n<li>propose two novel algorithms: robust factorization machine (RFM) and robust field-aware factorization machine(RFFM).</li>\n<li>using parallel stochastic gradient decent.</li>\n<li>evaluate on three publicly available response prediction datasets from criteo and avazu. for classification robust version takes a slight performance hit in the standard setting but significantly outperforms the non-robust counterparts when subjected to noise.</li>\n<li>provide guidelines for selection of uncertainly sets.</li>\n<li>a general model</li>\n</ul>\n<h4 id=\"model\"><a href=\"#model\" class=\"headerlink\" title=\"model\"></a>model</h4><p>we associate uncertainty vector $\\mu\\in \\mathbb{R}^d\\space s.t. \\space |\\mu_j|\\leq\\eta_j,\\forall j\\in \\{1,…,d\\}$ for characterizing noise in linear interactions and matrix $\\sum\\in\\mathbb{R}^{d\\times d} \\space s.t. \\space \\sum_{j,k}=\\sigma_j\\sigma_k,|\\sigma_j|\\le \\rho_j,\\forall j\\in\\{1,…,d\\}$ for capturing noise induced by pairwise interaction terms. Define robust factorization machines as $\\phi _{RFM}$：</p>\n<script type=\"math/tex; mode=display\">\n\\phi_{RFM}(\\mathbf{x},\\mathbf{w},\\mathbf{V},\\mathbf{x},\\mathbf{\\Sigma})=w_0+\\sum_{j=1}^dw_j(x_j+\\mu_j)+\\frac{1}{2}\\sum_{j=1}^{d}\\sum_{k=j}^{d}\\langle \\mathbf{v}_j,\\mathbf{v}_k\\rangle(x_jx_k+\\Sigma_{j,k})</script><p>after expanding:</p>\n<script type=\"math/tex; mode=display\">\n\\phi_{RFM}(\\mathbf{x},\\mathbf{w},\\mathbf{V},\\mathbf{x},\\mathbf{\\Sigma})=w_0+\\sum_{j=1}^{d}w_jx_j+\\sum_{j=1}^{d}w_j\\mu_j+\\frac{1}{2}\\sum_{f=1}^{p}(\\sum_{j=1}^{d}v_{j,f}x_j)^2+\n\\\\\n\\frac{1}{2}\\sum_{f=1}^{p}(\\sum_{j=1}^{d}v_{j,f}\\sigma_j)^2+\n+\\frac{1}{2}\\sum_{f=1}^{p}\\sum_{j=1}^{d}v_{j,f}^2x_j^2+\\frac{1}{2}\\sum_{f=1}^{p}\\sum_{j=1}^{d}v_{j,f}^2\\sigma_j^2</script><h4 id=\"how-to-robust\"><a href=\"#how-to-robust\" class=\"headerlink\" title=\"how to robust\"></a>how to robust</h4><p>change the model, use uncertainty sets.</p>\n<h3 id=\"2-Robust-Top-k-Multiclass-SVM-for-Visual-Category-Recognition\"><a href=\"#2-Robust-Top-k-Multiclass-SVM-for-Visual-Category-Recognition\" class=\"headerlink\" title=\"2. Robust Top-k Multiclass SVM for Visual Category Recognition\"></a>2. Robust Top-k Multiclass SVM for Visual Category Recognition</h3><h4 id=\"contributions-1\"><a href=\"#contributions-1\" class=\"headerlink\" title=\"contributions\"></a>contributions</h4><p>The major limitation of the existing top-k extension is its sensitivity to abnormal observations, i.e., outliers, after all its loss is still convex. to overcome this problem, we proposed a robust multiclass SVM formulation that directly aims at minimizing a weighted and truncated combination of the ordered prediction score. the algorithm includes many previous multiclass SVMs as special cases.</p>\n<h4 id=\"model-1\"><a href=\"#model-1\" class=\"headerlink\" title=\"model\"></a>model</h4><p>Given a training sample $(x_i,y_i),i=1,…,n$, where $x_i\\in\\mathcal{X}\\subseteq \\mathbb{R}^d$ and $y_i \\in \\mathcal{Y}:=\\{1,…,c\\}$, loss function for the multiclass SVM:</p>\n<script type=\"math/tex; mode=display\">\n\\ell_i=\\ell_i(W):=\\max_{j\\in\\mathcal{Y}} \\{\\mathbb{I}_{j\\neq y_i}+\\langle\\mathbf{w}_j,\\mathbf{x}_i\\rangle-\\langle\\mathbf{w}_{y_i},\\mathbf{x}_i\\rangle\\}</script><p>We use $a_{[k]}$ to denote the k-th largest entry of the vector a, and the matrix $W_{\\backslash y}\\in \\mathbb{R}^{(c-1)\\times d}$ remove the y-th row of $W$. then loss function for top-k multiclass SVM:</p>\n<script type=\"math/tex; mode=display\">\n\\ell_i(W):=\\max \\{0,(W_{\\backslash y_i}\\mathbf{x}_i)_{[k]}+1-\\langle\\mathbf{w}_{y_i},\\mathbf{x}_i\\rangle\\}\n\\\\\n=\\max \\{0, \\left ( (W-\\mathbf{1}\\mathbf{w}_{y_i}^{T})\\mathbf{x}_i+1-\\mathbf{e}_{y_i}\\right )_{[k]}\\}</script><p>where $\\mathbf{e}_j$ is the j-th canonical basis vector, and $\\mathbf{1}$ is the all ones vector.</p>\n<p>the major limitation of the original nonconvex top-k loss equation is their sensitivity to abnormal observations, i.e. outliers. This is mostly due to the unboundedness of the corresponding losses. To overcome this limitation and make it more robust, change the loss function:</p>\n<script type=\"math/tex; mode=display\">\n\\ell_i(W):=\\min \\{ \\max \\{0,\\sum_{j=1}^c \\alpha_j s_{[j]}^i\\},\\tau \\}</script><p>where we use the following abbreviations for the scores</p>\n<script type=\"math/tex; mode=display\">\ns^i=(W-\\mathbf{1}\\mathbf{w}_{y_i}^T)\\mathbf{x}_i+1-\\mathbf{e}_{y_i}</script><p>and $\\alpha \\in \\mathbb{R}^k$ is an arbitrary weight that choose to combine the ordered scores. $\\tau &gt; 0$ is a hyperparameter that we use to cap the loss for any training pair.</p>\n<h4 id=\"how-to-robust-1\"><a href=\"#how-to-robust-1\" class=\"headerlink\" title=\"how to robust\"></a>how to robust</h4><p>change the loss function by use capped form, make algorithm can “give up” focusing any training pair that incurs an excessively large loss, namely, outliers. </p>"},{"title":"机器学习-决策树","date":"2018-01-15T01:23:13.000Z","_content":"\n机器学习——周志华\n\n读书笔记\n\n第四章——决策树\n\n<!--more-->\n\n### 4.1 基本流程\n\n基本思想：分而治之，每次选择最优属性进行划分\n\n![算法](http://oygov02sc.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-1.png)\n\n### 4.2 划分选择\n\n目标：随着划分过程的不断进行，决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度（purity）越来越高。\n\n#### 4.2.1 信息增益（information gain)\n\n信息熵（information entropy）：度量样本集合纯度常用指标，熵越小，纯度越高，假定当前集合D中第k类样本所占的比例为 $p_k(k=1,2,…,|y|)$，则D的信息熵定义为\n$$\nEnt(D) = - \\sum_{k=1}^{|y|}p_{k}log{2}p_{k}\n$$\n信息增益：可以认为是划分前后的熵差，信息增益越大，则意味划分所获的纯度提升越大，即属性“越好”。假定离散属性 a 有 V 个可能的取值${a_{1},a_{2},…a_{v}}$，若采用 a 对样本集 D 进行划分，则会产生 V 个分支结点，其中第 v 个分支结点包含了 D 中所有在属性 a 上取值为 $a^{v}$ 的样本，记为$D^{v}$，可以计算出$D^{v}$的信息熵，再考虑不同分支结点所包含的样本数不同，给分支结点赋予权重$|D^v|/|D|$，即样本数越多的分支影响越大，于是可计算出用属性 a 对样本集 D 进行划分所获得的信息增益:\n$$\nGain(D,a) = Ent(D) - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}Ent(D^v)\n$$\nID3 决策树学习算法 [Quinlan, 1986]即采用该算法来选择划分属性。\n\n#### 4.2.2 增益率（gain ratio）\n\n使用信息增益准则的决策树，会对可取值数目较多的属性有所偏好，这种偏好会弱化决策树的泛化能力。\n\n为了减少这种偏好带来的不利影响，C4.5 决策树算法 [Quinlan, 1986]采用增益率来选择最优划分属性，增益率定义如下：\n$$\nGain\\_ratio(D,a) = \\dfrac{Gain(D,a)}{IV(a)}\n$$\n其中\n$$\nIV(a) = - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}\\log{2}^{\\dfrac{|D^{v}|}{|D|}}\n$$\n属于属性 a 的固有值（intrinsic value），属性 a 的取值数目越多，则 IV(a) 越大。\n\ntips：增益率会对可取值数目较少的属性有所偏好，因此，C4.5算法并不是选择增益率最大的候选划分属性，而是采用启发式[Quinlan, 1993]：\n\n1. 从候选属性中找出信息增益高于平均的属性组成集合 W\n2. 从 W 中选出增益率最高的作为最优划分属性\n\n#### 4.2.3 基尼指数（Gini index）\n\nCART 决策树算法[Breiman et al.,1984] 使用基尼系数来选择划分属性，数据集的纯度采用基尼值度量：\n$$\n\\begin{equation}\n\\begin{aligned}Gini(D) & = \\sum_{k=1}^{|y|}\\sum_{k^{'}\\not{=}k}{p_{k}p_{k^{'}}}\\\\\n& =1-\\sum_{k=1}^{|y|}p_{k}^{2}\n\\end{aligned}\n\\end{equation}\n$$\nGini(D)越小，数据集D的纯度越高，属性 a 的基尼指数定义为\n$$\nGini\\_index(D,a) = \\sum_{v=1}^{V}\\frac{|D|}{|D^v|}Gini(D^v)\n$$\n\n> 注意：在原书上此部分讲解较少，CART决策树算法采用二分递归分割技术，每次将当前结点分割为两个样本集，最终生成的是一棵二叉树。因此上述的Gini(D)公式的 y = 2：若属性为离散值且可能的取值大于2，则针对每个可能的取值a，根据样本对 k = a 测试的是否将样本分为两类，计算出Gini值和Gini_index，然后选择使Gini_index最小的值作为划分基准；若属性为连续值，参考下一节离散值处理.\n\n在候选属性集合A中，选择哪个使得划分后基尼指数最小的属性作为最优划分属性，即 $a_* = \\arg min_{a\\in{A}}Gini\\_index(D,a)$.\n\n### 4.3 剪枝处理（pruning）\n\n目的：降低过拟合的风险\n\n基本策略：预剪枝（prepruning）、后剪枝（post-pruning）\n\n> 采用留出法，将数据集分为训练集和验证集。\n\n#### 4.3.1 预剪枝\n\n在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化能力的提升，则停止划分并将当前结点标记为叶结点。\n\n* 计算划分前在验证集上的精度S1\n* 计算划分后在验证集上的精度S2\n* 若S1 < S2，则划分，反正则不划分，归为叶结点\n\n#### 4.3.2 后剪枝\n\n先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树换成叶结点能带来泛化性能提升，则将该字数换成叶结点。\n\n* 生成完整决策树，然后自底向上执行下面三步\n* 计算当前结点在验证集上的精度S1\n* 计算将当前结点领衔的分支剪除后的精度S2\n* 若S1 < S2 ，则剪枝（将该结点的分支剪除，替换为叶结点），否则不剪枝\n\n### 4.4 连续与缺失值\n\n#### 4.4.1 连续值处理\n\n对于连续属性，需要进行离散化。最简单的策略是采用二分法（bi-partition），这正是C4.5决策树算法中采用的机制[Quinlan,1993].\n\n> CART决策树算法也采用该方法\n\n给定样本集D和连续属性a，假定a在D上出现n个不同的取值，将这些值从小到大排序，记为${a^1,a^2,…,a^n}$. 基于划分点 t 可将D分为子集$D_t^-$和$D_t^+$，其中$D_t^-$包含那些在属性 a 上取值不大于 t 的样本，而 $D_t^+$ 则包含那些在属性 a 上取值大于 t 的样本。对于连续属性 a，我们可考察包含 n-1 个元素的候选划分点集合\n$$\nT_a = \\left\\{\\frac{a^i+a^{i+1}}{2} | 1 \\le i \\le n-1\\right\\}\n$$\n即把区间$[a^i,a^{i+1})$的中位数$\\frac{a^i+a^{i+1}}{2}$作为候选划分点，然后，可以像离散属性值一样来考察这些划分点，选择最优的划分点进行样本集合划分。\n\n#### 4.4.2 缺失值处理\n\n针对不完整样本，若样本出现大量缺失，简单的放弃是对数据极大的浪费，因此需要考虑利用有缺失属性值的训练样本。\n\n给定训练集 D 和属性 a，令 $\\widetilde{D}$  表示 D 中在属性 a 上没有缺失值的样本子集，假定属性 a 有 V 个可取值 ${a^1,a^2,…,a^V}$, 样本有 y 个类，假设我们为每个样本 x 赋予一个权重 $w_x$ ，定义：\n$$\n\\rho=\\frac{\\sum_{x\\in{\\widetilde{D}}}w_x}{\\sum_{x\\in{D}}w_x}\n\\\\\n\\widetilde{p}_k=\\frac{\\sum_{x\\in{\\widetilde{D}_k}}w_x}{\\sum_{x\\in{\\widetilde{D}}}w_x}\n(1\\le k \\le |y|)\n\\\\\n\\rho=\\frac{\\sum_{x\\in{\\widetilde{D}^v}}w_x}{\\sum_{x\\in{\\widetilde{D}}}w_x}\n(1\\le v \\le V)\n$$\n对属性a，$\\rho$ 表示无缺失样本所占的比例，$\\widetilde{p}_k$ 表示无缺失样本中第 k 类所占的比例， $\\widetilde{r}_v$ 表示无缺失样本中在属性 a 上取值 $a^v$ 的样本所占的比例，显然：\n$$\n\\sum_{k=1}^{|y|}\\widetilde{p}_k = 1, \\sum_{v=1}^{V}\\widetilde{r}_v=1\n$$\n基于上述定义，信息增益计算公式推广为\n$$\n\\begin{equation}\n\\begin{aligned}\nGain(D,a)&=\\rho\\times Gain(\\widetilde{D},a)\n\\\\\n&=\\rho \\times \\left(Ent(\\widetilde{D})-\\sum_{v=1}^V\\widetilde{r}_vEnt(\\widetilde{D}^v)\\right)\n\\end{aligned}\n\\end{equation}\n$$\n其中\n$$\nEnt(\\widetilde{D}) = -\\sum_{k=1}^{|y|}\\widetilde{p}_klog_2\\widetilde{p}_k\n$$\n若样本 x 在划分属性 a 上的取值已知，则将x划入与其取值对应的子结点，且缺中不变。若样本在属性 a 上**取值未知**，则将 x 同时划分到**所有子结点**，且样本权值在与属性值 $a^v$ 对应的子结点中调整为 $\\widetilde{r}_v\\cdot{w_x}$, 也就是让同一个样本以不同的概率划分到不同的子结点。\n\nC4.5 算法采用了上述解决方案[Quinlan,1993].\n\n### 4.5 多变量决策树\n\n将每个属性视为坐标空间中的一个坐标轴，则 d 个属性描述的样本就对应了 d 维空间的一个数据点，对样本分类就相当于在这个坐标空间寻找不同类样本的分类边界。传统的单变量决策树形成的分类边界有一个明显的特点：轴平行（axis-parallel），即分类边界是由若干个与坐标轴平行的分段组成。\n\n若采用斜的划分边界，则决策树模型将会简化，这就是多变量决策树（multivariate decision tree），每个非叶节点就是一个线性分类器。如下图\n\n![斜划分边界](http://oygov02sc.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-2.png)\n\n### 个人总结\n\n#### ID3\\ID4.5\\CART对比\n\nID3缺点\n\n- ID3算法不能处理具有连续值的属性（由于ID3以信息增益为准则选择划分属性，对可取值多的属性有所偏好，这样一来，用二分法进行连续属性的离散化处理时，可取值多的属性就越有可能成为分裂属性，而这样其实是没有意义的）\n- ID3算法不能处理属性具有缺失值的样本\n- 算法会生成很深的树，容易产生过拟合现象\n- 算法一般会优先选择有较多属性值的特征，因为属性值多的特征会有相对较大的信息增益\n\nID4.5是对ID3的改进，修正了其对较多属性值的偏好。C4.5还弥补了ID3中不能处理特征属性值连续的问题。但是，其存在如下缺点\n\n* 算法低效，在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效\n* 内存受限，适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行\n\nCART是二叉树，采用二元切分，即可用于分类也可用于回归。\n\n","source":"_posts/机器学习-决策树.md","raw":"---\ntitle: 机器学习-决策树\ndate: 2018-01-15 09:23:13\ntags: [machine learing]\ncategories: [artificial intelligence]\n---\n\n机器学习——周志华\n\n读书笔记\n\n第四章——决策树\n\n<!--more-->\n\n### 4.1 基本流程\n\n基本思想：分而治之，每次选择最优属性进行划分\n\n![算法](http://oygov02sc.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-1.png)\n\n### 4.2 划分选择\n\n目标：随着划分过程的不断进行，决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度（purity）越来越高。\n\n#### 4.2.1 信息增益（information gain)\n\n信息熵（information entropy）：度量样本集合纯度常用指标，熵越小，纯度越高，假定当前集合D中第k类样本所占的比例为 $p_k(k=1,2,…,|y|)$，则D的信息熵定义为\n$$\nEnt(D) = - \\sum_{k=1}^{|y|}p_{k}log{2}p_{k}\n$$\n信息增益：可以认为是划分前后的熵差，信息增益越大，则意味划分所获的纯度提升越大，即属性“越好”。假定离散属性 a 有 V 个可能的取值${a_{1},a_{2},…a_{v}}$，若采用 a 对样本集 D 进行划分，则会产生 V 个分支结点，其中第 v 个分支结点包含了 D 中所有在属性 a 上取值为 $a^{v}$ 的样本，记为$D^{v}$，可以计算出$D^{v}$的信息熵，再考虑不同分支结点所包含的样本数不同，给分支结点赋予权重$|D^v|/|D|$，即样本数越多的分支影响越大，于是可计算出用属性 a 对样本集 D 进行划分所获得的信息增益:\n$$\nGain(D,a) = Ent(D) - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}Ent(D^v)\n$$\nID3 决策树学习算法 [Quinlan, 1986]即采用该算法来选择划分属性。\n\n#### 4.2.2 增益率（gain ratio）\n\n使用信息增益准则的决策树，会对可取值数目较多的属性有所偏好，这种偏好会弱化决策树的泛化能力。\n\n为了减少这种偏好带来的不利影响，C4.5 决策树算法 [Quinlan, 1986]采用增益率来选择最优划分属性，增益率定义如下：\n$$\nGain\\_ratio(D,a) = \\dfrac{Gain(D,a)}{IV(a)}\n$$\n其中\n$$\nIV(a) = - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}\\log{2}^{\\dfrac{|D^{v}|}{|D|}}\n$$\n属于属性 a 的固有值（intrinsic value），属性 a 的取值数目越多，则 IV(a) 越大。\n\ntips：增益率会对可取值数目较少的属性有所偏好，因此，C4.5算法并不是选择增益率最大的候选划分属性，而是采用启发式[Quinlan, 1993]：\n\n1. 从候选属性中找出信息增益高于平均的属性组成集合 W\n2. 从 W 中选出增益率最高的作为最优划分属性\n\n#### 4.2.3 基尼指数（Gini index）\n\nCART 决策树算法[Breiman et al.,1984] 使用基尼系数来选择划分属性，数据集的纯度采用基尼值度量：\n$$\n\\begin{equation}\n\\begin{aligned}Gini(D) & = \\sum_{k=1}^{|y|}\\sum_{k^{'}\\not{=}k}{p_{k}p_{k^{'}}}\\\\\n& =1-\\sum_{k=1}^{|y|}p_{k}^{2}\n\\end{aligned}\n\\end{equation}\n$$\nGini(D)越小，数据集D的纯度越高，属性 a 的基尼指数定义为\n$$\nGini\\_index(D,a) = \\sum_{v=1}^{V}\\frac{|D|}{|D^v|}Gini(D^v)\n$$\n\n> 注意：在原书上此部分讲解较少，CART决策树算法采用二分递归分割技术，每次将当前结点分割为两个样本集，最终生成的是一棵二叉树。因此上述的Gini(D)公式的 y = 2：若属性为离散值且可能的取值大于2，则针对每个可能的取值a，根据样本对 k = a 测试的是否将样本分为两类，计算出Gini值和Gini_index，然后选择使Gini_index最小的值作为划分基准；若属性为连续值，参考下一节离散值处理.\n\n在候选属性集合A中，选择哪个使得划分后基尼指数最小的属性作为最优划分属性，即 $a_* = \\arg min_{a\\in{A}}Gini\\_index(D,a)$.\n\n### 4.3 剪枝处理（pruning）\n\n目的：降低过拟合的风险\n\n基本策略：预剪枝（prepruning）、后剪枝（post-pruning）\n\n> 采用留出法，将数据集分为训练集和验证集。\n\n#### 4.3.1 预剪枝\n\n在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化能力的提升，则停止划分并将当前结点标记为叶结点。\n\n* 计算划分前在验证集上的精度S1\n* 计算划分后在验证集上的精度S2\n* 若S1 < S2，则划分，反正则不划分，归为叶结点\n\n#### 4.3.2 后剪枝\n\n先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树换成叶结点能带来泛化性能提升，则将该字数换成叶结点。\n\n* 生成完整决策树，然后自底向上执行下面三步\n* 计算当前结点在验证集上的精度S1\n* 计算将当前结点领衔的分支剪除后的精度S2\n* 若S1 < S2 ，则剪枝（将该结点的分支剪除，替换为叶结点），否则不剪枝\n\n### 4.4 连续与缺失值\n\n#### 4.4.1 连续值处理\n\n对于连续属性，需要进行离散化。最简单的策略是采用二分法（bi-partition），这正是C4.5决策树算法中采用的机制[Quinlan,1993].\n\n> CART决策树算法也采用该方法\n\n给定样本集D和连续属性a，假定a在D上出现n个不同的取值，将这些值从小到大排序，记为${a^1,a^2,…,a^n}$. 基于划分点 t 可将D分为子集$D_t^-$和$D_t^+$，其中$D_t^-$包含那些在属性 a 上取值不大于 t 的样本，而 $D_t^+$ 则包含那些在属性 a 上取值大于 t 的样本。对于连续属性 a，我们可考察包含 n-1 个元素的候选划分点集合\n$$\nT_a = \\left\\{\\frac{a^i+a^{i+1}}{2} | 1 \\le i \\le n-1\\right\\}\n$$\n即把区间$[a^i,a^{i+1})$的中位数$\\frac{a^i+a^{i+1}}{2}$作为候选划分点，然后，可以像离散属性值一样来考察这些划分点，选择最优的划分点进行样本集合划分。\n\n#### 4.4.2 缺失值处理\n\n针对不完整样本，若样本出现大量缺失，简单的放弃是对数据极大的浪费，因此需要考虑利用有缺失属性值的训练样本。\n\n给定训练集 D 和属性 a，令 $\\widetilde{D}$  表示 D 中在属性 a 上没有缺失值的样本子集，假定属性 a 有 V 个可取值 ${a^1,a^2,…,a^V}$, 样本有 y 个类，假设我们为每个样本 x 赋予一个权重 $w_x$ ，定义：\n$$\n\\rho=\\frac{\\sum_{x\\in{\\widetilde{D}}}w_x}{\\sum_{x\\in{D}}w_x}\n\\\\\n\\widetilde{p}_k=\\frac{\\sum_{x\\in{\\widetilde{D}_k}}w_x}{\\sum_{x\\in{\\widetilde{D}}}w_x}\n(1\\le k \\le |y|)\n\\\\\n\\rho=\\frac{\\sum_{x\\in{\\widetilde{D}^v}}w_x}{\\sum_{x\\in{\\widetilde{D}}}w_x}\n(1\\le v \\le V)\n$$\n对属性a，$\\rho$ 表示无缺失样本所占的比例，$\\widetilde{p}_k$ 表示无缺失样本中第 k 类所占的比例， $\\widetilde{r}_v$ 表示无缺失样本中在属性 a 上取值 $a^v$ 的样本所占的比例，显然：\n$$\n\\sum_{k=1}^{|y|}\\widetilde{p}_k = 1, \\sum_{v=1}^{V}\\widetilde{r}_v=1\n$$\n基于上述定义，信息增益计算公式推广为\n$$\n\\begin{equation}\n\\begin{aligned}\nGain(D,a)&=\\rho\\times Gain(\\widetilde{D},a)\n\\\\\n&=\\rho \\times \\left(Ent(\\widetilde{D})-\\sum_{v=1}^V\\widetilde{r}_vEnt(\\widetilde{D}^v)\\right)\n\\end{aligned}\n\\end{equation}\n$$\n其中\n$$\nEnt(\\widetilde{D}) = -\\sum_{k=1}^{|y|}\\widetilde{p}_klog_2\\widetilde{p}_k\n$$\n若样本 x 在划分属性 a 上的取值已知，则将x划入与其取值对应的子结点，且缺中不变。若样本在属性 a 上**取值未知**，则将 x 同时划分到**所有子结点**，且样本权值在与属性值 $a^v$ 对应的子结点中调整为 $\\widetilde{r}_v\\cdot{w_x}$, 也就是让同一个样本以不同的概率划分到不同的子结点。\n\nC4.5 算法采用了上述解决方案[Quinlan,1993].\n\n### 4.5 多变量决策树\n\n将每个属性视为坐标空间中的一个坐标轴，则 d 个属性描述的样本就对应了 d 维空间的一个数据点，对样本分类就相当于在这个坐标空间寻找不同类样本的分类边界。传统的单变量决策树形成的分类边界有一个明显的特点：轴平行（axis-parallel），即分类边界是由若干个与坐标轴平行的分段组成。\n\n若采用斜的划分边界，则决策树模型将会简化，这就是多变量决策树（multivariate decision tree），每个非叶节点就是一个线性分类器。如下图\n\n![斜划分边界](http://oygov02sc.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-2.png)\n\n### 个人总结\n\n#### ID3\\ID4.5\\CART对比\n\nID3缺点\n\n- ID3算法不能处理具有连续值的属性（由于ID3以信息增益为准则选择划分属性，对可取值多的属性有所偏好，这样一来，用二分法进行连续属性的离散化处理时，可取值多的属性就越有可能成为分裂属性，而这样其实是没有意义的）\n- ID3算法不能处理属性具有缺失值的样本\n- 算法会生成很深的树，容易产生过拟合现象\n- 算法一般会优先选择有较多属性值的特征，因为属性值多的特征会有相对较大的信息增益\n\nID4.5是对ID3的改进，修正了其对较多属性值的偏好。C4.5还弥补了ID3中不能处理特征属性值连续的问题。但是，其存在如下缺点\n\n* 算法低效，在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效\n* 内存受限，适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行\n\nCART是二叉树，采用二元切分，即可用于分类也可用于回归。\n\n","slug":"机器学习-决策树","published":1,"updated":"2018-04-28T09:35:36.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owc60011fb9l2k45kb82","content":"<p>机器学习——周志华</p>\n<p>读书笔记</p>\n<p>第四章——决策树</p>\n<a id=\"more\"></a>\n<h3 id=\"4-1-基本流程\"><a href=\"#4-1-基本流程\" class=\"headerlink\" title=\"4.1 基本流程\"></a>4.1 基本流程</h3><p>基本思想：分而治之，每次选择最优属性进行划分</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-1.png\" alt=\"算法\"></p>\n<h3 id=\"4-2-划分选择\"><a href=\"#4-2-划分选择\" class=\"headerlink\" title=\"4.2 划分选择\"></a>4.2 划分选择</h3><p>目标：随着划分过程的不断进行，决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度（purity）越来越高。</p>\n<h4 id=\"4-2-1-信息增益（information-gain\"><a href=\"#4-2-1-信息增益（information-gain\" class=\"headerlink\" title=\"4.2.1 信息增益（information gain)\"></a>4.2.1 信息增益（information gain)</h4><p>信息熵（information entropy）：度量样本集合纯度常用指标，熵越小，纯度越高，假定当前集合D中第k类样本所占的比例为 $p_k(k=1,2,…,|y|)$，则D的信息熵定义为</p>\n<script type=\"math/tex; mode=display\">\nEnt(D) = - \\sum_{k=1}^{|y|}p_{k}log{2}p_{k}</script><p>信息增益：可以认为是划分前后的熵差，信息增益越大，则意味划分所获的纯度提升越大，即属性“越好”。假定离散属性 a 有 V 个可能的取值${a_{1},a_{2},…a_{v}}$，若采用 a 对样本集 D 进行划分，则会产生 V 个分支结点，其中第 v 个分支结点包含了 D 中所有在属性 a 上取值为 $a^{v}$ 的样本，记为$D^{v}$，可以计算出$D^{v}$的信息熵，再考虑不同分支结点所包含的样本数不同，给分支结点赋予权重$|D^v|/|D|$，即样本数越多的分支影响越大，于是可计算出用属性 a 对样本集 D 进行划分所获得的信息增益:</p>\n<script type=\"math/tex; mode=display\">\nGain(D,a) = Ent(D) - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}Ent(D^v)</script><p>ID3 决策树学习算法 [Quinlan, 1986]即采用该算法来选择划分属性。</p>\n<h4 id=\"4-2-2-增益率（gain-ratio）\"><a href=\"#4-2-2-增益率（gain-ratio）\" class=\"headerlink\" title=\"4.2.2 增益率（gain ratio）\"></a>4.2.2 增益率（gain ratio）</h4><p>使用信息增益准则的决策树，会对可取值数目较多的属性有所偏好，这种偏好会弱化决策树的泛化能力。</p>\n<p>为了减少这种偏好带来的不利影响，C4.5 决策树算法 [Quinlan, 1986]采用增益率来选择最优划分属性，增益率定义如下：</p>\n<script type=\"math/tex; mode=display\">\nGain\\_ratio(D,a) = \\dfrac{Gain(D,a)}{IV(a)}</script><p>其中</p>\n<script type=\"math/tex; mode=display\">\nIV(a) = - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}\\log{2}^{\\dfrac{|D^{v}|}{|D|}}</script><p>属于属性 a 的固有值（intrinsic value），属性 a 的取值数目越多，则 IV(a) 越大。</p>\n<p>tips：增益率会对可取值数目较少的属性有所偏好，因此，C4.5算法并不是选择增益率最大的候选划分属性，而是采用启发式[Quinlan, 1993]：</p>\n<ol>\n<li>从候选属性中找出信息增益高于平均的属性组成集合 W</li>\n<li>从 W 中选出增益率最高的作为最优划分属性</li>\n</ol>\n<h4 id=\"4-2-3-基尼指数（Gini-index）\"><a href=\"#4-2-3-基尼指数（Gini-index）\" class=\"headerlink\" title=\"4.2.3 基尼指数（Gini index）\"></a>4.2.3 基尼指数（Gini index）</h4><p>CART 决策树算法[Breiman et al.,1984] 使用基尼系数来选择划分属性，数据集的纯度采用基尼值度量：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\begin{aligned}Gini(D) & = \\sum_{k=1}^{|y|}\\sum_{k^{'}\\not{=}k}{p_{k}p_{k^{'}}}\\\\\n& =1-\\sum_{k=1}^{|y|}p_{k}^{2}\n\\end{aligned}\n\\end{equation}</script><p>Gini(D)越小，数据集D的纯度越高，属性 a 的基尼指数定义为</p>\n<script type=\"math/tex; mode=display\">\nGini\\_index(D,a) = \\sum_{v=1}^{V}\\frac{|D|}{|D^v|}Gini(D^v)</script><blockquote>\n<p>注意：在原书上此部分讲解较少，CART决策树算法采用二分递归分割技术，每次将当前结点分割为两个样本集，最终生成的是一棵二叉树。因此上述的Gini(D)公式的 y = 2：若属性为离散值且可能的取值大于2，则针对每个可能的取值a，根据样本对 k = a 测试的是否将样本分为两类，计算出Gini值和Gini_index，然后选择使Gini_index最小的值作为划分基准；若属性为连续值，参考下一节离散值处理.</p>\n</blockquote>\n<p>在候选属性集合A中，选择哪个使得划分后基尼指数最小的属性作为最优划分属性，即 $a_* = \\arg min_{a\\in{A}}Gini_index(D,a)$.</p>\n<h3 id=\"4-3-剪枝处理（pruning）\"><a href=\"#4-3-剪枝处理（pruning）\" class=\"headerlink\" title=\"4.3 剪枝处理（pruning）\"></a>4.3 剪枝处理（pruning）</h3><p>目的：降低过拟合的风险</p>\n<p>基本策略：预剪枝（prepruning）、后剪枝（post-pruning）</p>\n<blockquote>\n<p>采用留出法，将数据集分为训练集和验证集。</p>\n</blockquote>\n<h4 id=\"4-3-1-预剪枝\"><a href=\"#4-3-1-预剪枝\" class=\"headerlink\" title=\"4.3.1 预剪枝\"></a>4.3.1 预剪枝</h4><p>在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化能力的提升，则停止划分并将当前结点标记为叶结点。</p>\n<ul>\n<li>计算划分前在验证集上的精度S1</li>\n<li>计算划分后在验证集上的精度S2</li>\n<li>若S1 &lt; S2，则划分，反正则不划分，归为叶结点</li>\n</ul>\n<h4 id=\"4-3-2-后剪枝\"><a href=\"#4-3-2-后剪枝\" class=\"headerlink\" title=\"4.3.2 后剪枝\"></a>4.3.2 后剪枝</h4><p>先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树换成叶结点能带来泛化性能提升，则将该字数换成叶结点。</p>\n<ul>\n<li>生成完整决策树，然后自底向上执行下面三步</li>\n<li>计算当前结点在验证集上的精度S1</li>\n<li>计算将当前结点领衔的分支剪除后的精度S2</li>\n<li>若S1 &lt; S2 ，则剪枝（将该结点的分支剪除，替换为叶结点），否则不剪枝</li>\n</ul>\n<h3 id=\"4-4-连续与缺失值\"><a href=\"#4-4-连续与缺失值\" class=\"headerlink\" title=\"4.4 连续与缺失值\"></a>4.4 连续与缺失值</h3><h4 id=\"4-4-1-连续值处理\"><a href=\"#4-4-1-连续值处理\" class=\"headerlink\" title=\"4.4.1 连续值处理\"></a>4.4.1 连续值处理</h4><p>对于连续属性，需要进行离散化。最简单的策略是采用二分法（bi-partition），这正是C4.5决策树算法中采用的机制[Quinlan,1993].</p>\n<blockquote>\n<p>CART决策树算法也采用该方法</p>\n</blockquote>\n<p>给定样本集D和连续属性a，假定a在D上出现n个不同的取值，将这些值从小到大排序，记为${a^1,a^2,…,a^n}$. 基于划分点 t 可将D分为子集$D_t^-$和$D_t^+$，其中$D_t^-$包含那些在属性 a 上取值不大于 t 的样本，而 $D_t^+$ 则包含那些在属性 a 上取值大于 t 的样本。对于连续属性 a，我们可考察包含 n-1 个元素的候选划分点集合</p>\n<script type=\"math/tex; mode=display\">\nT_a = \\left\\{\\frac{a^i+a^{i+1}}{2} | 1 \\le i \\le n-1\\right\\}</script><p>即把区间$[a^i,a^{i+1})$的中位数$\\frac{a^i+a^{i+1}}{2}$作为候选划分点，然后，可以像离散属性值一样来考察这些划分点，选择最优的划分点进行样本集合划分。</p>\n<h4 id=\"4-4-2-缺失值处理\"><a href=\"#4-4-2-缺失值处理\" class=\"headerlink\" title=\"4.4.2 缺失值处理\"></a>4.4.2 缺失值处理</h4><p>针对不完整样本，若样本出现大量缺失，简单的放弃是对数据极大的浪费，因此需要考虑利用有缺失属性值的训练样本。</p>\n<p>给定训练集 D 和属性 a，令 $\\widetilde{D}$  表示 D 中在属性 a 上没有缺失值的样本子集，假定属性 a 有 V 个可取值 ${a^1,a^2,…,a^V}$, 样本有 y 个类，假设我们为每个样本 x 赋予一个权重 $w_x$ ，定义：</p>\n<script type=\"math/tex; mode=display\">\n\\rho=\\frac{\\sum_{x\\in{\\widetilde{D}}}w_x}{\\sum_{x\\in{D}}w_x}\n\\\\\n\\widetilde{p}_k=\\frac{\\sum_{x\\in{\\widetilde{D}_k}}w_x}{\\sum_{x\\in{\\widetilde{D}}}w_x}\n(1\\le k \\le |y|)\n\\\\\n\\rho=\\frac{\\sum_{x\\in{\\widetilde{D}^v}}w_x}{\\sum_{x\\in{\\widetilde{D}}}w_x}\n(1\\le v \\le V)</script><p>对属性a，$\\rho$ 表示无缺失样本所占的比例，$\\widetilde{p}_k$ 表示无缺失样本中第 k 类所占的比例， $\\widetilde{r}_v$ 表示无缺失样本中在属性 a 上取值 $a^v$ 的样本所占的比例，显然：</p>\n<script type=\"math/tex; mode=display\">\n\\sum_{k=1}^{|y|}\\widetilde{p}_k = 1, \\sum_{v=1}^{V}\\widetilde{r}_v=1</script><p>基于上述定义，信息增益计算公式推广为</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\begin{aligned}\nGain(D,a)&=\\rho\\times Gain(\\widetilde{D},a)\n\\\\\n&=\\rho \\times \\left(Ent(\\widetilde{D})-\\sum_{v=1}^V\\widetilde{r}_vEnt(\\widetilde{D}^v)\\right)\n\\end{aligned}\n\\end{equation}</script><p>其中</p>\n<script type=\"math/tex; mode=display\">\nEnt(\\widetilde{D}) = -\\sum_{k=1}^{|y|}\\widetilde{p}_klog_2\\widetilde{p}_k</script><p>若样本 x 在划分属性 a 上的取值已知，则将x划入与其取值对应的子结点，且缺中不变。若样本在属性 a 上<strong>取值未知</strong>，则将 x 同时划分到<strong>所有子结点</strong>，且样本权值在与属性值 $a^v$ 对应的子结点中调整为 $\\widetilde{r}_v\\cdot{w_x}$, 也就是让同一个样本以不同的概率划分到不同的子结点。</p>\n<p>C4.5 算法采用了上述解决方案[Quinlan,1993].</p>\n<h3 id=\"4-5-多变量决策树\"><a href=\"#4-5-多变量决策树\" class=\"headerlink\" title=\"4.5 多变量决策树\"></a>4.5 多变量决策树</h3><p>将每个属性视为坐标空间中的一个坐标轴，则 d 个属性描述的样本就对应了 d 维空间的一个数据点，对样本分类就相当于在这个坐标空间寻找不同类样本的分类边界。传统的单变量决策树形成的分类边界有一个明显的特点：轴平行（axis-parallel），即分类边界是由若干个与坐标轴平行的分段组成。</p>\n<p>若采用斜的划分边界，则决策树模型将会简化，这就是多变量决策树（multivariate decision tree），每个非叶节点就是一个线性分类器。如下图</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-2.png\" alt=\"斜划分边界\"></p>\n<h3 id=\"个人总结\"><a href=\"#个人总结\" class=\"headerlink\" title=\"个人总结\"></a>个人总结</h3><h4 id=\"ID3-ID4-5-CART对比\"><a href=\"#ID3-ID4-5-CART对比\" class=\"headerlink\" title=\"ID3\\ID4.5\\CART对比\"></a>ID3\\ID4.5\\CART对比</h4><p>ID3缺点</p>\n<ul>\n<li>ID3算法不能处理具有连续值的属性（由于ID3以信息增益为准则选择划分属性，对可取值多的属性有所偏好，这样一来，用二分法进行连续属性的离散化处理时，可取值多的属性就越有可能成为分裂属性，而这样其实是没有意义的）</li>\n<li>ID3算法不能处理属性具有缺失值的样本</li>\n<li>算法会生成很深的树，容易产生过拟合现象</li>\n<li>算法一般会优先选择有较多属性值的特征，因为属性值多的特征会有相对较大的信息增益</li>\n</ul>\n<p>ID4.5是对ID3的改进，修正了其对较多属性值的偏好。C4.5还弥补了ID3中不能处理特征属性值连续的问题。但是，其存在如下缺点</p>\n<ul>\n<li>算法低效，在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效</li>\n<li>内存受限，适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行</li>\n</ul>\n<p>CART是二叉树，采用二元切分，即可用于分类也可用于回归。</p>\n","site":{"data":{}},"excerpt":"<p>机器学习——周志华</p>\n<p>读书笔记</p>\n<p>第四章——决策树</p>","more":"<h3 id=\"4-1-基本流程\"><a href=\"#4-1-基本流程\" class=\"headerlink\" title=\"4.1 基本流程\"></a>4.1 基本流程</h3><p>基本思想：分而治之，每次选择最优属性进行划分</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-1.png\" alt=\"算法\"></p>\n<h3 id=\"4-2-划分选择\"><a href=\"#4-2-划分选择\" class=\"headerlink\" title=\"4.2 划分选择\"></a>4.2 划分选择</h3><p>目标：随着划分过程的不断进行，决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度（purity）越来越高。</p>\n<h4 id=\"4-2-1-信息增益（information-gain\"><a href=\"#4-2-1-信息增益（information-gain\" class=\"headerlink\" title=\"4.2.1 信息增益（information gain)\"></a>4.2.1 信息增益（information gain)</h4><p>信息熵（information entropy）：度量样本集合纯度常用指标，熵越小，纯度越高，假定当前集合D中第k类样本所占的比例为 $p_k(k=1,2,…,|y|)$，则D的信息熵定义为</p>\n<script type=\"math/tex; mode=display\">\nEnt(D) = - \\sum_{k=1}^{|y|}p_{k}log{2}p_{k}</script><p>信息增益：可以认为是划分前后的熵差，信息增益越大，则意味划分所获的纯度提升越大，即属性“越好”。假定离散属性 a 有 V 个可能的取值${a_{1},a_{2},…a_{v}}$，若采用 a 对样本集 D 进行划分，则会产生 V 个分支结点，其中第 v 个分支结点包含了 D 中所有在属性 a 上取值为 $a^{v}$ 的样本，记为$D^{v}$，可以计算出$D^{v}$的信息熵，再考虑不同分支结点所包含的样本数不同，给分支结点赋予权重$|D^v|/|D|$，即样本数越多的分支影响越大，于是可计算出用属性 a 对样本集 D 进行划分所获得的信息增益:</p>\n<script type=\"math/tex; mode=display\">\nGain(D,a) = Ent(D) - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}Ent(D^v)</script><p>ID3 决策树学习算法 [Quinlan, 1986]即采用该算法来选择划分属性。</p>\n<h4 id=\"4-2-2-增益率（gain-ratio）\"><a href=\"#4-2-2-增益率（gain-ratio）\" class=\"headerlink\" title=\"4.2.2 增益率（gain ratio）\"></a>4.2.2 增益率（gain ratio）</h4><p>使用信息增益准则的决策树，会对可取值数目较多的属性有所偏好，这种偏好会弱化决策树的泛化能力。</p>\n<p>为了减少这种偏好带来的不利影响，C4.5 决策树算法 [Quinlan, 1986]采用增益率来选择最优划分属性，增益率定义如下：</p>\n<script type=\"math/tex; mode=display\">\nGain\\_ratio(D,a) = \\dfrac{Gain(D,a)}{IV(a)}</script><p>其中</p>\n<script type=\"math/tex; mode=display\">\nIV(a) = - \\sum_{v=1}^{V}\\frac{|D^v|}{|D|}\\log{2}^{\\dfrac{|D^{v}|}{|D|}}</script><p>属于属性 a 的固有值（intrinsic value），属性 a 的取值数目越多，则 IV(a) 越大。</p>\n<p>tips：增益率会对可取值数目较少的属性有所偏好，因此，C4.5算法并不是选择增益率最大的候选划分属性，而是采用启发式[Quinlan, 1993]：</p>\n<ol>\n<li>从候选属性中找出信息增益高于平均的属性组成集合 W</li>\n<li>从 W 中选出增益率最高的作为最优划分属性</li>\n</ol>\n<h4 id=\"4-2-3-基尼指数（Gini-index）\"><a href=\"#4-2-3-基尼指数（Gini-index）\" class=\"headerlink\" title=\"4.2.3 基尼指数（Gini index）\"></a>4.2.3 基尼指数（Gini index）</h4><p>CART 决策树算法[Breiman et al.,1984] 使用基尼系数来选择划分属性，数据集的纯度采用基尼值度量：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\begin{aligned}Gini(D) & = \\sum_{k=1}^{|y|}\\sum_{k^{'}\\not{=}k}{p_{k}p_{k^{'}}}\\\\\n& =1-\\sum_{k=1}^{|y|}p_{k}^{2}\n\\end{aligned}\n\\end{equation}</script><p>Gini(D)越小，数据集D的纯度越高，属性 a 的基尼指数定义为</p>\n<script type=\"math/tex; mode=display\">\nGini\\_index(D,a) = \\sum_{v=1}^{V}\\frac{|D|}{|D^v|}Gini(D^v)</script><blockquote>\n<p>注意：在原书上此部分讲解较少，CART决策树算法采用二分递归分割技术，每次将当前结点分割为两个样本集，最终生成的是一棵二叉树。因此上述的Gini(D)公式的 y = 2：若属性为离散值且可能的取值大于2，则针对每个可能的取值a，根据样本对 k = a 测试的是否将样本分为两类，计算出Gini值和Gini_index，然后选择使Gini_index最小的值作为划分基准；若属性为连续值，参考下一节离散值处理.</p>\n</blockquote>\n<p>在候选属性集合A中，选择哪个使得划分后基尼指数最小的属性作为最优划分属性，即 $a_* = \\arg min_{a\\in{A}}Gini_index(D,a)$.</p>\n<h3 id=\"4-3-剪枝处理（pruning）\"><a href=\"#4-3-剪枝处理（pruning）\" class=\"headerlink\" title=\"4.3 剪枝处理（pruning）\"></a>4.3 剪枝处理（pruning）</h3><p>目的：降低过拟合的风险</p>\n<p>基本策略：预剪枝（prepruning）、后剪枝（post-pruning）</p>\n<blockquote>\n<p>采用留出法，将数据集分为训练集和验证集。</p>\n</blockquote>\n<h4 id=\"4-3-1-预剪枝\"><a href=\"#4-3-1-预剪枝\" class=\"headerlink\" title=\"4.3.1 预剪枝\"></a>4.3.1 预剪枝</h4><p>在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化能力的提升，则停止划分并将当前结点标记为叶结点。</p>\n<ul>\n<li>计算划分前在验证集上的精度S1</li>\n<li>计算划分后在验证集上的精度S2</li>\n<li>若S1 &lt; S2，则划分，反正则不划分，归为叶结点</li>\n</ul>\n<h4 id=\"4-3-2-后剪枝\"><a href=\"#4-3-2-后剪枝\" class=\"headerlink\" title=\"4.3.2 后剪枝\"></a>4.3.2 后剪枝</h4><p>先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树换成叶结点能带来泛化性能提升，则将该字数换成叶结点。</p>\n<ul>\n<li>生成完整决策树，然后自底向上执行下面三步</li>\n<li>计算当前结点在验证集上的精度S1</li>\n<li>计算将当前结点领衔的分支剪除后的精度S2</li>\n<li>若S1 &lt; S2 ，则剪枝（将该结点的分支剪除，替换为叶结点），否则不剪枝</li>\n</ul>\n<h3 id=\"4-4-连续与缺失值\"><a href=\"#4-4-连续与缺失值\" class=\"headerlink\" title=\"4.4 连续与缺失值\"></a>4.4 连续与缺失值</h3><h4 id=\"4-4-1-连续值处理\"><a href=\"#4-4-1-连续值处理\" class=\"headerlink\" title=\"4.4.1 连续值处理\"></a>4.4.1 连续值处理</h4><p>对于连续属性，需要进行离散化。最简单的策略是采用二分法（bi-partition），这正是C4.5决策树算法中采用的机制[Quinlan,1993].</p>\n<blockquote>\n<p>CART决策树算法也采用该方法</p>\n</blockquote>\n<p>给定样本集D和连续属性a，假定a在D上出现n个不同的取值，将这些值从小到大排序，记为${a^1,a^2,…,a^n}$. 基于划分点 t 可将D分为子集$D_t^-$和$D_t^+$，其中$D_t^-$包含那些在属性 a 上取值不大于 t 的样本，而 $D_t^+$ 则包含那些在属性 a 上取值大于 t 的样本。对于连续属性 a，我们可考察包含 n-1 个元素的候选划分点集合</p>\n<script type=\"math/tex; mode=display\">\nT_a = \\left\\{\\frac{a^i+a^{i+1}}{2} | 1 \\le i \\le n-1\\right\\}</script><p>即把区间$[a^i,a^{i+1})$的中位数$\\frac{a^i+a^{i+1}}{2}$作为候选划分点，然后，可以像离散属性值一样来考察这些划分点，选择最优的划分点进行样本集合划分。</p>\n<h4 id=\"4-4-2-缺失值处理\"><a href=\"#4-4-2-缺失值处理\" class=\"headerlink\" title=\"4.4.2 缺失值处理\"></a>4.4.2 缺失值处理</h4><p>针对不完整样本，若样本出现大量缺失，简单的放弃是对数据极大的浪费，因此需要考虑利用有缺失属性值的训练样本。</p>\n<p>给定训练集 D 和属性 a，令 $\\widetilde{D}$  表示 D 中在属性 a 上没有缺失值的样本子集，假定属性 a 有 V 个可取值 ${a^1,a^2,…,a^V}$, 样本有 y 个类，假设我们为每个样本 x 赋予一个权重 $w_x$ ，定义：</p>\n<script type=\"math/tex; mode=display\">\n\\rho=\\frac{\\sum_{x\\in{\\widetilde{D}}}w_x}{\\sum_{x\\in{D}}w_x}\n\\\\\n\\widetilde{p}_k=\\frac{\\sum_{x\\in{\\widetilde{D}_k}}w_x}{\\sum_{x\\in{\\widetilde{D}}}w_x}\n(1\\le k \\le |y|)\n\\\\\n\\rho=\\frac{\\sum_{x\\in{\\widetilde{D}^v}}w_x}{\\sum_{x\\in{\\widetilde{D}}}w_x}\n(1\\le v \\le V)</script><p>对属性a，$\\rho$ 表示无缺失样本所占的比例，$\\widetilde{p}_k$ 表示无缺失样本中第 k 类所占的比例， $\\widetilde{r}_v$ 表示无缺失样本中在属性 a 上取值 $a^v$ 的样本所占的比例，显然：</p>\n<script type=\"math/tex; mode=display\">\n\\sum_{k=1}^{|y|}\\widetilde{p}_k = 1, \\sum_{v=1}^{V}\\widetilde{r}_v=1</script><p>基于上述定义，信息增益计算公式推广为</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\begin{aligned}\nGain(D,a)&=\\rho\\times Gain(\\widetilde{D},a)\n\\\\\n&=\\rho \\times \\left(Ent(\\widetilde{D})-\\sum_{v=1}^V\\widetilde{r}_vEnt(\\widetilde{D}^v)\\right)\n\\end{aligned}\n\\end{equation}</script><p>其中</p>\n<script type=\"math/tex; mode=display\">\nEnt(\\widetilde{D}) = -\\sum_{k=1}^{|y|}\\widetilde{p}_klog_2\\widetilde{p}_k</script><p>若样本 x 在划分属性 a 上的取值已知，则将x划入与其取值对应的子结点，且缺中不变。若样本在属性 a 上<strong>取值未知</strong>，则将 x 同时划分到<strong>所有子结点</strong>，且样本权值在与属性值 $a^v$ 对应的子结点中调整为 $\\widetilde{r}_v\\cdot{w_x}$, 也就是让同一个样本以不同的概率划分到不同的子结点。</p>\n<p>C4.5 算法采用了上述解决方案[Quinlan,1993].</p>\n<h3 id=\"4-5-多变量决策树\"><a href=\"#4-5-多变量决策树\" class=\"headerlink\" title=\"4.5 多变量决策树\"></a>4.5 多变量决策树</h3><p>将每个属性视为坐标空间中的一个坐标轴，则 d 个属性描述的样本就对应了 d 维空间的一个数据点，对样本分类就相当于在这个坐标空间寻找不同类样本的分类边界。传统的单变量决策树形成的分类边界有一个明显的特点：轴平行（axis-parallel），即分类边界是由若干个与坐标轴平行的分段组成。</p>\n<p>若采用斜的划分边界，则决策树模型将会简化，这就是多变量决策树（multivariate decision tree），每个非叶节点就是一个线性分类器。如下图</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-2.png\" alt=\"斜划分边界\"></p>\n<h3 id=\"个人总结\"><a href=\"#个人总结\" class=\"headerlink\" title=\"个人总结\"></a>个人总结</h3><h4 id=\"ID3-ID4-5-CART对比\"><a href=\"#ID3-ID4-5-CART对比\" class=\"headerlink\" title=\"ID3\\ID4.5\\CART对比\"></a>ID3\\ID4.5\\CART对比</h4><p>ID3缺点</p>\n<ul>\n<li>ID3算法不能处理具有连续值的属性（由于ID3以信息增益为准则选择划分属性，对可取值多的属性有所偏好，这样一来，用二分法进行连续属性的离散化处理时，可取值多的属性就越有可能成为分裂属性，而这样其实是没有意义的）</li>\n<li>ID3算法不能处理属性具有缺失值的样本</li>\n<li>算法会生成很深的树，容易产生过拟合现象</li>\n<li>算法一般会优先选择有较多属性值的特征，因为属性值多的特征会有相对较大的信息增益</li>\n</ul>\n<p>ID4.5是对ID3的改进，修正了其对较多属性值的偏好。C4.5还弥补了ID3中不能处理特征属性值连续的问题。但是，其存在如下缺点</p>\n<ul>\n<li>算法低效，在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效</li>\n<li>内存受限，适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行</li>\n</ul>\n<p>CART是二叉树，采用二元切分，即可用于分类也可用于回归。</p>"},{"title":"链表考点剖析","date":"2017-10-30T07:20:06.000Z","_content":"\n链表，最为基础的数据结构，同时也是面试中最容易出现的考察点。很多人都觉得链表如此简单，以至于在面试不断的深入考察中出现纰漏。一旦在链表上出现差错，那么也意味着你基础的羸弱，直接导致面试的失败。\n\n在大三一年实习和后来校招的面试中，遇到了不下于五次链表的题目，题目有难有易，很难保证第一次接触能够完美的给出解答。因此总结了链表相关题目和解法，如有补充请留言。\n\n<!--more-->\n\n### 定义\n\n全文的链表节点定义如下，无哑节点，基于C++实现。\n\n```c++\nstruct ListNode\n{\n\tint m_nKey;\n\tListNode * m_pNext;\n};\n```\n\n### 题目\n\n#### 求节点数目\n\n最基础的题目，直接遍历，注意循环停止条件。\n\n```c++\nunsigned int GetThisLength(ListNode *pHead)\n{\n\tif (pHead == NULL)\n\t\treturn 0;\n\tListNode *pCurrent = pHead;\n\tunsigned int nlength = 0;\n\twhile (pCurrent != NULL)\n\t{\n\t\tnlength++;\n\t\tpCurrent = pCurrent->m_pNext;\n\t}\n\treturn nlength;\n}\n```\n\n#### 反转链表\n\n一道非常经典的面试题，简单的同时也非常容易出错，分为递归和非递归解法。\n\n递归解法：每次递归返回的是已经反转好的链表的头结点，注意好跳出条件即可。\n\n非递归解法：遍历链表，已遍历的部分已反转，将正在遍历的节点当做头结点连接到已反转的部分。\n\n```c++\n//递归解法\nListNode * ReverseList(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *newHead = ReverseList(pHead->next);\n  \tpHead->next->next = newHead->next;\n  \tpHead->next = NULL;\n\treturn newHead;\n}\n\n//非递归解法\nListNode * ReverseList(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *pReverseHead = NULL;\n\tListNode *pCurrent = pHead;\n\twhile (pCurrent != NULL)\n\t{\n\t\tListNode *temp = pCurrent;\n\t\tpCurrent = pCurrent->m_pNext;\n\t\ttemp->m_pNext = pReverseHead;\n\t\tpReverseHead = temp;\n\t}\n\treturn pReverseHead;\n}\n```\n\n#### 找倒数第k个节点\n\n双指针解题，这中思考方式在后面的题目经常出现。第一个指针先走k步，然后两个指针一起遍历，这样第一个指针到最后一个节点的时候，第二个指针即指向第k个节点。\n\n```c++\nListNode * RGetKthNode(ListNode * pHead, unsigned int k)\n{\n\tif (k == 0 || pHead == NULL)\n\t\treturn NULL;\n\tListNode *pAhead = pHead;\n\tListNode *pBehind = pHead;\n\twhile (pAhead != NULL&&k > 1)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tk--;\n\t}\n\tif (k > 1 || pAhead == NULL)\n\t\treturn NULL;\n\twhile (pAhead->m_pNext != NULL)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tpBehind = pBehind->m_pNext;\n\t}\n}\n```\n\n#### 查找中间节点\n\n无需先获取长度，只需要一次遍历即可解决问题，和上一题类似思路，两个指针，分别为“快”指针和“慢”指针。快指针每次“走两步”，慢指针每次”走一步“，这样快指针走过的节点始终是慢指针的两倍。快指针到尾节点时，返回慢指针即可。\n\n```C++\nListNode * GetMiddleNode(ListNode * pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *pAhead = pHead;\n\tListNode *pBehind = pHead;\n\twhile (pAhead->m_pNext != NULL)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tpBehind = pBehind->m_pNext;\n\t\tif (pAhead->m_pNext != NULL)\n\t\t\tpAhead = pAhead->m_pNext;\n\t}\n\treturn pBehind;\n}\n```\n\n#### 倒序打印链表\n\n借助栈实现，遍历时将节点值存储到栈中。\n\n```c++\nvoid PrintList(ListNode *pHead)\n{\n\tstack<ListNode *> s;\n\twhile (pHead != NULL)\n\t{\n\t\ts.push(pHead);\n\t\tpHead = pHead->m_pNext;\n\t}\n\twhile (!s.empty())\n\t{\n\t\tcout << s.top() << \"\\t\";\n\t\ts.pop();\n\t}\n}\n```\n\n#### 合并两个链表\n\n遍历对比节点值，直接合并。\n\n```c++\nListNode *MergeSortedLit(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL)\n\t\treturn pHead1;\n\tif (pHead2 == NULL)\n\t\treturn pHead2;\n\tListNode *pHeadMerged = NULL;\n\tif (pHead1->m_nKey < pHead2->m_nKey)\n\t{\n\t\tpHeadMerged = pHead1;\n\t\t//pHeadMerged->m_pNext = NULL;\n\t\tpHead1 = pHead1->m_pNext;\n\t}\n\telse\n\t{\n\t\tpHeadMerged = pHead2;\n\t\t//pHeadMerged->m_pNext = NULL;\n\t\tpHead2 = pHead2->m_pNext;\n\t}\n\tListNode *pTemp = pHeadMerged;\n\twhile (pHead1 != NULL && pHead2 != NULL)\n\t{\n\t\tif (pHead1->m_nKey < pHead2->m_nKey)\n\t\t{\n\t\t\tpTemp->m_pNext = pHead1;\n\t\t\tpHead1 = pHead1->m_pNext;\n\t\t\tpTemp = pTemp->m_pNext;\n\t\t\t//pTemp->m_pNext = NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpTemp->m_pNext = pHead2;\n\t\t\tpHead2 = pHead2->m_pNext;\n\t\t\tpTemp = pTemp->m_pNext;\n\t\t\t//pTemp->m_pNext = NULL;\n\t\t}\n\t}\n\tif (pHead1 != NULL)\n\t\tpTemp->m_pNext = pHead1;\n\telse if (pHead2 != NULL)\n\t\tpTemp->m_pNext = pHead2;\n\treturn pHeadMerged;\n}\n```\n\n#### 判断单链表是否有环\n\n注意该链表有可能是首尾相接，也可能是只有后面一段是环。\n\n经典的快慢指针解题思路，快指针每次走两步，慢指针每次走一步。如果快慢指针相遇则存在环，否则不存在环。\n\n```c++\nbool HasCircle(ListNode *pHead)\n{\n\tListNode *pFast = pHead;\n\tListNode *pSlow = pHead;\n\twhile (pFast != NULL&&pFast->m_pNext != NULL)\n\t{\n\t\tpFast = pFast->m_pNext->m_pNext;\n\t\tpSlow = pSlow->m_pNext;\n\t\tif (pFast == pSlow)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n```\n\n#### 判断两个链表是否相交\n\n如果两个链表相交，那么他们在相交点之后必定成为同一条链表，所以只需要判断两个链表的尾节点是否相同即可。\n\n```c++\nbool IsIntersected(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL&&pHead2 == NULL)\n\t\treturn false;\n\twhile (pHead1->m_pNext != NULL)\n\t\tpHead1 = pHead1->m_pNext;\n\twhile (pHead2->m_pNext != NULL)\n\t\tpHead2 = pHead2->m_pNext;\n\treturn pHead1 == pHead2;\n}\n```\n\n#### 求两个单链表相交的第一个节点\n\n先获取两个链表的长度，然后获取长度差值len，双指针策略，较长的链表的指针先走len步，然后两个指针一起遍历，相遇即跳出，跳出点即相交的第一个节点。\n\n```c++\nListNode * GetFirstCommonNode(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL || pHead2 == NULL)\n\t\treturn NULL;\n\tint len1 = 1;\n\tListNode *pTail1 = pHead1;\n\twhile (pTail1->m_pNext != NULL)\n\t{\n\t\tlen1++;\n\t\tpTail1 = pTail1->m_pNext;\n\t}\n\tint len2 = 1;\n\tListNode *pTail2 = pHead2;\n\twhile (pTail1->m_pNext != NULL)\n\t{\n\t\tlen2++;\n\t\tpTail2 = pTail2->m_pNext;\n\t}\n\tif (pTail1 != pTail2)\n\t\treturn NULL;\n\tListNode * pNode1 = pHead1;\n\tListNode * pNode2 = pHead2;\n\tif (len1 > len2)\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\telse\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\twhile (pNode1!=pNode2)\n\t{\n\t\tpNode1 = pNode1->m_pNext;\n\t\tpNode2 = pNode2->m_pNext;\n\t}\n\treturn pNode1;\n}\n```\n\n#### 已知有环，求入环后第一个节点\n\n这题将**判断链表是否有环**和**求两个单链表相交的第一个节点**相结合，在快慢指针相遇点断开成两条新的链表，之后两个链表相交的第一个节点就是两个单链表相交的第一个节点。\n\n参考图\n\n![](http://oygov02sc.bkt.clouddn.com/%E9%93%BE%E8%A1%A8%E8%80%83%E7%82%B9%E5%89%96%E6%9E%90-1.png)\n\n```c++\nListNode * GetFirstNodeInCycle(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn NULL;\n\tListNode *pFast = pHead;\n\tListNode *pSlow = pHead;\n\twhile (pFast != NULL&&pFast->m_pNext != NULL)\n\t{\n\t\tpFast = pFast->m_pNext->m_pNext;\n\t\tpSlow = pSlow->m_pNext;\n\t\tif (pFast == pSlow)\n\t\t\tbreak;\n\t}\n\tif (pFast == NULL || pFast->m_pNext == NULL)\n\t\treturn NULL;\n\tListNode *pAssumedTail = pFast;\n\tListNode *pHead1 = pHead;\n\tListNode *pHead2 = pAssumedTail->m_pNext;\n\tListNode *pNode1 = pHead1;\n\tint len1 = 1;\n\twhile (pNode1 != pAssumedTail)\n\t{\n\t\tlen1++;\n\t\tpNode1 = pNode1->m_pNext;\n\t}\n\tListNode *pNode2 = pHead2;\n\tint len2 = 1;\n\twhile (pNode2 != pAssumedTail)\n\t{\n\t\tlen2++;\n\t\tpNode1 = pNode2->m_pNext;\n\t}\n\tif (len1 > len2)\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\telse\n\t{\n\t\tint k = len2 - len1;\n\t\twhile (k--)\n\t\t\tpNode2 = pNode2->m_pNext;\n\t}\n\twhile (pNode1 != pNode2)\n\t{\n\t\tpNode1 = pNode1->m_pNext;\n\t\tpNode2 = pNode2->m_pNext;\n\t}\n\treturn pNode1;\n}\n```\n\n#### O(1)删除一个节点\n\n一般来说删除一个节点的时间复杂度是O(n)，此处的删除是一种投机的方法，将待删除的节点的下一个节点的值赋予当前节点，然后删除下一个节点。当然如果需要删除的节点是尾节点，还是需要遍历才能删除。\n\n```C++\nvoid DeleteNode(ListNode *pHead, ListNode *pToBeDeleted)\n{\n\tif (pToBeDeleted == NULL)\n\t\treturn;\n\tif (pToBeDeleted->m_pNext != NULL)\n\t{\n\t\tListNode *pNext = pToBeDeleted->m_pNext;\n\t\tpToBeDeleted->m_nKey = pNext->m_nKey;\n\t\tpToBeDeleted->m_pNext = pNext->m_pNext;\n\t\tdelete pNext;\n\t\tpNext = NULL;\n\t}\n\telse\n\t{\n\t\tif (pHead == pToBeDeleted)\n\t\t{\n\t\t\tdelete pToBeDeleted;\n\t\t\tpHead = NULL;\n\t\t\tpToBeDeleted = NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tListNode *pTemp = pHead;\n\t\t\twhile (pTemp->m_pNext != pToBeDeleted)\n\t\t\t\tpTemp = pTemp->m_pNext;\n\t\t\tdelete pToBeDeleted;\n\t\t\tpTemp->m_pNext = NULL;\n\t\t\tpToBeDeleted = NULL;\n\t\t}\n\t}\n}\n```\n\n### 考点\n\n考点多集中在双指针，快慢指针，遍历等方面。在设计链表题目时，切记要考虑空链表，遍历跳出点以及该链表是否存在哑结点。在做题前需要向面试官询问，并在代码中恰当处理，否则很容易出错。\n\n### 附录\n\n全部代码\n\n```c++\n#include<iostream>\n#include<stack>\nusing namespace std;\n\nstruct ListNode\n{\n\tint m_nKey;\n\tListNode * m_pNext;\n};\n\nint main()\n{\n\treturn 0;\n}\n\n//求节点个数\nunsigned int GetThisLength(ListNode *pHead)\n{\n\tif (pHead == NULL)\n\t\treturn 0;\n\tListNode *pCurrent = pHead;\n\tunsigned int nlength = 0;\n\twhile (pCurrent != NULL)\n\t{\n\t\tnlength++;\n\t\tpCurrent = pCurrent->m_pNext;\n\t}\n\treturn nlength;\n}\n\n//反转链表\nListNode * ReverseList(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *pReverseHead = NULL;\n\tListNode *pCurrent = pHead;\n\twhile (pCurrent != NULL)\n\t{\n\t\tListNode *temp = pCurrent;\n\t\tpCurrent = pCurrent->m_pNext;\n\t\ttemp->m_pNext = pReverseHead;\n\t\tpReverseHead = temp;\n\t}\n\treturn pReverseHead;\n}\nListNode * ReverseList(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *newHead = ReverseList(pHead->next);\n  \tpHead->next->next = newHead->next;\n  \tpHead->next = NULL;\n\treturn pReverseHead;\n}\n\n//找倒数第k个节点\nListNode * RGetKthNode(ListNode * pHead, unsigned int k)\n{\n\tif (k == 0 || pHead == NULL)\n\t\treturn NULL;\n\tListNode *pAhead = pHead;\n\tListNode *pBehind = pHead;\n\twhile (pAhead != NULL&&k > 1)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tk--;\n\t}\n\tif (k > 1 || pAhead == NULL)\n\t\treturn NULL;\n\twhile (pAhead->m_pNext != NULL)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tpBehind = pBehind->m_pNext;\n\t}\n}\n\n//查找中间结点\nListNode * GetMiddleNode(ListNode * pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *pAhead = pHead;\n\tListNode *pBehind = pHead;\n\twhile (pAhead->m_pNext != NULL)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tpBehind = pBehind->m_pNext;\n\t\tif (pAhead->m_pNext != NULL)\n\t\t\tpAhead = pAhead->m_pNext;\n\t}\n\treturn pBehind;\n}\n\n//倒序打印链表\nvoid PrintList(ListNode *pHead)\n{\n\tstack<ListNode *> s;\n\twhile (pHead != NULL)\n\t{\n\t\ts.push(pHead);\n\t\tpHead = pHead->m_pNext;\n\t}\n\twhile (!s.empty())\n\t{\n\t\tcout << s.top() << \"\\t\";\n\t\ts.pop();\n\t}\n}\n\n//合并两个链表\nListNode *MergeSortedLit(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL)\n\t\treturn pHead1;\n\tif (pHead2 == NULL)\n\t\treturn pHead2;\n\tListNode *pHeadMerged = NULL;\n\tif (pHead1->m_nKey < pHead2->m_nKey)\n\t{\n\t\tpHeadMerged = pHead1;\n\t\t//pHeadMerged->m_pNext = NULL;\n\t\tpHead1 = pHead1->m_pNext;\n\t}\n\telse\n\t{\n\t\tpHeadMerged = pHead2;\n\t\t//pHeadMerged->m_pNext = NULL;\n\t\tpHead2 = pHead2->m_pNext;\n\t}\n\tListNode *pTemp = pHeadMerged;\n\twhile (pHead1 != NULL && pHead2 != NULL)\n\t{\n\t\tif (pHead1->m_nKey < pHead2->m_nKey)\n\t\t{\n\t\t\tpTemp->m_pNext = pHead1;\n\t\t\tpHead1 = pHead1->m_pNext;\n\t\t\tpTemp = pTemp->m_pNext;\n\t\t\t//pTemp->m_pNext = NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpTemp->m_pNext = pHead2;\n\t\t\tpHead2 = pHead2->m_pNext;\n\t\t\tpTemp = pTemp->m_pNext;\n\t\t\t//pTemp->m_pNext = NULL;\n\t\t}\n\t}\n\tif (pHead1 != NULL)\n\t\tpTemp->m_pNext = pHead1;\n\telse if (pHead2 != NULL)\n\t\tpTemp->m_pNext = pHead2;\n\treturn pHeadMerged;\n}\n\n//判断单链表是否有环\nbool HasCircle(ListNode *pHead)\n{\n\tListNode *pFast = pHead;\n\tListNode *pSlow = pHead;\n\twhile (pFast != NULL&&pFast->m_pNext != NULL)\n\t{\n\t\tpFast = pFast->m_pNext->m_pNext;\n\t\tpSlow = pSlow->m_pNext;\n\t\tif (pFast == pSlow)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n//判断两个链表是否相交\nbool IsIntersected(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL&&pHead2 == NULL)\n\t\treturn false;\n\twhile (pHead1->m_pNext != NULL)\n\t\tpHead1 = pHead1->m_pNext;\n\twhile (pHead2->m_pNext != NULL)\n\t\tpHead2 = pHead2->m_pNext;\n\treturn pHead1 == pHead2;\n}\n\n//求两个单链表相交的第一个节点\nListNode * GetFirstCommonNode(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL || pHead2 == NULL)\n\t\treturn NULL;\n\tint len1 = 1;\n\tListNode *pTail1 = pHead1;\n\twhile (pTail1->m_pNext != NULL)\n\t{\n\t\tlen1++;\n\t\tpTail1 = pTail1->m_pNext;\n\t}\n\tint len2 = 1;\n\tListNode *pTail2 = pHead2;\n\twhile (pTail1->m_pNext != NULL)\n\t{\n\t\tlen2++;\n\t\tpTail2 = pTail2->m_pNext;\n\t}\n\tif (pTail1 != pTail2)\n\t\treturn NULL;\n\tListNode * pNode1 = pHead1;\n\tListNode * pNode2 = pHead2;\n\tif (len1 > len2)\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\telse\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\twhile (pNode1!=pNode2)\n\t{\n\t\tpNode1 = pNode1->m_pNext;\n\t\tpNode2 = pNode2->m_pNext;\n\t}\n\treturn pNode1;\n}\n\n//已知有环，求入环后第一个节点\nListNode * GetFirstNodeInCycle(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn NULL;\n\tListNode *pFast = pHead;\n\tListNode *pSlow = pHead;\n\twhile (pFast != NULL&&pFast->m_pNext != NULL)\n\t{\n\t\tpFast = pFast->m_pNext->m_pNext;\n\t\tpSlow = pSlow->m_pNext;\n\t\tif (pFast == pSlow)\n\t\t\tbreak;\n\t}\n\tif (pFast == NULL || pFast->m_pNext == NULL)\n\t\treturn NULL;\n\tListNode *pAssumedTail = pFast;\n\tListNode *pHead1 = pHead;\n\tListNode *pHead2 = pAssumedTail->m_pNext;\n\tListNode *pNode1 = pHead1;\n\tint len1 = 1;\n\twhile (pNode1 != pAssumedTail)\n\t{\n\t\tlen1++;\n\t\tpNode1 = pNode1->m_pNext;\n\t}\n\tListNode *pNode2 = pHead2;\n\tint len2 = 1;\n\twhile (pNode2 != pAssumedTail)\n\t{\n\t\tlen2++;\n\t\tpNode1 = pNode2->m_pNext;\n\t}\n\tif (len1 > len2)\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\telse\n\t{\n\t\tint k = len2 - len1;\n\t\twhile (k--)\n\t\t\tpNode2 = pNode2->m_pNext;\n\t}\n\twhile (pNode1 != pNode2)\n\t{\n\t\tpNode1 = pNode1->m_pNext;\n\t\tpNode2 = pNode2->m_pNext;\n\t}\n\treturn pNode1;\n}\n\n//O(1)删除一个节点\nvoid DeleteNode(ListNode *pHead, ListNode *pToBeDeleted)\n{\n\tif (pToBeDeleted == NULL)\n\t\treturn;\n\tif (pToBeDeleted->m_pNext != NULL)\n\t{\n\t\tListNode *pNext = pToBeDeleted->m_pNext;\n\t\tpToBeDeleted->m_nKey = pNext->m_nKey;\n\t\tpToBeDeleted->m_pNext = pNext->m_pNext;\n\t\tdelete pNext;\n\t\tpNext = NULL;\n\t}\n\telse\n\t{\n\t\tif (pHead == pToBeDeleted)\n\t\t{\n\t\t\tdelete pToBeDeleted;\n\t\t\tpHead = NULL;\n\t\t\tpToBeDeleted = NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tListNode *pTemp = pHead;\n\t\t\twhile (pTemp->m_pNext != pToBeDeleted)\n\t\t\t\tpTemp = pTemp->m_pNext;\n\t\t\tdelete pToBeDeleted;\n\t\t\tpTemp->m_pNext = NULL;\n\t\t\tpToBeDeleted = NULL;\n\t\t}\n\t}\n}\n```\n\n","source":"_posts/链表考点剖析.md","raw":"---\ntitle: 链表考点剖析\ndate: 2017-10-30 15:20:06\ntags: 面试\ncategories: 笔试面试\n---\n\n链表，最为基础的数据结构，同时也是面试中最容易出现的考察点。很多人都觉得链表如此简单，以至于在面试不断的深入考察中出现纰漏。一旦在链表上出现差错，那么也意味着你基础的羸弱，直接导致面试的失败。\n\n在大三一年实习和后来校招的面试中，遇到了不下于五次链表的题目，题目有难有易，很难保证第一次接触能够完美的给出解答。因此总结了链表相关题目和解法，如有补充请留言。\n\n<!--more-->\n\n### 定义\n\n全文的链表节点定义如下，无哑节点，基于C++实现。\n\n```c++\nstruct ListNode\n{\n\tint m_nKey;\n\tListNode * m_pNext;\n};\n```\n\n### 题目\n\n#### 求节点数目\n\n最基础的题目，直接遍历，注意循环停止条件。\n\n```c++\nunsigned int GetThisLength(ListNode *pHead)\n{\n\tif (pHead == NULL)\n\t\treturn 0;\n\tListNode *pCurrent = pHead;\n\tunsigned int nlength = 0;\n\twhile (pCurrent != NULL)\n\t{\n\t\tnlength++;\n\t\tpCurrent = pCurrent->m_pNext;\n\t}\n\treturn nlength;\n}\n```\n\n#### 反转链表\n\n一道非常经典的面试题，简单的同时也非常容易出错，分为递归和非递归解法。\n\n递归解法：每次递归返回的是已经反转好的链表的头结点，注意好跳出条件即可。\n\n非递归解法：遍历链表，已遍历的部分已反转，将正在遍历的节点当做头结点连接到已反转的部分。\n\n```c++\n//递归解法\nListNode * ReverseList(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *newHead = ReverseList(pHead->next);\n  \tpHead->next->next = newHead->next;\n  \tpHead->next = NULL;\n\treturn newHead;\n}\n\n//非递归解法\nListNode * ReverseList(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *pReverseHead = NULL;\n\tListNode *pCurrent = pHead;\n\twhile (pCurrent != NULL)\n\t{\n\t\tListNode *temp = pCurrent;\n\t\tpCurrent = pCurrent->m_pNext;\n\t\ttemp->m_pNext = pReverseHead;\n\t\tpReverseHead = temp;\n\t}\n\treturn pReverseHead;\n}\n```\n\n#### 找倒数第k个节点\n\n双指针解题，这中思考方式在后面的题目经常出现。第一个指针先走k步，然后两个指针一起遍历，这样第一个指针到最后一个节点的时候，第二个指针即指向第k个节点。\n\n```c++\nListNode * RGetKthNode(ListNode * pHead, unsigned int k)\n{\n\tif (k == 0 || pHead == NULL)\n\t\treturn NULL;\n\tListNode *pAhead = pHead;\n\tListNode *pBehind = pHead;\n\twhile (pAhead != NULL&&k > 1)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tk--;\n\t}\n\tif (k > 1 || pAhead == NULL)\n\t\treturn NULL;\n\twhile (pAhead->m_pNext != NULL)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tpBehind = pBehind->m_pNext;\n\t}\n}\n```\n\n#### 查找中间节点\n\n无需先获取长度，只需要一次遍历即可解决问题，和上一题类似思路，两个指针，分别为“快”指针和“慢”指针。快指针每次“走两步”，慢指针每次”走一步“，这样快指针走过的节点始终是慢指针的两倍。快指针到尾节点时，返回慢指针即可。\n\n```C++\nListNode * GetMiddleNode(ListNode * pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *pAhead = pHead;\n\tListNode *pBehind = pHead;\n\twhile (pAhead->m_pNext != NULL)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tpBehind = pBehind->m_pNext;\n\t\tif (pAhead->m_pNext != NULL)\n\t\t\tpAhead = pAhead->m_pNext;\n\t}\n\treturn pBehind;\n}\n```\n\n#### 倒序打印链表\n\n借助栈实现，遍历时将节点值存储到栈中。\n\n```c++\nvoid PrintList(ListNode *pHead)\n{\n\tstack<ListNode *> s;\n\twhile (pHead != NULL)\n\t{\n\t\ts.push(pHead);\n\t\tpHead = pHead->m_pNext;\n\t}\n\twhile (!s.empty())\n\t{\n\t\tcout << s.top() << \"\\t\";\n\t\ts.pop();\n\t}\n}\n```\n\n#### 合并两个链表\n\n遍历对比节点值，直接合并。\n\n```c++\nListNode *MergeSortedLit(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL)\n\t\treturn pHead1;\n\tif (pHead2 == NULL)\n\t\treturn pHead2;\n\tListNode *pHeadMerged = NULL;\n\tif (pHead1->m_nKey < pHead2->m_nKey)\n\t{\n\t\tpHeadMerged = pHead1;\n\t\t//pHeadMerged->m_pNext = NULL;\n\t\tpHead1 = pHead1->m_pNext;\n\t}\n\telse\n\t{\n\t\tpHeadMerged = pHead2;\n\t\t//pHeadMerged->m_pNext = NULL;\n\t\tpHead2 = pHead2->m_pNext;\n\t}\n\tListNode *pTemp = pHeadMerged;\n\twhile (pHead1 != NULL && pHead2 != NULL)\n\t{\n\t\tif (pHead1->m_nKey < pHead2->m_nKey)\n\t\t{\n\t\t\tpTemp->m_pNext = pHead1;\n\t\t\tpHead1 = pHead1->m_pNext;\n\t\t\tpTemp = pTemp->m_pNext;\n\t\t\t//pTemp->m_pNext = NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpTemp->m_pNext = pHead2;\n\t\t\tpHead2 = pHead2->m_pNext;\n\t\t\tpTemp = pTemp->m_pNext;\n\t\t\t//pTemp->m_pNext = NULL;\n\t\t}\n\t}\n\tif (pHead1 != NULL)\n\t\tpTemp->m_pNext = pHead1;\n\telse if (pHead2 != NULL)\n\t\tpTemp->m_pNext = pHead2;\n\treturn pHeadMerged;\n}\n```\n\n#### 判断单链表是否有环\n\n注意该链表有可能是首尾相接，也可能是只有后面一段是环。\n\n经典的快慢指针解题思路，快指针每次走两步，慢指针每次走一步。如果快慢指针相遇则存在环，否则不存在环。\n\n```c++\nbool HasCircle(ListNode *pHead)\n{\n\tListNode *pFast = pHead;\n\tListNode *pSlow = pHead;\n\twhile (pFast != NULL&&pFast->m_pNext != NULL)\n\t{\n\t\tpFast = pFast->m_pNext->m_pNext;\n\t\tpSlow = pSlow->m_pNext;\n\t\tif (pFast == pSlow)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n```\n\n#### 判断两个链表是否相交\n\n如果两个链表相交，那么他们在相交点之后必定成为同一条链表，所以只需要判断两个链表的尾节点是否相同即可。\n\n```c++\nbool IsIntersected(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL&&pHead2 == NULL)\n\t\treturn false;\n\twhile (pHead1->m_pNext != NULL)\n\t\tpHead1 = pHead1->m_pNext;\n\twhile (pHead2->m_pNext != NULL)\n\t\tpHead2 = pHead2->m_pNext;\n\treturn pHead1 == pHead2;\n}\n```\n\n#### 求两个单链表相交的第一个节点\n\n先获取两个链表的长度，然后获取长度差值len，双指针策略，较长的链表的指针先走len步，然后两个指针一起遍历，相遇即跳出，跳出点即相交的第一个节点。\n\n```c++\nListNode * GetFirstCommonNode(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL || pHead2 == NULL)\n\t\treturn NULL;\n\tint len1 = 1;\n\tListNode *pTail1 = pHead1;\n\twhile (pTail1->m_pNext != NULL)\n\t{\n\t\tlen1++;\n\t\tpTail1 = pTail1->m_pNext;\n\t}\n\tint len2 = 1;\n\tListNode *pTail2 = pHead2;\n\twhile (pTail1->m_pNext != NULL)\n\t{\n\t\tlen2++;\n\t\tpTail2 = pTail2->m_pNext;\n\t}\n\tif (pTail1 != pTail2)\n\t\treturn NULL;\n\tListNode * pNode1 = pHead1;\n\tListNode * pNode2 = pHead2;\n\tif (len1 > len2)\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\telse\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\twhile (pNode1!=pNode2)\n\t{\n\t\tpNode1 = pNode1->m_pNext;\n\t\tpNode2 = pNode2->m_pNext;\n\t}\n\treturn pNode1;\n}\n```\n\n#### 已知有环，求入环后第一个节点\n\n这题将**判断链表是否有环**和**求两个单链表相交的第一个节点**相结合，在快慢指针相遇点断开成两条新的链表，之后两个链表相交的第一个节点就是两个单链表相交的第一个节点。\n\n参考图\n\n![](http://oygov02sc.bkt.clouddn.com/%E9%93%BE%E8%A1%A8%E8%80%83%E7%82%B9%E5%89%96%E6%9E%90-1.png)\n\n```c++\nListNode * GetFirstNodeInCycle(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn NULL;\n\tListNode *pFast = pHead;\n\tListNode *pSlow = pHead;\n\twhile (pFast != NULL&&pFast->m_pNext != NULL)\n\t{\n\t\tpFast = pFast->m_pNext->m_pNext;\n\t\tpSlow = pSlow->m_pNext;\n\t\tif (pFast == pSlow)\n\t\t\tbreak;\n\t}\n\tif (pFast == NULL || pFast->m_pNext == NULL)\n\t\treturn NULL;\n\tListNode *pAssumedTail = pFast;\n\tListNode *pHead1 = pHead;\n\tListNode *pHead2 = pAssumedTail->m_pNext;\n\tListNode *pNode1 = pHead1;\n\tint len1 = 1;\n\twhile (pNode1 != pAssumedTail)\n\t{\n\t\tlen1++;\n\t\tpNode1 = pNode1->m_pNext;\n\t}\n\tListNode *pNode2 = pHead2;\n\tint len2 = 1;\n\twhile (pNode2 != pAssumedTail)\n\t{\n\t\tlen2++;\n\t\tpNode1 = pNode2->m_pNext;\n\t}\n\tif (len1 > len2)\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\telse\n\t{\n\t\tint k = len2 - len1;\n\t\twhile (k--)\n\t\t\tpNode2 = pNode2->m_pNext;\n\t}\n\twhile (pNode1 != pNode2)\n\t{\n\t\tpNode1 = pNode1->m_pNext;\n\t\tpNode2 = pNode2->m_pNext;\n\t}\n\treturn pNode1;\n}\n```\n\n#### O(1)删除一个节点\n\n一般来说删除一个节点的时间复杂度是O(n)，此处的删除是一种投机的方法，将待删除的节点的下一个节点的值赋予当前节点，然后删除下一个节点。当然如果需要删除的节点是尾节点，还是需要遍历才能删除。\n\n```C++\nvoid DeleteNode(ListNode *pHead, ListNode *pToBeDeleted)\n{\n\tif (pToBeDeleted == NULL)\n\t\treturn;\n\tif (pToBeDeleted->m_pNext != NULL)\n\t{\n\t\tListNode *pNext = pToBeDeleted->m_pNext;\n\t\tpToBeDeleted->m_nKey = pNext->m_nKey;\n\t\tpToBeDeleted->m_pNext = pNext->m_pNext;\n\t\tdelete pNext;\n\t\tpNext = NULL;\n\t}\n\telse\n\t{\n\t\tif (pHead == pToBeDeleted)\n\t\t{\n\t\t\tdelete pToBeDeleted;\n\t\t\tpHead = NULL;\n\t\t\tpToBeDeleted = NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tListNode *pTemp = pHead;\n\t\t\twhile (pTemp->m_pNext != pToBeDeleted)\n\t\t\t\tpTemp = pTemp->m_pNext;\n\t\t\tdelete pToBeDeleted;\n\t\t\tpTemp->m_pNext = NULL;\n\t\t\tpToBeDeleted = NULL;\n\t\t}\n\t}\n}\n```\n\n### 考点\n\n考点多集中在双指针，快慢指针，遍历等方面。在设计链表题目时，切记要考虑空链表，遍历跳出点以及该链表是否存在哑结点。在做题前需要向面试官询问，并在代码中恰当处理，否则很容易出错。\n\n### 附录\n\n全部代码\n\n```c++\n#include<iostream>\n#include<stack>\nusing namespace std;\n\nstruct ListNode\n{\n\tint m_nKey;\n\tListNode * m_pNext;\n};\n\nint main()\n{\n\treturn 0;\n}\n\n//求节点个数\nunsigned int GetThisLength(ListNode *pHead)\n{\n\tif (pHead == NULL)\n\t\treturn 0;\n\tListNode *pCurrent = pHead;\n\tunsigned int nlength = 0;\n\twhile (pCurrent != NULL)\n\t{\n\t\tnlength++;\n\t\tpCurrent = pCurrent->m_pNext;\n\t}\n\treturn nlength;\n}\n\n//反转链表\nListNode * ReverseList(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *pReverseHead = NULL;\n\tListNode *pCurrent = pHead;\n\twhile (pCurrent != NULL)\n\t{\n\t\tListNode *temp = pCurrent;\n\t\tpCurrent = pCurrent->m_pNext;\n\t\ttemp->m_pNext = pReverseHead;\n\t\tpReverseHead = temp;\n\t}\n\treturn pReverseHead;\n}\nListNode * ReverseList(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *newHead = ReverseList(pHead->next);\n  \tpHead->next->next = newHead->next;\n  \tpHead->next = NULL;\n\treturn pReverseHead;\n}\n\n//找倒数第k个节点\nListNode * RGetKthNode(ListNode * pHead, unsigned int k)\n{\n\tif (k == 0 || pHead == NULL)\n\t\treturn NULL;\n\tListNode *pAhead = pHead;\n\tListNode *pBehind = pHead;\n\twhile (pAhead != NULL&&k > 1)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tk--;\n\t}\n\tif (k > 1 || pAhead == NULL)\n\t\treturn NULL;\n\twhile (pAhead->m_pNext != NULL)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tpBehind = pBehind->m_pNext;\n\t}\n}\n\n//查找中间结点\nListNode * GetMiddleNode(ListNode * pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn pHead;\n\tListNode *pAhead = pHead;\n\tListNode *pBehind = pHead;\n\twhile (pAhead->m_pNext != NULL)\n\t{\n\t\tpAhead = pAhead->m_pNext;\n\t\tpBehind = pBehind->m_pNext;\n\t\tif (pAhead->m_pNext != NULL)\n\t\t\tpAhead = pAhead->m_pNext;\n\t}\n\treturn pBehind;\n}\n\n//倒序打印链表\nvoid PrintList(ListNode *pHead)\n{\n\tstack<ListNode *> s;\n\twhile (pHead != NULL)\n\t{\n\t\ts.push(pHead);\n\t\tpHead = pHead->m_pNext;\n\t}\n\twhile (!s.empty())\n\t{\n\t\tcout << s.top() << \"\\t\";\n\t\ts.pop();\n\t}\n}\n\n//合并两个链表\nListNode *MergeSortedLit(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL)\n\t\treturn pHead1;\n\tif (pHead2 == NULL)\n\t\treturn pHead2;\n\tListNode *pHeadMerged = NULL;\n\tif (pHead1->m_nKey < pHead2->m_nKey)\n\t{\n\t\tpHeadMerged = pHead1;\n\t\t//pHeadMerged->m_pNext = NULL;\n\t\tpHead1 = pHead1->m_pNext;\n\t}\n\telse\n\t{\n\t\tpHeadMerged = pHead2;\n\t\t//pHeadMerged->m_pNext = NULL;\n\t\tpHead2 = pHead2->m_pNext;\n\t}\n\tListNode *pTemp = pHeadMerged;\n\twhile (pHead1 != NULL && pHead2 != NULL)\n\t{\n\t\tif (pHead1->m_nKey < pHead2->m_nKey)\n\t\t{\n\t\t\tpTemp->m_pNext = pHead1;\n\t\t\tpHead1 = pHead1->m_pNext;\n\t\t\tpTemp = pTemp->m_pNext;\n\t\t\t//pTemp->m_pNext = NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpTemp->m_pNext = pHead2;\n\t\t\tpHead2 = pHead2->m_pNext;\n\t\t\tpTemp = pTemp->m_pNext;\n\t\t\t//pTemp->m_pNext = NULL;\n\t\t}\n\t}\n\tif (pHead1 != NULL)\n\t\tpTemp->m_pNext = pHead1;\n\telse if (pHead2 != NULL)\n\t\tpTemp->m_pNext = pHead2;\n\treturn pHeadMerged;\n}\n\n//判断单链表是否有环\nbool HasCircle(ListNode *pHead)\n{\n\tListNode *pFast = pHead;\n\tListNode *pSlow = pHead;\n\twhile (pFast != NULL&&pFast->m_pNext != NULL)\n\t{\n\t\tpFast = pFast->m_pNext->m_pNext;\n\t\tpSlow = pSlow->m_pNext;\n\t\tif (pFast == pSlow)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n//判断两个链表是否相交\nbool IsIntersected(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL&&pHead2 == NULL)\n\t\treturn false;\n\twhile (pHead1->m_pNext != NULL)\n\t\tpHead1 = pHead1->m_pNext;\n\twhile (pHead2->m_pNext != NULL)\n\t\tpHead2 = pHead2->m_pNext;\n\treturn pHead1 == pHead2;\n}\n\n//求两个单链表相交的第一个节点\nListNode * GetFirstCommonNode(ListNode *pHead1, ListNode *pHead2)\n{\n\tif (pHead1 == NULL || pHead2 == NULL)\n\t\treturn NULL;\n\tint len1 = 1;\n\tListNode *pTail1 = pHead1;\n\twhile (pTail1->m_pNext != NULL)\n\t{\n\t\tlen1++;\n\t\tpTail1 = pTail1->m_pNext;\n\t}\n\tint len2 = 1;\n\tListNode *pTail2 = pHead2;\n\twhile (pTail1->m_pNext != NULL)\n\t{\n\t\tlen2++;\n\t\tpTail2 = pTail2->m_pNext;\n\t}\n\tif (pTail1 != pTail2)\n\t\treturn NULL;\n\tListNode * pNode1 = pHead1;\n\tListNode * pNode2 = pHead2;\n\tif (len1 > len2)\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\telse\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\twhile (pNode1!=pNode2)\n\t{\n\t\tpNode1 = pNode1->m_pNext;\n\t\tpNode2 = pNode2->m_pNext;\n\t}\n\treturn pNode1;\n}\n\n//已知有环，求入环后第一个节点\nListNode * GetFirstNodeInCycle(ListNode *pHead)\n{\n\tif (pHead == NULL || pHead->m_pNext == NULL)\n\t\treturn NULL;\n\tListNode *pFast = pHead;\n\tListNode *pSlow = pHead;\n\twhile (pFast != NULL&&pFast->m_pNext != NULL)\n\t{\n\t\tpFast = pFast->m_pNext->m_pNext;\n\t\tpSlow = pSlow->m_pNext;\n\t\tif (pFast == pSlow)\n\t\t\tbreak;\n\t}\n\tif (pFast == NULL || pFast->m_pNext == NULL)\n\t\treturn NULL;\n\tListNode *pAssumedTail = pFast;\n\tListNode *pHead1 = pHead;\n\tListNode *pHead2 = pAssumedTail->m_pNext;\n\tListNode *pNode1 = pHead1;\n\tint len1 = 1;\n\twhile (pNode1 != pAssumedTail)\n\t{\n\t\tlen1++;\n\t\tpNode1 = pNode1->m_pNext;\n\t}\n\tListNode *pNode2 = pHead2;\n\tint len2 = 1;\n\twhile (pNode2 != pAssumedTail)\n\t{\n\t\tlen2++;\n\t\tpNode1 = pNode2->m_pNext;\n\t}\n\tif (len1 > len2)\n\t{\n\t\tint k = len1 - len2;\n\t\twhile (k--)\n\t\t\tpNode1 = pNode1->m_pNext;\n\t}\n\telse\n\t{\n\t\tint k = len2 - len1;\n\t\twhile (k--)\n\t\t\tpNode2 = pNode2->m_pNext;\n\t}\n\twhile (pNode1 != pNode2)\n\t{\n\t\tpNode1 = pNode1->m_pNext;\n\t\tpNode2 = pNode2->m_pNext;\n\t}\n\treturn pNode1;\n}\n\n//O(1)删除一个节点\nvoid DeleteNode(ListNode *pHead, ListNode *pToBeDeleted)\n{\n\tif (pToBeDeleted == NULL)\n\t\treturn;\n\tif (pToBeDeleted->m_pNext != NULL)\n\t{\n\t\tListNode *pNext = pToBeDeleted->m_pNext;\n\t\tpToBeDeleted->m_nKey = pNext->m_nKey;\n\t\tpToBeDeleted->m_pNext = pNext->m_pNext;\n\t\tdelete pNext;\n\t\tpNext = NULL;\n\t}\n\telse\n\t{\n\t\tif (pHead == pToBeDeleted)\n\t\t{\n\t\t\tdelete pToBeDeleted;\n\t\t\tpHead = NULL;\n\t\t\tpToBeDeleted = NULL;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tListNode *pTemp = pHead;\n\t\t\twhile (pTemp->m_pNext != pToBeDeleted)\n\t\t\t\tpTemp = pTemp->m_pNext;\n\t\t\tdelete pToBeDeleted;\n\t\t\tpTemp->m_pNext = NULL;\n\t\t\tpToBeDeleted = NULL;\n\t\t}\n\t}\n}\n```\n\n","slug":"链表考点剖析","published":1,"updated":"2018-01-03T16:03:11.046Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjkv4owc70014fb9lvp7kl413","content":"<p>链表，最为基础的数据结构，同时也是面试中最容易出现的考察点。很多人都觉得链表如此简单，以至于在面试不断的深入考察中出现纰漏。一旦在链表上出现差错，那么也意味着你基础的羸弱，直接导致面试的失败。</p>\n<p>在大三一年实习和后来校招的面试中，遇到了不下于五次链表的题目，题目有难有易，很难保证第一次接触能够完美的给出解答。因此总结了链表相关题目和解法，如有补充请留言。</p>\n<a id=\"more\"></a>\n<h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>全文的链表节点定义如下，无哑节点，基于C++实现。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">ListNode</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">\t<span class=\"keyword\">int</span> m_nKey;</span><br><span class=\"line\">\tListNode * m_pNext;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h3 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h3><h4 id=\"求节点数目\"><a href=\"#求节点数目\" class=\"headerlink\" title=\"求节点数目\"></a>求节点数目</h4><p>最基础的题目，直接遍历，注意循环停止条件。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> <span class=\"title\">GetThisLength</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">\tListNode *pCurrent = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> nlength = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pCurrent != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tnlength++;</span><br><span class=\"line\">\t\tpCurrent = pCurrent-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> nlength;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"反转链表\"><a href=\"#反转链表\" class=\"headerlink\" title=\"反转链表\"></a>反转链表</h4><p>一道非常经典的面试题，简单的同时也非常容易出错，分为递归和非递归解法。</p>\n<p>递归解法：每次递归返回的是已经反转好的链表的头结点，注意好跳出条件即可。</p>\n<p>非递归解法：遍历链表，已遍历的部分已反转，将正在遍历的节点当做头结点连接到已反转的部分。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//递归解法</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *newHead = ReverseList(pHead-&gt;next);</span><br><span class=\"line\">  \tpHead-&gt;next-&gt;next = newHead-&gt;next;</span><br><span class=\"line\">  \tpHead-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> newHead;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//非递归解法</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *pReverseHead = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pCurrent = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pCurrent != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tListNode *temp = pCurrent;</span><br><span class=\"line\">\t\tpCurrent = pCurrent-&gt;m_pNext;</span><br><span class=\"line\">\t\ttemp-&gt;m_pNext = pReverseHead;</span><br><span class=\"line\">\t\tpReverseHead = temp;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pReverseHead;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"找倒数第k个节点\"><a href=\"#找倒数第k个节点\" class=\"headerlink\" title=\"找倒数第k个节点\"></a>找倒数第k个节点</h4><p>双指针解题，这中思考方式在后面的题目经常出现。第一个指针先走k步，然后两个指针一起遍历，这样第一个指针到最后一个节点的时候，第二个指针即指向第k个节点。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">RGetKthNode</span><span class=\"params\">(ListNode * pHead, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (k == <span class=\"number\">0</span> || pHead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pAhead = pHead;</span><br><span class=\"line\">\tListNode *pBehind = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead != <span class=\"literal\">NULL</span>&amp;&amp;k &gt; <span class=\"number\">1</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tk--;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (k &gt; <span class=\"number\">1</span> || pAhead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tpBehind = pBehind-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"查找中间节点\"><a href=\"#查找中间节点\" class=\"headerlink\" title=\"查找中间节点\"></a>查找中间节点</h4><p>无需先获取长度，只需要一次遍历即可解决问题，和上一题类似思路，两个指针，分别为“快”指针和“慢”指针。快指针每次“走两步”，慢指针每次”走一步“，这样快指针走过的节点始终是慢指针的两倍。快指针到尾节点时，返回慢指针即可。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetMiddleNode</span><span class=\"params\">(ListNode * pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *pAhead = pHead;</span><br><span class=\"line\">\tListNode *pBehind = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tpBehind = pBehind-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pBehind;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"倒序打印链表\"><a href=\"#倒序打印链表\" class=\"headerlink\" title=\"倒序打印链表\"></a>倒序打印链表</h4><p>借助栈实现，遍历时将节点值存储到栈中。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">PrintList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"built_in\">stack</span>&lt;ListNode *&gt; s;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\ts.push(pHead);</span><br><span class=\"line\">\t\tpHead = pHead-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (!s.empty())</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\">cout</span> &lt;&lt; s.top() &lt;&lt; <span class=\"string\">\"\\t\"</span>;</span><br><span class=\"line\">\t\ts.pop();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"合并两个链表\"><a href=\"#合并两个链表\" class=\"headerlink\" title=\"合并两个链表\"></a>合并两个链表</h4><p>遍历对比节点值，直接合并。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode *<span class=\"title\">MergeSortedLit</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead2;</span><br><span class=\"line\">\tListNode *pHeadMerged = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1-&gt;m_nKey &lt; pHead2-&gt;m_nKey)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpHeadMerged = pHead1;</span><br><span class=\"line\">\t\t<span class=\"comment\">//pHeadMerged-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpHeadMerged = pHead2;</span><br><span class=\"line\">\t\t<span class=\"comment\">//pHeadMerged-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tListNode *pTemp = pHeadMerged;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead1 != <span class=\"literal\">NULL</span> &amp;&amp; pHead2 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pHead1-&gt;m_nKey &lt; pHead2-&gt;m_nKey)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = pHead1;</span><br><span class=\"line\">\t\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//pTemp-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = pHead2;</span><br><span class=\"line\">\t\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//pTemp-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpTemp-&gt;m_pNext = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (pHead2 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpTemp-&gt;m_pNext = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pHeadMerged;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"判断单链表是否有环\"><a href=\"#判断单链表是否有环\" class=\"headerlink\" title=\"判断单链表是否有环\"></a>判断单链表是否有环</h4><p>注意该链表有可能是首尾相接，也可能是只有后面一段是环。</p>\n<p>经典的快慢指针解题思路，快指针每次走两步，慢指针每次走一步。如果快慢指针相遇则存在环，否则不存在环。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">HasCircle</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\tListNode *pFast = pHead;</span><br><span class=\"line\">\tListNode *pSlow = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pFast != <span class=\"literal\">NULL</span>&amp;&amp;pFast-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpFast = pFast-&gt;m_pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\tpSlow = pSlow-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pFast == pSlow)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"判断两个链表是否相交\"><a href=\"#判断两个链表是否相交\" class=\"headerlink\" title=\"判断两个链表是否相交\"></a>判断两个链表是否相交</h4><p>如果两个链表相交，那么他们在相交点之后必定成为同一条链表，所以只需要判断两个链表的尾节点是否相同即可。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsIntersected</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span>&amp;&amp;pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead2-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pHead1 == pHead2;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"求两个单链表相交的第一个节点\"><a href=\"#求两个单链表相交的第一个节点\" class=\"headerlink\" title=\"求两个单链表相交的第一个节点\"></a>求两个单链表相交的第一个节点</h4><p>先获取两个链表的长度，然后获取长度差值len，双指针策略，较长的链表的指针先走len步，然后两个指针一起遍历，相遇即跳出，跳出点即相交的第一个节点。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetFirstCommonNode</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span> || pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len1 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\tListNode *pTail1 = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pTail1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen1++;</span><br><span class=\"line\">\t\tpTail1 = pTail1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len2 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\tListNode *pTail2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pTail1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen2++;</span><br><span class=\"line\">\t\tpTail2 = pTail2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pTail1 != pTail2)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode * pNode1 = pHead1;</span><br><span class=\"line\">\tListNode * pNode2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (len1 &gt; len2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1!=pNode2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pNode1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"已知有环，求入环后第一个节点\"><a href=\"#已知有环，求入环后第一个节点\" class=\"headerlink\" title=\"已知有环，求入环后第一个节点\"></a>已知有环，求入环后第一个节点</h4><p>这题将<strong>判断链表是否有环</strong>和<strong>求两个单链表相交的第一个节点</strong>相结合，在快慢指针相遇点断开成两条新的链表，之后两个链表相交的第一个节点就是两个单链表相交的第一个节点。</p>\n<p>参考图</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/%E9%93%BE%E8%A1%A8%E8%80%83%E7%82%B9%E5%89%96%E6%9E%90-1.png\" alt=\"\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetFirstNodeInCycle</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pFast = pHead;</span><br><span class=\"line\">\tListNode *pSlow = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pFast != <span class=\"literal\">NULL</span>&amp;&amp;pFast-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpFast = pFast-&gt;m_pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\tpSlow = pSlow-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pFast == pSlow)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pFast == <span class=\"literal\">NULL</span> || pFast-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pAssumedTail = pFast;</span><br><span class=\"line\">\tListNode *pHead1 = pHead;</span><br><span class=\"line\">\tListNode *pHead2 = pAssumedTail-&gt;m_pNext;</span><br><span class=\"line\">\tListNode *pNode1 = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len1 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1 != pAssumedTail)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen1++;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tListNode *pNode2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len2 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode2 != pAssumedTail)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen2++;</span><br><span class=\"line\">\t\tpNode1 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (len1 &gt; len2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len2 - len1;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1 != pNode2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pNode1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"O-1-删除一个节点\"><a href=\"#O-1-删除一个节点\" class=\"headerlink\" title=\"O(1)删除一个节点\"></a>O(1)删除一个节点</h4><p>一般来说删除一个节点的时间复杂度是O(n)，此处的删除是一种投机的方法，将待删除的节点的下一个节点的值赋予当前节点，然后删除下一个节点。当然如果需要删除的节点是尾节点，还是需要遍历才能删除。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">DeleteNode</span><span class=\"params\">(ListNode *pHead, ListNode *pToBeDeleted)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pToBeDeleted == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pToBeDeleted-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tListNode *pNext = pToBeDeleted-&gt;m_pNext;</span><br><span class=\"line\">\t\tpToBeDeleted-&gt;m_nKey = pNext-&gt;m_nKey;</span><br><span class=\"line\">\t\tpToBeDeleted-&gt;m_pNext = pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">delete</span> pNext;</span><br><span class=\"line\">\t\tpNext = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pHead == pToBeDeleted)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">delete</span> pToBeDeleted;</span><br><span class=\"line\">\t\t\tpHead = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t\tpToBeDeleted = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tListNode *pTemp = pHead;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">while</span> (pTemp-&gt;m_pNext != pToBeDeleted)</span><br><span class=\"line\">\t\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">delete</span> pToBeDeleted;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t\tpToBeDeleted = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"考点\"><a href=\"#考点\" class=\"headerlink\" title=\"考点\"></a>考点</h3><p>考点多集中在双指针，快慢指针，遍历等方面。在设计链表题目时，切记要考虑空链表，遍历跳出点以及该链表是否存在哑结点。在做题前需要向面试官询问，并在代码中恰当处理，否则很容易出错。</p>\n<h3 id=\"附录\"><a href=\"#附录\" class=\"headerlink\" title=\"附录\"></a>附录</h3><p>全部代码</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stack&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">ListNode</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">\t<span class=\"keyword\">int</span> m_nKey;</span><br><span class=\"line\">\tListNode * m_pNext;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//求节点个数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> <span class=\"title\">GetThisLength</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">\tListNode *pCurrent = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> nlength = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pCurrent != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tnlength++;</span><br><span class=\"line\">\t\tpCurrent = pCurrent-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> nlength;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//反转链表</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *pReverseHead = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pCurrent = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pCurrent != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tListNode *temp = pCurrent;</span><br><span class=\"line\">\t\tpCurrent = pCurrent-&gt;m_pNext;</span><br><span class=\"line\">\t\ttemp-&gt;m_pNext = pReverseHead;</span><br><span class=\"line\">\t\tpReverseHead = temp;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pReverseHead;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *newHead = ReverseList(pHead-&gt;next);</span><br><span class=\"line\">  \tpHead-&gt;next-&gt;next = newHead-&gt;next;</span><br><span class=\"line\">  \tpHead-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pReverseHead;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//找倒数第k个节点</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">RGetKthNode</span><span class=\"params\">(ListNode * pHead, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (k == <span class=\"number\">0</span> || pHead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pAhead = pHead;</span><br><span class=\"line\">\tListNode *pBehind = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead != <span class=\"literal\">NULL</span>&amp;&amp;k &gt; <span class=\"number\">1</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tk--;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (k &gt; <span class=\"number\">1</span> || pAhead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tpBehind = pBehind-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//查找中间结点</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetMiddleNode</span><span class=\"params\">(ListNode * pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *pAhead = pHead;</span><br><span class=\"line\">\tListNode *pBehind = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tpBehind = pBehind-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pBehind;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//倒序打印链表</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">PrintList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"built_in\">stack</span>&lt;ListNode *&gt; s;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\ts.push(pHead);</span><br><span class=\"line\">\t\tpHead = pHead-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (!s.empty())</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\">cout</span> &lt;&lt; s.top() &lt;&lt; <span class=\"string\">\"\\t\"</span>;</span><br><span class=\"line\">\t\ts.pop();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//合并两个链表</span></span><br><span class=\"line\"><span class=\"function\">ListNode *<span class=\"title\">MergeSortedLit</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead2;</span><br><span class=\"line\">\tListNode *pHeadMerged = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1-&gt;m_nKey &lt; pHead2-&gt;m_nKey)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpHeadMerged = pHead1;</span><br><span class=\"line\">\t\t<span class=\"comment\">//pHeadMerged-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpHeadMerged = pHead2;</span><br><span class=\"line\">\t\t<span class=\"comment\">//pHeadMerged-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tListNode *pTemp = pHeadMerged;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead1 != <span class=\"literal\">NULL</span> &amp;&amp; pHead2 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pHead1-&gt;m_nKey &lt; pHead2-&gt;m_nKey)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = pHead1;</span><br><span class=\"line\">\t\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//pTemp-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = pHead2;</span><br><span class=\"line\">\t\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//pTemp-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpTemp-&gt;m_pNext = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (pHead2 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpTemp-&gt;m_pNext = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pHeadMerged;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判断单链表是否有环</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">HasCircle</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\tListNode *pFast = pHead;</span><br><span class=\"line\">\tListNode *pSlow = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pFast != <span class=\"literal\">NULL</span>&amp;&amp;pFast-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpFast = pFast-&gt;m_pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\tpSlow = pSlow-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pFast == pSlow)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判断两个链表是否相交</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsIntersected</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span>&amp;&amp;pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead2-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pHead1 == pHead2;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//求两个单链表相交的第一个节点</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetFirstCommonNode</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span> || pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len1 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\tListNode *pTail1 = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pTail1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen1++;</span><br><span class=\"line\">\t\tpTail1 = pTail1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len2 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\tListNode *pTail2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pTail1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen2++;</span><br><span class=\"line\">\t\tpTail2 = pTail2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pTail1 != pTail2)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode * pNode1 = pHead1;</span><br><span class=\"line\">\tListNode * pNode2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (len1 &gt; len2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1!=pNode2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pNode1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//已知有环，求入环后第一个节点</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetFirstNodeInCycle</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pFast = pHead;</span><br><span class=\"line\">\tListNode *pSlow = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pFast != <span class=\"literal\">NULL</span>&amp;&amp;pFast-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpFast = pFast-&gt;m_pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\tpSlow = pSlow-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pFast == pSlow)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pFast == <span class=\"literal\">NULL</span> || pFast-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pAssumedTail = pFast;</span><br><span class=\"line\">\tListNode *pHead1 = pHead;</span><br><span class=\"line\">\tListNode *pHead2 = pAssumedTail-&gt;m_pNext;</span><br><span class=\"line\">\tListNode *pNode1 = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len1 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1 != pAssumedTail)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen1++;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tListNode *pNode2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len2 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode2 != pAssumedTail)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen2++;</span><br><span class=\"line\">\t\tpNode1 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (len1 &gt; len2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len2 - len1;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1 != pNode2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pNode1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//O(1)删除一个节点</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">DeleteNode</span><span class=\"params\">(ListNode *pHead, ListNode *pToBeDeleted)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pToBeDeleted == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pToBeDeleted-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tListNode *pNext = pToBeDeleted-&gt;m_pNext;</span><br><span class=\"line\">\t\tpToBeDeleted-&gt;m_nKey = pNext-&gt;m_nKey;</span><br><span class=\"line\">\t\tpToBeDeleted-&gt;m_pNext = pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">delete</span> pNext;</span><br><span class=\"line\">\t\tpNext = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pHead == pToBeDeleted)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">delete</span> pToBeDeleted;</span><br><span class=\"line\">\t\t\tpHead = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t\tpToBeDeleted = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tListNode *pTemp = pHead;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">while</span> (pTemp-&gt;m_pNext != pToBeDeleted)</span><br><span class=\"line\">\t\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">delete</span> pToBeDeleted;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t\tpToBeDeleted = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>链表，最为基础的数据结构，同时也是面试中最容易出现的考察点。很多人都觉得链表如此简单，以至于在面试不断的深入考察中出现纰漏。一旦在链表上出现差错，那么也意味着你基础的羸弱，直接导致面试的失败。</p>\n<p>在大三一年实习和后来校招的面试中，遇到了不下于五次链表的题目，题目有难有易，很难保证第一次接触能够完美的给出解答。因此总结了链表相关题目和解法，如有补充请留言。</p>","more":"<h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>全文的链表节点定义如下，无哑节点，基于C++实现。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">ListNode</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">\t<span class=\"keyword\">int</span> m_nKey;</span><br><span class=\"line\">\tListNode * m_pNext;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h3 id=\"题目\"><a href=\"#题目\" class=\"headerlink\" title=\"题目\"></a>题目</h3><h4 id=\"求节点数目\"><a href=\"#求节点数目\" class=\"headerlink\" title=\"求节点数目\"></a>求节点数目</h4><p>最基础的题目，直接遍历，注意循环停止条件。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> <span class=\"title\">GetThisLength</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">\tListNode *pCurrent = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> nlength = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pCurrent != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tnlength++;</span><br><span class=\"line\">\t\tpCurrent = pCurrent-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> nlength;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"反转链表\"><a href=\"#反转链表\" class=\"headerlink\" title=\"反转链表\"></a>反转链表</h4><p>一道非常经典的面试题，简单的同时也非常容易出错，分为递归和非递归解法。</p>\n<p>递归解法：每次递归返回的是已经反转好的链表的头结点，注意好跳出条件即可。</p>\n<p>非递归解法：遍历链表，已遍历的部分已反转，将正在遍历的节点当做头结点连接到已反转的部分。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//递归解法</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *newHead = ReverseList(pHead-&gt;next);</span><br><span class=\"line\">  \tpHead-&gt;next-&gt;next = newHead-&gt;next;</span><br><span class=\"line\">  \tpHead-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> newHead;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//非递归解法</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *pReverseHead = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pCurrent = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pCurrent != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tListNode *temp = pCurrent;</span><br><span class=\"line\">\t\tpCurrent = pCurrent-&gt;m_pNext;</span><br><span class=\"line\">\t\ttemp-&gt;m_pNext = pReverseHead;</span><br><span class=\"line\">\t\tpReverseHead = temp;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pReverseHead;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"找倒数第k个节点\"><a href=\"#找倒数第k个节点\" class=\"headerlink\" title=\"找倒数第k个节点\"></a>找倒数第k个节点</h4><p>双指针解题，这中思考方式在后面的题目经常出现。第一个指针先走k步，然后两个指针一起遍历，这样第一个指针到最后一个节点的时候，第二个指针即指向第k个节点。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">RGetKthNode</span><span class=\"params\">(ListNode * pHead, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (k == <span class=\"number\">0</span> || pHead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pAhead = pHead;</span><br><span class=\"line\">\tListNode *pBehind = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead != <span class=\"literal\">NULL</span>&amp;&amp;k &gt; <span class=\"number\">1</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tk--;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (k &gt; <span class=\"number\">1</span> || pAhead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tpBehind = pBehind-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"查找中间节点\"><a href=\"#查找中间节点\" class=\"headerlink\" title=\"查找中间节点\"></a>查找中间节点</h4><p>无需先获取长度，只需要一次遍历即可解决问题，和上一题类似思路，两个指针，分别为“快”指针和“慢”指针。快指针每次“走两步”，慢指针每次”走一步“，这样快指针走过的节点始终是慢指针的两倍。快指针到尾节点时，返回慢指针即可。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetMiddleNode</span><span class=\"params\">(ListNode * pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *pAhead = pHead;</span><br><span class=\"line\">\tListNode *pBehind = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tpBehind = pBehind-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pBehind;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"倒序打印链表\"><a href=\"#倒序打印链表\" class=\"headerlink\" title=\"倒序打印链表\"></a>倒序打印链表</h4><p>借助栈实现，遍历时将节点值存储到栈中。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">PrintList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"built_in\">stack</span>&lt;ListNode *&gt; s;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\ts.push(pHead);</span><br><span class=\"line\">\t\tpHead = pHead-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (!s.empty())</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\">cout</span> &lt;&lt; s.top() &lt;&lt; <span class=\"string\">\"\\t\"</span>;</span><br><span class=\"line\">\t\ts.pop();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"合并两个链表\"><a href=\"#合并两个链表\" class=\"headerlink\" title=\"合并两个链表\"></a>合并两个链表</h4><p>遍历对比节点值，直接合并。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode *<span class=\"title\">MergeSortedLit</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead2;</span><br><span class=\"line\">\tListNode *pHeadMerged = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1-&gt;m_nKey &lt; pHead2-&gt;m_nKey)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpHeadMerged = pHead1;</span><br><span class=\"line\">\t\t<span class=\"comment\">//pHeadMerged-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpHeadMerged = pHead2;</span><br><span class=\"line\">\t\t<span class=\"comment\">//pHeadMerged-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tListNode *pTemp = pHeadMerged;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead1 != <span class=\"literal\">NULL</span> &amp;&amp; pHead2 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pHead1-&gt;m_nKey &lt; pHead2-&gt;m_nKey)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = pHead1;</span><br><span class=\"line\">\t\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//pTemp-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = pHead2;</span><br><span class=\"line\">\t\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//pTemp-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpTemp-&gt;m_pNext = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (pHead2 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpTemp-&gt;m_pNext = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pHeadMerged;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"判断单链表是否有环\"><a href=\"#判断单链表是否有环\" class=\"headerlink\" title=\"判断单链表是否有环\"></a>判断单链表是否有环</h4><p>注意该链表有可能是首尾相接，也可能是只有后面一段是环。</p>\n<p>经典的快慢指针解题思路，快指针每次走两步，慢指针每次走一步。如果快慢指针相遇则存在环，否则不存在环。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">HasCircle</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\tListNode *pFast = pHead;</span><br><span class=\"line\">\tListNode *pSlow = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pFast != <span class=\"literal\">NULL</span>&amp;&amp;pFast-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpFast = pFast-&gt;m_pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\tpSlow = pSlow-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pFast == pSlow)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"判断两个链表是否相交\"><a href=\"#判断两个链表是否相交\" class=\"headerlink\" title=\"判断两个链表是否相交\"></a>判断两个链表是否相交</h4><p>如果两个链表相交，那么他们在相交点之后必定成为同一条链表，所以只需要判断两个链表的尾节点是否相同即可。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsIntersected</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span>&amp;&amp;pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead2-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pHead1 == pHead2;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"求两个单链表相交的第一个节点\"><a href=\"#求两个单链表相交的第一个节点\" class=\"headerlink\" title=\"求两个单链表相交的第一个节点\"></a>求两个单链表相交的第一个节点</h4><p>先获取两个链表的长度，然后获取长度差值len，双指针策略，较长的链表的指针先走len步，然后两个指针一起遍历，相遇即跳出，跳出点即相交的第一个节点。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetFirstCommonNode</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span> || pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len1 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\tListNode *pTail1 = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pTail1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen1++;</span><br><span class=\"line\">\t\tpTail1 = pTail1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len2 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\tListNode *pTail2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pTail1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen2++;</span><br><span class=\"line\">\t\tpTail2 = pTail2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pTail1 != pTail2)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode * pNode1 = pHead1;</span><br><span class=\"line\">\tListNode * pNode2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (len1 &gt; len2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1!=pNode2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pNode1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"已知有环，求入环后第一个节点\"><a href=\"#已知有环，求入环后第一个节点\" class=\"headerlink\" title=\"已知有环，求入环后第一个节点\"></a>已知有环，求入环后第一个节点</h4><p>这题将<strong>判断链表是否有环</strong>和<strong>求两个单链表相交的第一个节点</strong>相结合，在快慢指针相遇点断开成两条新的链表，之后两个链表相交的第一个节点就是两个单链表相交的第一个节点。</p>\n<p>参考图</p>\n<p><img src=\"http://oygov02sc.bkt.clouddn.com/%E9%93%BE%E8%A1%A8%E8%80%83%E7%82%B9%E5%89%96%E6%9E%90-1.png\" alt=\"\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetFirstNodeInCycle</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pFast = pHead;</span><br><span class=\"line\">\tListNode *pSlow = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pFast != <span class=\"literal\">NULL</span>&amp;&amp;pFast-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpFast = pFast-&gt;m_pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\tpSlow = pSlow-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pFast == pSlow)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pFast == <span class=\"literal\">NULL</span> || pFast-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pAssumedTail = pFast;</span><br><span class=\"line\">\tListNode *pHead1 = pHead;</span><br><span class=\"line\">\tListNode *pHead2 = pAssumedTail-&gt;m_pNext;</span><br><span class=\"line\">\tListNode *pNode1 = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len1 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1 != pAssumedTail)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen1++;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tListNode *pNode2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len2 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode2 != pAssumedTail)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen2++;</span><br><span class=\"line\">\t\tpNode1 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (len1 &gt; len2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len2 - len1;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1 != pNode2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pNode1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"O-1-删除一个节点\"><a href=\"#O-1-删除一个节点\" class=\"headerlink\" title=\"O(1)删除一个节点\"></a>O(1)删除一个节点</h4><p>一般来说删除一个节点的时间复杂度是O(n)，此处的删除是一种投机的方法，将待删除的节点的下一个节点的值赋予当前节点，然后删除下一个节点。当然如果需要删除的节点是尾节点，还是需要遍历才能删除。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">DeleteNode</span><span class=\"params\">(ListNode *pHead, ListNode *pToBeDeleted)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pToBeDeleted == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pToBeDeleted-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tListNode *pNext = pToBeDeleted-&gt;m_pNext;</span><br><span class=\"line\">\t\tpToBeDeleted-&gt;m_nKey = pNext-&gt;m_nKey;</span><br><span class=\"line\">\t\tpToBeDeleted-&gt;m_pNext = pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">delete</span> pNext;</span><br><span class=\"line\">\t\tpNext = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pHead == pToBeDeleted)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">delete</span> pToBeDeleted;</span><br><span class=\"line\">\t\t\tpHead = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t\tpToBeDeleted = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tListNode *pTemp = pHead;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">while</span> (pTemp-&gt;m_pNext != pToBeDeleted)</span><br><span class=\"line\">\t\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">delete</span> pToBeDeleted;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t\tpToBeDeleted = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"考点\"><a href=\"#考点\" class=\"headerlink\" title=\"考点\"></a>考点</h3><p>考点多集中在双指针，快慢指针，遍历等方面。在设计链表题目时，切记要考虑空链表，遍历跳出点以及该链表是否存在哑结点。在做题前需要向面试官询问，并在代码中恰当处理，否则很容易出错。</p>\n<h3 id=\"附录\"><a href=\"#附录\" class=\"headerlink\" title=\"附录\"></a>附录</h3><p>全部代码</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stack&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">ListNode</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">\t<span class=\"keyword\">int</span> m_nKey;</span><br><span class=\"line\">\tListNode * m_pNext;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//求节点个数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> <span class=\"title\">GetThisLength</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">\tListNode *pCurrent = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> nlength = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pCurrent != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tnlength++;</span><br><span class=\"line\">\t\tpCurrent = pCurrent-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> nlength;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//反转链表</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *pReverseHead = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pCurrent = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pCurrent != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tListNode *temp = pCurrent;</span><br><span class=\"line\">\t\tpCurrent = pCurrent-&gt;m_pNext;</span><br><span class=\"line\">\t\ttemp-&gt;m_pNext = pReverseHead;</span><br><span class=\"line\">\t\tpReverseHead = temp;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pReverseHead;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *newHead = ReverseList(pHead-&gt;next);</span><br><span class=\"line\">  \tpHead-&gt;next-&gt;next = newHead-&gt;next;</span><br><span class=\"line\">  \tpHead-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pReverseHead;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//找倒数第k个节点</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">RGetKthNode</span><span class=\"params\">(ListNode * pHead, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (k == <span class=\"number\">0</span> || pHead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pAhead = pHead;</span><br><span class=\"line\">\tListNode *pBehind = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead != <span class=\"literal\">NULL</span>&amp;&amp;k &gt; <span class=\"number\">1</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tk--;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (k &gt; <span class=\"number\">1</span> || pAhead == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tpBehind = pBehind-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//查找中间结点</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetMiddleNode</span><span class=\"params\">(ListNode * pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">\tListNode *pAhead = pHead;</span><br><span class=\"line\">\tListNode *pBehind = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t\tpBehind = pBehind-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pAhead-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t\tpAhead = pAhead-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pBehind;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//倒序打印链表</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">PrintList</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"built_in\">stack</span>&lt;ListNode *&gt; s;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\ts.push(pHead);</span><br><span class=\"line\">\t\tpHead = pHead-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (!s.empty())</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\">cout</span> &lt;&lt; s.top() &lt;&lt; <span class=\"string\">\"\\t\"</span>;</span><br><span class=\"line\">\t\ts.pop();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//合并两个链表</span></span><br><span class=\"line\"><span class=\"function\">ListNode *<span class=\"title\">MergeSortedLit</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> pHead2;</span><br><span class=\"line\">\tListNode *pHeadMerged = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1-&gt;m_nKey &lt; pHead2-&gt;m_nKey)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpHeadMerged = pHead1;</span><br><span class=\"line\">\t\t<span class=\"comment\">//pHeadMerged-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpHeadMerged = pHead2;</span><br><span class=\"line\">\t\t<span class=\"comment\">//pHeadMerged-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tListNode *pTemp = pHeadMerged;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead1 != <span class=\"literal\">NULL</span> &amp;&amp; pHead2 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pHead1-&gt;m_nKey &lt; pHead2-&gt;m_nKey)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = pHead1;</span><br><span class=\"line\">\t\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//pTemp-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = pHead2;</span><br><span class=\"line\">\t\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"comment\">//pTemp-&gt;m_pNext = NULL;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpTemp-&gt;m_pNext = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (pHead2 != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpTemp-&gt;m_pNext = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pHeadMerged;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判断单链表是否有环</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">HasCircle</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\tListNode *pFast = pHead;</span><br><span class=\"line\">\tListNode *pSlow = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pFast != <span class=\"literal\">NULL</span>&amp;&amp;pFast-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpFast = pFast-&gt;m_pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\tpSlow = pSlow-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pFast == pSlow)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//判断两个链表是否相交</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsIntersected</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span>&amp;&amp;pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpHead1 = pHead1-&gt;m_pNext;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pHead2-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\tpHead2 = pHead2-&gt;m_pNext;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pHead1 == pHead2;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//求两个单链表相交的第一个节点</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetFirstCommonNode</span><span class=\"params\">(ListNode *pHead1, ListNode *pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead1 == <span class=\"literal\">NULL</span> || pHead2 == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len1 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\tListNode *pTail1 = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pTail1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen1++;</span><br><span class=\"line\">\t\tpTail1 = pTail1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len2 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\tListNode *pTail2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pTail1-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen2++;</span><br><span class=\"line\">\t\tpTail2 = pTail2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pTail1 != pTail2)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode * pNode1 = pHead1;</span><br><span class=\"line\">\tListNode * pNode2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (len1 &gt; len2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1!=pNode2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pNode1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//已知有环，求入环后第一个节点</span></span><br><span class=\"line\"><span class=\"function\">ListNode * <span class=\"title\">GetFirstNodeInCycle</span><span class=\"params\">(ListNode *pHead)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pHead == <span class=\"literal\">NULL</span> || pHead-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pFast = pHead;</span><br><span class=\"line\">\tListNode *pSlow = pHead;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pFast != <span class=\"literal\">NULL</span>&amp;&amp;pFast-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpFast = pFast-&gt;m_pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\tpSlow = pSlow-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pFast == pSlow)</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pFast == <span class=\"literal\">NULL</span> || pFast-&gt;m_pNext == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\tListNode *pAssumedTail = pFast;</span><br><span class=\"line\">\tListNode *pHead1 = pHead;</span><br><span class=\"line\">\tListNode *pHead2 = pAssumedTail-&gt;m_pNext;</span><br><span class=\"line\">\tListNode *pNode1 = pHead1;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len1 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1 != pAssumedTail)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen1++;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tListNode *pNode2 = pHead2;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> len2 = <span class=\"number\">1</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode2 != pAssumedTail)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tlen2++;</span><br><span class=\"line\">\t\tpNode1 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (len1 &gt; len2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len1 - len2;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> k = len2 - len1;</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span> (k--)</span><br><span class=\"line\">\t\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span> (pNode1 != pNode2)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tpNode1 = pNode1-&gt;m_pNext;</span><br><span class=\"line\">\t\tpNode2 = pNode2-&gt;m_pNext;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pNode1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//O(1)删除一个节点</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">DeleteNode</span><span class=\"params\">(ListNode *pHead, ListNode *pToBeDeleted)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pToBeDeleted == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (pToBeDeleted-&gt;m_pNext != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tListNode *pNext = pToBeDeleted-&gt;m_pNext;</span><br><span class=\"line\">\t\tpToBeDeleted-&gt;m_nKey = pNext-&gt;m_nKey;</span><br><span class=\"line\">\t\tpToBeDeleted-&gt;m_pNext = pNext-&gt;m_pNext;</span><br><span class=\"line\">\t\t<span class=\"keyword\">delete</span> pNext;</span><br><span class=\"line\">\t\tpNext = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (pHead == pToBeDeleted)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">delete</span> pToBeDeleted;</span><br><span class=\"line\">\t\t\tpHead = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t\tpToBeDeleted = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tListNode *pTemp = pHead;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">while</span> (pTemp-&gt;m_pNext != pToBeDeleted)</span><br><span class=\"line\">\t\t\t\tpTemp = pTemp-&gt;m_pNext;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">delete</span> pToBeDeleted;</span><br><span class=\"line\">\t\t\tpTemp-&gt;m_pNext = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t\tpToBeDeleted = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjkv4owbi0001fb9lvul48xzk","category_id":"cjkv4owbn0003fb9lpesiajag","_id":"cjkv4owbv000efb9ljnwfqpzw"},{"post_id":"cjkv4owbt000bfb9ldzgz5660","category_id":"cjkv4owbn0003fb9lpesiajag","_id":"cjkv4owbz000lfb9ldf34zxeb"},{"post_id":"cjkv4owbl0002fb9lx2y40lmh","category_id":"cjkv4owbs0008fb9lzljyf5t5","_id":"cjkv4owc1000qfb9l7q2fota4"},{"post_id":"cjkv4owbp0005fb9lg5l30bv2","category_id":"cjkv4owbv000ffb9lvxrr1o5y","_id":"cjkv4owc3000ufb9ld6gblm73"},{"post_id":"cjkv4owbq0006fb9lq3e3w7ab","category_id":"cjkv4owbv000ffb9lvxrr1o5y","_id":"cjkv4owc50010fb9lyifvggwf"},{"post_id":"cjkv4owbr0007fb9l6wcgzepb","category_id":"cjkv4owbv000ffb9lvxrr1o5y","_id":"cjkv4owc80016fb9l63kc45vy"},{"post_id":"cjkv4owc5000yfb9lsxh3o9g2","category_id":"cjkv4owbv000ffb9lvxrr1o5y","_id":"cjkv4owc80019fb9lg7ipyg6i"},{"post_id":"cjkv4owc60011fb9l2k45kb82","category_id":"cjkv4owbv000ffb9lvxrr1o5y","_id":"cjkv4owc8001bfb9l9y8iqthp"},{"post_id":"cjkv4owbu000dfb9ld8oarcb4","category_id":"cjkv4owbv000ffb9lvxrr1o5y","_id":"cjkv4owc9001dfb9ldjn6jjkp"},{"post_id":"cjkv4owbw000ifb9l4wqxjcde","category_id":"cjkv4owc70015fb9l0lahr6rg","_id":"cjkv4owc9001gfb9lg2764pz5"},{"post_id":"cjkv4owby000kfb9lglyhudwn","category_id":"cjkv4owc8001cfb9lfgvfb86o","_id":"cjkv4owca001kfb9lfwlwazyn"},{"post_id":"cjkv4owc0000pfb9lmsftyumg","category_id":"cjkv4owc9001hfb9ljlo5wira","_id":"cjkv4owcb001ofb9lqdlbfgia"},{"post_id":"cjkv4owc2000sfb9ln10bxsim","category_id":"cjkv4owca001lfb9ldoap9yso","_id":"cjkv4owcc001sfb9ly40yqdjb"},{"post_id":"cjkv4owc4000wfb9lk4p71avv","category_id":"cjkv4owcb001pfb9lylod0t3m","_id":"cjkv4owcc001vfb9l8gtvzj7e"},{"post_id":"cjkv4owc70014fb9lvp7kl413","category_id":"cjkv4owcc001tfb9lq8sjf5tl","_id":"cjkv4owcd001wfb9lodxu0rk7"}],"PostTag":[{"post_id":"cjkv4owbq0006fb9lq3e3w7ab","tag_id":"cjkv4owbp0004fb9lfx8u4klv","_id":"cjkv4owbs000afb9lflfoplzx"},{"post_id":"cjkv4owbi0001fb9lvul48xzk","tag_id":"cjkv4owbp0004fb9lfx8u4klv","_id":"cjkv4owbu000cfb9ldwn5ovci"},{"post_id":"cjkv4owbr0007fb9l6wcgzepb","tag_id":"cjkv4owbp0004fb9lfx8u4klv","_id":"cjkv4owbw000hfb9lpz62sirs"},{"post_id":"cjkv4owbt000bfb9ldzgz5660","tag_id":"cjkv4owbp0004fb9lfx8u4klv","_id":"cjkv4owby000jfb9lumhi6egv"},{"post_id":"cjkv4owbl0002fb9lx2y40lmh","tag_id":"cjkv4owbs0009fb9lyoy841he","_id":"cjkv4owbz000ofb9lvs7bh9la"},{"post_id":"cjkv4owbp0005fb9lg5l30bv2","tag_id":"cjkv4owbv000gfb9l7pfchsds","_id":"cjkv4owc1000rfb9lcsq5bsom"},{"post_id":"cjkv4owbu000dfb9ld8oarcb4","tag_id":"cjkv4owbz000nfb9lqsgb9qtj","_id":"cjkv4owc4000xfb9lofkxntjh"},{"post_id":"cjkv4owc5000yfb9lsxh3o9g2","tag_id":"cjkv4owbp0004fb9lfx8u4klv","_id":"cjkv4owc70013fb9lf7zofon9"},{"post_id":"cjkv4owbw000ifb9l4wqxjcde","tag_id":"cjkv4owc3000vfb9lh6751l30","_id":"cjkv4owc80017fb9li9y3w5us"},{"post_id":"cjkv4owby000kfb9lglyhudwn","tag_id":"cjkv4owc60012fb9l53le8xy6","_id":"cjkv4owc8001afb9lszqmk0rg"},{"post_id":"cjkv4owc0000pfb9lmsftyumg","tag_id":"cjkv4owc80018fb9ldczccj1b","_id":"cjkv4owc9001ffb9leafp5anr"},{"post_id":"cjkv4owc2000sfb9ln10bxsim","tag_id":"cjkv4owc9001efb9lzkkxam2t","_id":"cjkv4owca001jfb9l7c73u4q9"},{"post_id":"cjkv4owc4000wfb9lk4p71avv","tag_id":"cjkv4owc9001ifb9lgi16nt3b","_id":"cjkv4owcb001nfb9loqb8qg0t"},{"post_id":"cjkv4owc60011fb9l2k45kb82","tag_id":"cjkv4owca001mfb9l8aqt75go","_id":"cjkv4owcc001rfb9lrj0325bu"},{"post_id":"cjkv4owc70014fb9lvp7kl413","tag_id":"cjkv4owcb001qfb9lygnafe6q","_id":"cjkv4owcc001ufb9lmnoae22f"}],"Tag":[{"name":"machine learning","_id":"cjkv4owbp0004fb9lfx8u4klv"},{"name":"年度总结","_id":"cjkv4owbs0009fb9lyoy841he"},{"name":"deep learning","_id":"cjkv4owbv000gfb9l7pfchsds"},{"name":"softmax","_id":"cjkv4owbz000nfb9lqsgb9qtj"},{"name":"游戏","_id":"cjkv4owc3000vfb9lh6751l30"},{"name":"google map","_id":"cjkv4owc60012fb9l53le8xy6"},{"name":"Controllers","_id":"cjkv4owc80018fb9ldczccj1b"},{"name":"hexo","_id":"cjkv4owc9001efb9lzkkxam2t"},{"name":"java基础","_id":"cjkv4owc9001ifb9lgi16nt3b"},{"name":"machine learing","_id":"cjkv4owca001mfb9l8aqt75go"},{"name":"面试","_id":"cjkv4owcb001qfb9lygnafe6q"}]}}