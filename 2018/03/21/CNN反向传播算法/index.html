

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Jianwen Yin">
  <meta name="keywords" content="">
  <title>CNN反向传播算法 - CodingxWriting</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
    
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Jianwen Yin</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2018-03-21 11:19" pubdate>
        2018年3月21日 上午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.8k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      63
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">CNN反向传播算法</h1>
            
            <div class="markdown-body" id="post-body">
              <blockquote>
<p>全文翻译自 Notes on Convolutional Neural Networks</p>
<p><a target="_blank" rel="noopener" href="http://web.mit.edu/jvb/www/papers/cnn_tutorial.pdf">论文链接</a></p>
<p>释部分为自己的补充说明，可能存在错误</p>
</blockquote>
<!--- more --->
<p>###1 介绍</p>
<p>本文档讨论CNN的推导和实现，并加上一些简单的扩展。相比权值，卷积神经网络涉及到更多的连接。其架构本身实现了正则化。此外，CNN在某种程度上实现了平移不变性。这种特殊的神经网络假设我们希望通过数据驱动的方式学习过滤器，用来提取输入特征。推导是在二维的数据和卷积的基础上展开的，但可以很容易的推广到任意维度。</p>
<p>我们先对经典的BP算法做一个描述，然后推导2D卷积神经网络中卷积层和子采样层（池化层）的BP权值更新方法。在整个过程中，我们强调了视线的效率，给出MATLAB代码片段配合方程讲解。然后讨论如何自动组合前一层的feature map，最后是feature map的稀疏组合。</p>
<p>免责声明：这个笔记可能有错误。</p>
<blockquote>
<p>feature map 就是特征矩阵，一张图片的每个像素点的RGB值可分别组成矩阵（R矩阵，G矩阵，B矩阵），这些就是feature map</p>
</blockquote>
<p>###2 全连接的反向传播算法</p>
<p>一个典型的卷积神经网络，开始是卷积层和子采样层交替，最后几层（最接近输出）是全连接的一维网络（全连接层）。当你准备将2D feature map作为一维全连接网络的输入时，直接将所有特征连接为一个一维向量，然后就可以利用BP算法。因此在讨论CNN之前，这里先对BP算法进行解释。</p>
<p>####2.1 前向传播 Feedforward Pass</p>
<p>在接下来的推导中，我们考虑平方和误差函数，对于一个有c个类别和N个训练样本的多分类问题，计算公式如下： <span class="math display">\[
E^N=\frac{1}{2}\sum_{n=1}^{N}\sum_{k=1}^{c}(t_k^n-y_k^n)^2
\]</span> <span class="math inline">\(t_k^n\)</span>是第n个样本对应标签的第k个维度的值，<span class="math inline">\(y_k^n\)</span>表示第n个样本对应的网络输出的第k个值。对于多分类问题，输出一般为“one-of-c”形式。如果样本<span class="math inline">\(x^n\)</span>属于第k类，那么<span class="math inline">\(t_k^n\)</span>为正，<span class="math inline">\(t^n\)</span>的其他维度即<span class="math inline">\(t_{k\neq1}^n\)</span>为0或负数。这取决于输出激活函数的选择，此处不做讨论。</p>
<p>因为整个训练集的误差为每个训练样本的误差和，所以我们先讨论一个样本。第n个样本的误差如下： <span class="math display">\[
E^N=\frac{1}{2}\sum_{n=1}^{N}\sum_{k=1}^c(t_k^n-y_k^n)^2=\frac{1}{2}||t^n-y^n||_2^2\tag{1}
\]</span> 在全连接层，我们可以根据反向传播规则计算E对网络权值的偏导数。用<span class="math inline">\(l\)</span>代表当前层，输出层被指定为<span class="math inline">\(L\)</span>层，输入层为第1层，那么当前层的输出为 <span class="math display">\[
x^l=f(u^l), with \space u^l=W^lx^{l-1}+b^l\tag{2}
\]</span></p>
<p>输出激活函数<span class="math inline">\(f(\cdot)\)</span>一般选择logistic(sigmoid)函数<span class="math inline">\(f(x)=(1+e^{-\beta x})^{-1}\)</span>或者hyperbolic tangent函数<span class="math inline">\(f(x)=a\space tanh(bx)\)</span>。logistic函数将<span class="math inline">\([-\infty,\infty]\)</span>映射到<span class="math inline">\([0,1]\)</span>，hyperbolic tangent函数将<span class="math inline">\([-\infty,\infty]\)</span>映射到<span class="math inline">\([-a,a]\)</span>，因此hyperbolic tangent函数的输出平均值一般趋于0，sigmoid函数的输出平均为非零。但是如果将训练数据归一化到均值为0方差为1，可以在梯度下降时增加收敛。对于归一化的数据集来说，hyperbolic tangent函数是较好的选择。LeCun推荐<span class="math inline">\(a=1.7159,b=2/3\)</span>，所以最大非线性点在<span class="math inline">\(f(\pm1)=\pm1\)</span>，因此对预期训练目标进行正则化将会避免训练饱和。</p>
<p>####2.2 反向传播 Backpropagation Pass</p>
<p>通过网络反向传播的误差可以看作每个神经元关于偏差扰动的敏感度（sensitivities），通过链式法则可得：</p>
<blockquote>
<p>敏感度就是误差对目标的偏导数</p>
</blockquote>
<p><span class="math display">\[
\begin{equation}
\frac{\partial{E}}{\partial{b}}=\frac{\partial{E}}{\partial{u}}\frac{\partial{u}}{\partial{b}}=\delta
\end{equation}\tag{3}
\]</span></p>
<p>因为<span class="math inline">\(\frac{\partial{u}}{\partial{b}}=1\)</span>，所以bias的敏感度和误差对一个神经元的输入的偏导数是相等的。利用这个关系将高层误差反向传播到底层，使用下面的递推关系式： <span class="math display">\[
\delta^t=(W^{l+1})^T\delta^{l+1}\circ f&#39;(u^t)\tag{4}
\]</span> 其中<span class="math inline">\(\circ\)</span>表示对应位置元素相乘，从公式（1）可以看到，输出层神经元的敏感度会有一些不同： <span class="math display">\[
\delta^L=f&#39;(u^L)\circ(y^n-t^n)
\]</span> 最后，对每个神经元运用delta规则进行更行，即对神经元的输入使用delta进行缩放。用向量的形式表述就是：输入向量（前一层的输出）和灵敏度向量之间的一个外积： <span class="math display">\[
\frac{\partial{E}}{\partial{W^l}}=x^{l-1}(\delta^l)^T\tag{5}
\]</span></p>
<p><span class="math display">\[
\bigtriangleup W^l=-\eta\frac{\partial{E}}{\partial{W^l}}\tag{6}
\]</span></p>
<p>更新偏置值（bias）也是相同的原理，在实际中通常为每个权值赋予一个特定的学习率<span class="math inline">\(\eta_{ij}\)</span>。</p>
<h3 id="卷积神经网络-convolutional-neural-networks">3 卷积神经网络 Convolutional Neural Networks</h3>
<blockquote>
<p>公式符号释意</p>
<p>在本文中卷积核有多个，每个卷积核和feature map有多个维度，例如一张图片有RGB值，那么就有三个维度</p>
<p><span class="math inline">\(i\)</span>----卷积核或者feature的第几维度 <span class="math inline">\(j\)</span>----第几个卷积核 <span class="math inline">\(up()\)</span>----上采样函数 <span class="math inline">\(down()\)</span>----下采样函数 <span class="math inline">\(l\)</span>----当前层</p>
</blockquote>
<p>通常卷积层和子采样层交替以减少计算时间并逐步建立空间和结构不变性。为了同时保持特异性，需要小的子采样因子。这并不是什么新鲜的概念，但简洁有效。这种模型在哺乳动物的视觉皮层非常常见，在过去十年，听觉神经科学发现，这些相同的设计范例可以在多种不同动物皮层的主要和带状听觉区域中找到。 分级分析和学习架构可能仍然是听觉领域的关键。</p>
<p>####3.1 卷积层 Convolution Layers</p>
<p>我们现在推导卷积层的BP更行。在一个卷积层，上一层的feature map与一个卷积核进行卷积运算，然后通过一个激活函数获得输出feature map。每个输出map可能是多个卷积结果的结合，公式表述： <span class="math display">\[
x_j^l=f\left(\sum_{i\in M_j}x_i^{l-1}*k_{ij}^{l}+b_j^l\right)
\]</span></p>
<p><span class="math inline">\(M_j\)</span>表示输入maps的集合，在MATLAB中卷积的运算需采用"valid"模式。通常情况下，输入maps选择一对或者三个。后面我们会讨论如何自动选择需要组合的特征map。每一个输出map都会加上一个偏执项<span class="math inline">\(b\)</span>，但是对于一个特定的输出map，输入maps会和相同的卷积核进行卷积运算，也就是说，如果输出map <span class="math inline">\(j\)</span> 和 <span class="math inline">\(k\)</span> 都是由map <span class="math inline">\(i\)</span>通过卷积运算的结果，那么对应的卷积核是不同的。</p>
<blockquote>
<p>一张图片有RGB三个颜色通道，则对应的卷积核也是三维的，输出的feature map就是三个卷积结果的结合</p>
<figure>
<img src="https://ws3.sinaimg.cn/large/005PPQ5Ily1g0ymwrjv8jg30m50iqaob.gif" srcset="/img/loading.gif" alt="CNN_02" /><figcaption aria-hidden="true">CNN_02</figcaption>
</figure>
</blockquote>
<p>3.1.1 Computing the Gradients</p>
<p>我们假设每个卷积层<span class="math inline">\(l\)</span>后面都接一个子采样层 <span class="math inline">\(l+1\)</span>。在使用BP算法计算 <span class="math inline">\(l\)</span> 层每个节点的敏感度时，我们需要先对下一层（<span class="math inline">\(l+1\)</span>层）连接当前层（<span class="math inline">\(l\)</span>层）的节点的敏感度求和，再乘以这些连接对应的权值（连接<span class="math inline">\(l\)</span>层和<span class="math inline">\(l+1\)</span>层的权值），最后乘以当前层<span class="math inline">\(l\)</span>的该神经元节点的输入<span class="math inline">\(u\)</span>的激活函数<span class="math inline">\(f\)</span>的导数值。因为下采样的存在，采样层的一个像素（神经元）对应的灵敏度<span class="math inline">\(\delta\)</span>对应于卷积层（上一层）的输出map的一块像素（采样窗口大小）。因此，<span class="math inline">\(l\)</span>层中的map的每个节点只与<span class="math inline">\(l+1\)</span>层中相应map的一个节点连接。为了有效计算<span class="math inline">\(l\)</span>层的敏感度，我们可以对下采样层的敏感，度map进行“上采样(upsample)”操作，这样可以使下采样层的敏感度map的大小和卷积层的map大小相同，然后将<span class="math inline">\(l\)</span>层的激活值偏导map和<span class="math inline">\(l+1\)</span>层的上采样敏感度map对应元素相乘。因为下采样层map的权值均是一个常数<span class="math inline">\(\beta\)</span>（见3.2节），所以我们只需要将上一步得到的结果乘以 $ $ 就可以得到<span class="math inline">\(l\)</span>层的敏感度map <span class="math inline">\(\delta^l\)</span>。我们可以在卷积层的每个feature map进行相同的计算过程： <span class="math display">\[
\delta_j^l=\beta_j^{l+1}\left(f&#39;(u_j^l)\circ up(\delta_j^{l+1})\right)
\]</span> 其中的 <span class="math inline">\(up(\cdot)\)</span>表示上采样操作，如果下采样过程的采样因子为<span class="math inline">\(n\)</span>，只需将每个像素点在水平方向和垂直方向复制<span class="math inline">\(n\)</span>次就可以实现，一种有效的实现方式是利用 Kronecker product: <span class="math display">\[
up(x)=x\otimes1_{n\times n}
\]</span></p>
<blockquote>
<p>Ref:<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh/克罗内克积">克罗内克积</a></p>
</blockquote>
<p>现在对于一个给定的map，我们已经可以计算其敏感度map，然后我们可以简单的对敏感度map的所有节点求和计算出其bias（偏置项）梯度: <span class="math display">\[
\frac{\partial{E}}{\partial{b_j}}=\sum_{u,v}(\delta_j^l)_{uv}
\]</span> 最后，使用BP算法计算权重（卷积核）的梯度，很多权重在连接中是共享的，因此我们需要对所有与该权值有联系（权值共享的连接）的连接对该点求梯度，然后对这些梯度进行求和，就像计算bias梯度一样： <span class="math display">\[
\frac{\partial{E}}{\partial{k_{ij}^l}}=\sum_{u,v}(\delta_j^l)_{uv}(p_i^{l-1})_{uv}\tag{7}
\]</span> 其中<span class="math inline">\((p_i^{l-1})_{uv}\)</span>是<span class="math inline">\(x_i^{l-1}\)</span>在卷积运算时和<span class="math inline">\(k_{ij}^l\)</span>按元素相乘得到输出map的<span class="math inline">\((u,v)\)</span>位置值的patch。看上去好像我们我刻意追踪输入map中哪些patch与输出map中的哪些像素（及其对应的敏感map）相对应，但是公式(7)可以通过卷积运算获得: <span class="math display">\[
\frac{\partial{E}}{\partial{k_{ij}^l}}=rot180(conv2(x_i^{l-1},rot180(\delta_j^l),&#39;valid&#39;))
\]</span> 这里我们对<span class="math inline">\(\delta\)</span>敏感度map做旋转操作是为了这样就可以进行互相关计算而不是卷积，之后将输出旋转回来，以便当我们在前馈阶段执行卷积时，卷积核将具有正确的方向。</p>
<p>####3.2 子采样层 Sub-sampling Layers</p>
<p>子采样层对输入maps进行downsample操作（池化），输入有N个maps，输出也会有N个maps，只是每个maps变小了，公式表述如下： <span class="math display">\[
x_j^l=f\left(\beta_j^ldown(x_j^{l-1})+b_j^l\right)
\]</span></p>
<p>其中的<span class="math inline">\(down(\cdot)\)</span>是下采样函数。典型的操作一般是对输入图像的不同<span class="math inline">\(n\times n\)</span>的块的像素进行求和。这样输出图像在两个维度上都缩小了n倍。每个输出map都有一个属于自己的乘性偏置β和一个加性偏置b。</p>
<p>3.2.1 Computing the Gradients</p>
<p>这里的困难在于如何计算敏感度maps。只要我们能得到敏感度maps，需要更新的只有bias参数 <span class="math inline">\(\beta\)</span> 和 <span class="math inline">\(b\)</span> 。如果子采样层的下一层是全连接层，那么子采样层的敏感度maps只需要利用BP算法就可以容易获得。所以我们假设子采样层的上一层和下一层都是卷积层。</p>
<p>当我们在3.1.1节计算卷积核梯度时，我们需要找到输入map中patch和输出map的像素的对应关系。这里就是必须找到当前层的敏感度map中那个patch与下一层的敏感度矩阵的的给定像素对应，这样就可以像公式 (4)那样应用<span class="math inline">\(\delta\)</span>递推。 当然，将输入patch和输出像素之间连接相乘的权重恰好是（旋转的）卷积核的权重。利用卷积可以实现该计算： <span class="math display">\[
\delta_j^l=f&#39;(u_j^l)\circ conv2(\delta_j^{l+1},rot180(k_j^{l+1}),full)
\]</span> 如前所述，我们旋转内核是为了是卷积函数实施互相关计算。同时，我们需要对卷积边界进行“full”处理，Matlab的卷积函数会自动执行这个过程，对缺少的输入像素进行补零操作。</p>
<p>现在我们可以很容易的计算 <span class="math inline">\(b\)</span> 和 <span class="math inline">\(\beta\)</span> 的梯度，加性基 <span class="math inline">\(b\)</span> 的处理和之前一样，将敏感度map中所有元素相加即可 ： <span class="math display">\[
\frac{\partial E}{\partial b_j}=\sum_{u,v}(\delta_j^l)_{uv}
\]</span> 对于乘性偏置<span class="math inline">\(\beta\)</span> ，参与了前向传播时下采样map的运算，所以在前向计算时将这些maps保存，这样避免了在反向传播时重复计算。定义： <span class="math display">\[
d_j^l=down(x_j^{l-1})
\]</span></p>
<p><span class="math inline">\(\beta\)</span> 梯度计算公式如下： <span class="math display">\[
\frac{\partial E}{\partial \beta_j}=\sum_{u,v}(\delta_j^l)
\]</span></p>
<blockquote>
<p>补充说明：对rot180的解释</p>
<p>假设第<span class="math inline">\(l-1\)</span>层输出<span class="math inline">\(x^l\)</span>是一个3x3矩阵，第<span class="math inline">\(l\)</span>层卷积核<span class="math inline">\(k^l\)</span>是一个2x2的矩阵，步幅为1，输出一个2x2的矩阵<span class="math inline">\(z^l\)</span>，则有（简化<span class="math inline">\(b^l=0\)</span>，单卷积核) <span class="math display">\[
x^{l-1}*k^{l}=z^{l}
\]</span> 矩阵形式表达： <span class="math display">\[
\left( \begin{array}{}
x_{11}&amp;x_{12}&amp;x_{13}\\
x_{21}&amp;x_{22}&amp;x_{23}\\
x_{31}&amp;x_{32}&amp;x_{33}
\end{array}
\right)
*
\left( \begin{array}{}
k_{11}&amp;k_{12}\\
k_{21}&amp;k_{22}
\end{array}
\right)
=
\left( \begin{array}{}
z_{11}&amp;z_{12}\\
z_{21}&amp;z_{22}
\end{array}
\right)
\]</span> 根据卷积的定义可得： <span class="math display">\[
z_{11}=x_{11}k_{11}+x_{12}k_{12}+x_{21}k_{21}+x_{22}k_{22}\\
z_{12}=x_{12}k_{11}+x_{13}k_{12}+x_{22}k_{21}+x_{23}k_{22}\\
z_{21}=x_{21}k_{11}+x_{22}k_{12}+x_{31}k_{21}+x_{32}k_{22}\\
z_{22}=x_{22}k_{11}+x_{23}k_{12}+x_{32}k_{21}+x_{33}k_{22}
\]</span> 第<span class="math inline">\(l\)</span>层的梯度误差为<span class="math inline">\(\delta^l\)</span>，反向传导： <span class="math display">\[
\frac{\partial{E}}{\partial{k^l}}=\frac{\partial{E}}{\partial{z^l}}\frac{\partial{z^l}}{\partial{k^l}}=\delta^l\frac{z^l}{k^l}
\]</span> 因此对于卷积核<span class="math inline">\(k^l\)</span>的梯度为第<span class="math inline">\(l\)</span>层的敏感度（梯度）乘上<span class="math inline">\(\frac{\partial{z^l}}{\partial{k^l}}\)</span>，分别计算可得 <span class="math display">\[
\bigtriangledown{k_{11}}=\delta_{11}x_{11}+\delta_{12}x_{22}+\delta_{21}x_{21}+\delta_{22}x_{22}\\
\bigtriangledown{k_{12}}=\delta_{11}x_{12}+\delta_{12}x_{13}+\delta_{21}x_{22}+\delta_{22}x_{23}\\
\bigtriangledown{k_{21}}=\delta_{11}x_{21}+\delta_{12}x_{22}+\delta_{21}x_{31}+\delta_{22}x_{32}\\
\bigtriangledown{k_{22}}=\delta_{11}x_{22}+\delta_{12}x_{23}+\delta_{21}x_{32}+\delta_{22}x_{33}
\]</span> 上面4个式子用矩阵卷积形式表示： <span class="math display">\[
\left( \begin{array}{}
x_{11}&amp;x_{12}&amp;x_{13}\\
x_{21}&amp;x_{22}&amp;x_{23}\\
x_{31}&amp;x_{32}&amp;x_{33}
\end{array}
\right)
*
\left( \begin{array}{}
\delta_{11}&amp;\delta_{12}\\
\delta_{21}&amp;\delta_{22}
\end{array}
\right)
=
\left( \begin{array}{}
\bigtriangledown k_{11}&amp;\bigtriangledown k_{12}\\
\bigtriangledown k_{21}&amp;\bigtriangledown k_{22}
\end{array}
\right)
\]</span> 公式化表达为： <span class="math display">\[
\frac{\partial{E}}{\partial{k^l}}=x^{l-1}*\delta^l
\]</span></p>
<p>这里需要注意，在论文中进行了两次旋转，这是因为在MATLAB中conv2函数在计算卷积时除了会对矩阵进行“0”扩展，还会将卷积核进行旋转，然后再计算。例如：</p>
<pre><code class="hljs matlab">a =
     <span class="hljs-number">1</span>     <span class="hljs-number">1</span>     <span class="hljs-number">1</span>
     <span class="hljs-number">1</span>     <span class="hljs-number">1</span>     <span class="hljs-number">1</span>
     <span class="hljs-number">1</span>     <span class="hljs-number">1</span>     <span class="hljs-number">1</span>
k =
     <span class="hljs-number">1</span>     <span class="hljs-number">2</span>     <span class="hljs-number">3</span>
     <span class="hljs-number">4</span>     <span class="hljs-number">5</span>     <span class="hljs-number">6</span>
     <span class="hljs-number">7</span>     <span class="hljs-number">8</span>     <span class="hljs-number">9</span>

&gt;&gt; convn(a,k,<span class="hljs-string">&#x27;full&#x27;</span>)
<span class="hljs-built_in">ans</span> =

     <span class="hljs-number">1</span>     <span class="hljs-number">3</span>     <span class="hljs-number">6</span>     <span class="hljs-number">5</span>     <span class="hljs-number">3</span>
     <span class="hljs-number">5</span>    <span class="hljs-number">12</span>    <span class="hljs-number">21</span>    <span class="hljs-number">16</span>     <span class="hljs-number">9</span>
    <span class="hljs-number">12</span>    <span class="hljs-number">27</span>    <span class="hljs-number">45</span>    <span class="hljs-number">33</span>    <span class="hljs-number">18</span>
    <span class="hljs-number">11</span>    <span class="hljs-number">24</span>    <span class="hljs-number">39</span>    <span class="hljs-number">28</span>    <span class="hljs-number">15</span>
     <span class="hljs-number">7</span>    <span class="hljs-number">15</span>    <span class="hljs-number">24</span>    <span class="hljs-number">17</span>     <span class="hljs-number">9</span></code></pre>
<p>因此在编写代码时需要注意保持一致（要么旋转，要么不旋转）。</p>
<p>在3.2节计算 <span class="math inline">\(\delta^l_j\)</span> 也是同理</p>
<p>利用反向传播： <span class="math display">\[
\frac{\partial{E}}{\partial{x^{l-1}}}=\frac{\partial{E}}{\partial{z^l}}\frac{\partial{z^l}}{\partial{x^{l-1}}}=\delta^l\frac{z^l}{x^{l-1}}
\]</span> 利用上式，可得： <span class="math display">\[
\bigtriangledown{x_{11}}=\delta_{11}k_{11}\\
\bigtriangledown{x_{12}}=\delta_{11}k_{12}+\delta_{12}k_{11}\\
\bigtriangledown{x_{13}}=\delta_{12}k_{12}\\
\bigtriangledown{x_{21}}=\delta_{11}k_{21}+\delta_{21}k_{11}\\
\bigtriangledown{x_{22}}=\delta_{11}k_{22}+\delta_{12}k_{21}+\delta_{21}k_{12}+\delta_{22}k_{11}\\
\bigtriangledown{x_{23}}=\delta_{12}k_{22}+\delta_{22}k_{12}\\
\bigtriangledown{x_{31}}=\delta_{21}k_{21}\\
\bigtriangledown{x_{32}}=\delta_{21}k_{22}+\delta_{22}k_{21}\\
\bigtriangledown{x_{33}}=\delta_{22}k_{22}
\]</span> 上面九个式子用矩阵卷积形式表示： <span class="math display">\[
\left( \begin{array}{}
0&amp;0&amp;0&amp;0\\
0&amp;\delta_{11}&amp;\delta_{12}&amp;0\\
0&amp;\delta_{21}&amp;\delta_{22}&amp;0\\
0&amp;0&amp;0&amp;0
\end{array}
\right)
*
\left( \begin{array}{}
k_{22}&amp;k_{21}\\
k_{12}&amp;k_{11}
\end{array}
\right)
=
\left( \begin{array}{}
\bigtriangledown x_{11}&amp;\bigtriangledown x_{12}&amp;\bigtriangledown x_{13}\\
\bigtriangledown x_{21}&amp;\bigtriangledown x_{22}&amp;\bigtriangledown x_{23}\\
\bigtriangledown x_{31}&amp;\bigtriangledown x_{32}&amp;\bigtriangledown x_{33}
\end{array}
\right)
\]</span> 公式化表达为： <span class="math display">\[
\frac{\partial{E}}{\partial{x^{l-1}}}=\delta^l * rot180(k^l)
\]</span></p>
</blockquote>
<p>####3.3 学习特征maps组合 Learning Combinations of Feature Maps</p>
<p>通常，对不同的maps进行卷积并对结果求和获得一个输出map，往往能取得不错的效果。在一些文献中，通过人工选择输入maps进行组合。但是我们可以尝试通过训练获得这个组合。让 <span class="math inline">\(a_{ij}\)</span> 表示得到第 <span class="math inline">\(j\)</span> 个输出map中第 <span class="math inline">\(i\)</span> 个输入map的权重，那么第 <span class="math inline">\(j\)</span> 个输出map的定义如下： <span class="math display">\[
x_j^l=f\left( \sum_{i=1}^{N_{in}}a_{ij}(x_i^{l-1}*k_i^l)+b_j^l\right)
\]</span> 同时需满足以下约束： <span class="math display">\[
\sum_ia_ij=1,and \space 0\leq a_{ij}\leq1
\]</span> 这些约束可以通过将变量<span class="math inline">\(a_{ij}\)</span>表示为softmax形式来加强： <span class="math display">\[
a_{ij}=\frac{exp(c_{ij})}{\sum_kexp(c_{kj})}
\]</span></p>
<p>因为对于固定的 <span class="math inline">\(j\)</span> 来说，每组权值 <span class="math inline">\(c_{ij}\)</span> 都和其他组权值相独立，所以为了方便描述，我们把下标 <span class="math inline">\(j\)</span> 去掉，只考虑单个map的更新，其他map的更新方式是相同的过程，只是索引 <span class="math inline">\(j\)</span> 不同。</p>
<p>softmax函数的导数： <span class="math display">\[
\frac{\partial a_k}{\partial c_i}=\delta_{ki}a_i-a_ia_k\tag{8}
\]</span> 这里的 <span class="math inline">\(\delta\)</span> 是 kronecker delta，参照公式 (1) 我们可以得到在 <span class="math inline">\(l\)</span> 层误差对 <span class="math inline">\(a_i\)</span> 的偏导： <span class="math display">\[
\frac{\partial E}{\partial a_i}=\frac{\partial E}{\partial u^l}\frac{\partial u^l}{\partial a_i}=\sum_{u,v}(\delta^l \circ (x_i^{l-1}*k_i^l))_{uv}
\]</span> 这里的<span class="math inline">\(\delta^l\)</span>对应具有输入 <span class="math inline">\(u\)</span> 的输出map的敏感度map。和前面一样，这里的卷积运算也是“valid”类型，目的是使结果和sensitivity map大小匹配。最后使用链式法则计算损失函数对权值 <span class="math inline">\(c_i\)</span> 的偏导数： <span class="math display">\[
\begin{align}
\frac{\partial E}{\partial c_i}&amp;=\sum_k\frac{\partial E}{\partial a_k}\frac{\partial a_k}{\partial c_i}\tag{9}\\
&amp;=a_i\left( \frac{\partial E}{\partial a_i}-\sum_k\frac{\partial E}{\partial a_k}a_k\right)\tag{10}
\end{align}
\]</span> 3.3.1 Enforcing Sparse Combinations</p>
<p>为了给 <span class="math inline">\(a_i\)</span> 增加稀疏约束（限制一个输出map只与某些而不是全部输入map相连接），我们在代价函数中添加正则项惩罚 <span class="math inline">\(\Omega(a)\)</span> 。这样就可以使某些权值趋于0，最后只有部分输入maps参与输出map相连接，代价函数为： <span class="math display">\[
\widetilde{E}^n=E^n + \lambda\sum{i,j}|(a){ij}|\tag{11}
\]</span> 然后求这个正则项对 <span class="math inline">\(c_i\)</span>梯度的影响： <span class="math display">\[
\frac{\partial\Omega}{\partial a_i}=\lambda sign(a_i)\tag{12}
\]</span></p>
<p>结合公式 (8) 的结果： <span class="math display">\[
\begin{align}
\frac{\partial\Omega}{\partial c_i}&amp; = \sum_k\frac{\partial\Omega}{\partial a_k}\frac{\partial a_k}{\partial c_i} \\
&amp;=
\lambda\left(|a_i|-a_i\sum_k|a_k|\right)
\end{align}
\]</span> 最后结合公式 (13) 和公式 (9) ，可以求的权重 <span class="math inline">\(c_i\)</span> 的梯度： <span class="math display">\[
\frac{\partial\widetilde{E}^n}{\partial c_i} = \frac{\partial E^n}{\partial c_i} +\frac{\partial \Omega}{\partial c_i}
\]</span></p>
<h4 id="加快matlab训练速度-making-it-fast-with-matlab">3.4 加快MATLAB训练速度 Making it Fast with MATLAB</h4>
<blockquote>
<p>与CNN关系不大，不做翻译，可看原文</p>
</blockquote>
<h3 id="实际训练问题-practical-training-issues-incomplete">4 实际训练问题 Practical Training Issues (Incomplete)</h3>
<blockquote>
<p>与CNN关系不大，不做翻译，可看原文</p>
</blockquote>
<p>$$</p>
<p>$$</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/artificial-intelligence/">artificial intelligence</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/deep-learning/">deep learning</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2018/04/11/Softmax-and-Cross-Entropy-Loss/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Softmax and Cross Entropy Loss</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2018/03/19/ZELDA-%E7%94%B7%E4%BA%BA%E7%9A%84%E6%B5%AA%E6%BC%AB/">
                        <span class="hidden-mobile">ZELDA-男人的浪漫</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                
  <script type="text/javascript">
    function loadUtterances() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'yinxiaojian/blog-comment');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    }
    waitElementVisible('comments', loadUtterances)
  </script>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "CNN反向传播算法&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  











</body>
</html>
